[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "GAP Production Data Documentation",
    "section": "",
    "text": "AFSC Bottom Trawl Surveys\nAFSC bottom trawl surveys are conducted by the AFSC’s Groundfish Assessment Program and Shellfish Assessment Program and are conducted in the Gulf of Alaska, Aleutian Islands, Eastern Bering Sea Slope, Eastern Bering Sea Shelf, and Northern Bering Sea. Each survey is a multispecies survey that collects data on the distribution, abundance, and biological characteristics of fish, crab, and other resources to inform groundfish stock assessment and management. These fishery-independent surveys are conducted in the summer aboard contracted commercial fishing vessels. Specifics regarding each of the surveys can be found below.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#afsc-bottom-trawl-surveys",
    "href": "index.html#afsc-bottom-trawl-surveys",
    "title": "GAP Production Data Documentation",
    "section": "",
    "text": "Sorting and weighing fish on deck on the 2022 Bering Sea groundfish survey aboard the F/V Alaska Knight. Credit: Emily Markowitz/NOAA Fisheries.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#documentation-objective",
    "href": "index.html#documentation-objective",
    "title": "GAP Production Data Documentation",
    "section": "Documentation Objective",
    "text": "Documentation Objective\nAs part of our commitment to open science, reproducibility, and transparency, we provide this metadata guide to compliment our public-domain data.\n\nPlease consider this resource to be a Living Document. The code in this repository is regularly being updated and improved. Please refer to releases for finalized products and project milestones.\n\n\nAt this time, these master production and AKFIN tables are provisional and we are welcoming feedback before the 2024 survey season. We look forward to hearing from you. Do not hesitate to reach out (to us at either nmfs.afsc.gap.metadata@noaa.gov or GitHub issues, especially if you find discrepancies in the data or want to suggest improvements to infrastructure. Thank you in advance for your collaboration and partnership with us as we develop our future data universe.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#user-resources",
    "href": "index.html#user-resources",
    "title": "GAP Production Data Documentation",
    "section": "User Resources",
    "text": "User Resources\n\nGroundfish Assessment Program Bottom Trawl Surveys\nAFSC’s Resource Assessment and Conservation Engineering Division\nAll AFSC Research Surveys\nSurvey code books\nPublications and Data Reports\nResearch Surveys conducted at AFSC",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#cite-this-data",
    "href": "index.html#cite-this-data",
    "title": "GAP Production Data Documentation",
    "section": "Cite this data",
    "text": "Cite this data\nUse the below bibtext citations, as cited in our group’s citation repository for citing the data created and maintained in this repo. Add “note = {Accessed: mm/dd/yyyy}” to append the day this data was accessed. Included here are AFSC RACE Groundfish and Shellfish Assessment Program’s:\n\nDesign-Based Production Data (internal) (NOAA Fisheries Alaska Fisheries Science Center, Goundfish Assessment Program, 2024).\n\nAFSC RACE Groundfish Data for AKFIN (Alaska Fisheries Information Network (AKFIN), 2024).\nPublic Data hosted on the Fisheries One Stop Shop (FOSS) Data Platform (NOAA Fisheries Alaska Fisheries Science Center, 2024).\n\n\n\n\n@misc{GAPProducts,\n  author = {{NOAA Fisheries Alaska Fisheries Science Center, Goundfish Assessment Program}},\n  year = {2023}, \n  title = {AFSC Goundfish Assessment Program Design-Based Production Data},\n  howpublished = {https://www.fisheries.noaa.gov/alaska/science-data/groundfish-assessment-program-bottom-trawl-surveys},\n  publisher = {{U.S. Dep. Commer.}},\n  copyright = {Public Domain} \n}\n\n@misc{FOSSAFSCData,\n  author = {{NOAA Fisheries Alaska Fisheries Science Center}},\n  year = {2023}, \n  title = {Fisheries One Stop Shop Public Data: RACE Division Bottom Trawl Survey Data Query},\n  howpublished = {https://www.fisheries.noaa.gov/foss},\n  publisher = {{U.S. Dep. Commer.}},\n  copyright = {Public Domain} \n}\n\n@misc{GAPakfin,\n  author = {{Alaska Fisheries Information Network (AKFIN)}}, \n  institution = {{NOAA Fisheries Alaska Fisheries Science Center, Goundfish Assessment Program}},\n  year = {2023}, \n  title = {AFSC Goundfish Assessment Program Design-Based Production Data},\n  howpublished = {https://www.psmfc.org/program/alaska-fisheries-information-network-akfin},\n  publisher = {{U.S. Dep. Commer.}},\n  copyright = {Public Domain} \n}",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#access-constraints",
    "href": "index.html#access-constraints",
    "title": "GAP Production Data Documentation",
    "section": "Access Constraints",
    "text": "Access Constraints\nThere are no legal restrictions on access to the data. They reside in public domain and can be freely distributed.\nUser Constraints: Users must read and fully comprehend the metadata and code of conduct prior to use. Data should not be used beyond the limits of the source scale. Acknowledgement of AFSC Groundfish Assessment Program, as the source from which these data were obtained, in any publications and/or other representations of these data, is suggested.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#suggestions-and-comments",
    "href": "index.html#suggestions-and-comments",
    "title": "GAP Production Data Documentation",
    "section": "Suggestions and comments",
    "text": "Suggestions and comments\nIf the data or metadata can be improved, please create a pull request, submit an issue to the GitHub organization or submit an issue to the code’s repository.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#noaa-readme",
    "href": "index.html#noaa-readme",
    "title": "GAP Production Data Documentation",
    "section": "NOAA README",
    "text": "NOAA README\nThis repository is a scientific product and is not official communication of the National Oceanic and Atmospheric Administration, or the United States Department of Commerce. All NOAA GitHub project code is provided on an ‘as is’ basis and the user assumes responsibility for its use. Any claims against the Department of Commerce or Department of Commerce bureaus stemming from the use of this GitHub project will be governed by all applicable Federal law. Any reference to specific commercial products, processes, or services by service mark, trademark, manufacturer, or otherwise, does not constitute or imply their endorsement, recommendation or favoring by the Department of Commerce. The Department of Commerce seal and logo, or the seal and logo of a DOC bureau, shall not be used in any manner to imply endorsement of any commercial product or activity by DOC or the United States Government.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#noaa-license",
    "href": "index.html#noaa-license",
    "title": "GAP Production Data Documentation",
    "section": "NOAA License",
    "text": "NOAA License\nSoftware code created by U.S. Government employees is not subject to copyright in the United States (17 U.S.C. §105). The United States/Department of Commerce reserve all rights to seek and obtain copyright protection in countries other than the United States for Software authored in its entirety by the Department of Commerce. To this end, the Department of Commerce hereby grants to Recipient a royalty-free, nonexclusive license to use, copy, and create derivative works of the Software outside of the United States.\n\n\n\n\nAlaska Fisheries Information Network (AKFIN). (2024). AFSC groundfish assessment program design-based production data. NOAA Fisheries Alaska Fisheries Science Center, Groundfish Assessment Program; https://akfinbi.psmfc.org/analytics/; U.S. Dep. Commer. https://www.psmfc.org/program/alaska-fisheries-information-network-akfin\n\n\nNOAA Fisheries Alaska Fisheries Science Center. (2024). Fisheries one stop shop public data: RACE division bottom trawl survey data query. https://www.fisheries.noaa.gov/foss; U.S. Dep. Commer.\n\n\nNOAA Fisheries Alaska Fisheries Science Center, Goundfish Assessment Program. (2024). AFSC goundfish assessment program design-based production data. https://www.fisheries.noaa.gov/alaska/science-data/groundfish-assessment-program-bottom-trawl-surveys; U.S. Dep. Commer.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "content/intro-survey-background.html",
    "href": "content/intro-survey-background.html",
    "title": "Survey Background",
    "section": "",
    "text": "What we do",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Survey Background</span>"
    ]
  },
  {
    "objectID": "content/intro-survey-background.html#who-is-conducting-the-research",
    "href": "content/intro-survey-background.html#who-is-conducting-the-research",
    "title": "Survey Background",
    "section": "Who is conducting the research?",
    "text": "Who is conducting the research?\nScientists from the Alaska Fisheries Science Center’s Groundfish Assessment Program (GAP) conduct these bottom trawl surveys with participation from the Alaska Department of Fish & Game (ADF&G), the International Pacific Halibut Commission (IPHC), universities, and other organizations. This research is conducted primarily on chartered fishing vessels.",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Survey Background</span>"
    ]
  },
  {
    "objectID": "content/intro-survey-background.html#what-is-the-research-objective",
    "href": "content/intro-survey-background.html#what-is-the-research-objective",
    "title": "Survey Background",
    "section": "What is the research objective?",
    "text": "What is the research objective?\nLearn more about the program. The objectives of these surveys are to:\n\nmonitor the population and environmental trends in the marine ecosystem of the Bering Sea, Aleutian Islands, and Gulf of Alaska,\nproduce fishery-independent biomass (weight) and abundance (number) estimates for commercially important fish and crab species, and\ncollect other biological and environmental data for use in ecosystem-based fishery management.",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Survey Background</span>"
    ]
  },
  {
    "objectID": "content/intro-survey-background.html#who-is-conducting-the-research-1",
    "href": "content/intro-survey-background.html#who-is-conducting-the-research-1",
    "title": "Survey Background",
    "section": "Who is conducting the research?",
    "text": "Who is conducting the research?\nScientists from the Alaska Fisheries Science Center conduct these bottom trawl surveys with participation from the Alaska Department of Fish & Game (ADF&G), the International Pacific Halibut Commission (IPHC), and universities. This research is conducted on chartered fishing vessels.",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Survey Background</span>"
    ]
  },
  {
    "objectID": "content/intro-survey-background.html#bottom-trawl-surveys-and-regions",
    "href": "content/intro-survey-background.html#bottom-trawl-surveys-and-regions",
    "title": "Survey Background",
    "section": "Bottom trawl surveys and regions",
    "text": "Bottom trawl surveys and regions\n\n\n\nStrata used in the all surveys.\n\n\nEach survey conducted by the Groundfish Assessment Program are multispecies bottom trawl surveys. We collect environmental and biological data to assess how climate variability and loss of sea ice are affecting bottom-dwelling marine life on the Bering Sea shelf. We monitor trends in the distribution (location and movement patterns) and abundance of groundfish and crab species as well as oceanographic data (e.g., water temperature, depth). We collect biological information such as organism weight, length, stomachs to learn about diets, and otoliths to determine fish ages. We use this information in annual stock assessments and to assess the state of the ecosystem. This research is conducted on fishing industry contract vessels.\n\n\nSurvey summary statsSurveySurvey Definition IDYearsDepth (m)Area (km2)# Statistical Areas# Possible StationsAleutian Islands Bottom Trawl Survey522024 - 1991 (14)1 - 50064,415.0801,312Eastern Bering Sea Slope Bottom Trawl Survey782016 - 2002 (6)201 - 1,20032,861.337Eastern Bering Sea Crab/Groundfish Bottom Trawl Survey982025 - 1982 (43)1 - 200492,989.928515Gulf of Alaska Bottom Trawl Survey472025 - 1990 (17)1 - 1,000315,501.9376,939Northern Bering Sea Crab/Groundfish Survey - Eastern Bering Sea Shelf Survey Extension1432025 - 2010 (7)1 - 100189,191.44144\n\n\n\nAleutian Islands\nMost recent data report: (Von Szalay et al., 2023)\n\nUpper Continental Slope of the Aleutian Islands from Unimak Pass to Stalemate Bank\nTriennial (1990s)/Biennial since 2000 in even years, since 1992\nModified Index-Stratified Random of Successful Stations Survey Design\nImportant commercial fish species include Atka mackerel, Pacific ocean perch, walleye pollock, Pacific cod, sablefish, and other rockfish species.\n\n\n\n\nStrata used in the Aleutian Islands bottom trawl survey.\n\n\n\n\nGulf of Alaska\nMost recent data report: (Siple et al., 2024)\n\nContinental Shelf and Upper Slope of the Gulf of Alaska extending from the Islands of Four Mountains 2,300 km east to Dixon Entrance\nTriennial (1990s)/Biennial since 2001 in odd years, since 1991\nStratified Random Survey Design\nImportant commercial species in the Gulf of Alaska include Pacific ocean perch, walleye pollock, Pacific cod, flatfish, and other rockfish species.\n\n\n\n\nStrata used in the Gulf of Alaska bottom trawl survey.\n\n\n\n\nEastern Bering Sea Shelf\nMost recent data report: (Markowitz et al., 2025)\n\nThe continental shelf of the eastern Bering Sea from the Aleutian Islands to the Bering Strait\nConducted annually since 1982.\nUses a stratified systematic sampling survey design with fixed stations at center of 20 x 20 nm grid.\nSimilar in design to the northern Bering Sea shelf bottom trawl survey.\nFocus species for the Bering Sea include walleye pollock, Pacific cod, Greenland turbot, yellowfin sole, northern rock sole, red king crab, and snow and Tanner crabs.\n\n\n\n\nStrata used in the Eastern Bering Sea bottom trawl survey.\n\n\n\n\nNorthern Bering Sea\nMost recent data report: (Markowitz et al., 2024)\n\nThe continental shelf of the northern Bering Sea, including the area north of St. Lawrence Island and Norton Sound\nBiennial/Annual; conducted intermittently since 2010\nUses a stratified systematic sampling survey design with fixed stations at center of 20 x 20 nm grid.\nSimilar in design to the eastern Bering Sea shelf bottom trawl survey.\n\n\n\n\nStrata used in the Northern Bering Sea bottom trawl survey.\n\n\n\n\nEastern Bering Sea Upper Continental Slope\nMost recent data report: (Hoff, 2016)\n\nThe eastern Bering Sea upper continental slope survey area extends from Unalaska and Akutan Islands to the U.S.-Russian Maritime Boundary at 61° N near the International Date Line (166° E to 180° W) at depths from 200 to 1,200 m\nConducted intermittently since 2002 (funding dependent)\nModified Index-Stratified Random of Successful Stations Survey Design\nFocus species for the Bering Sea slope include giant grenadier, Pacific ocean perch, popeye grenadier, walleye pollock, and arrowtooth flounder.\n\n\n\n\nStrata used in the Bering Sea Slope bottom trawl survey.\n\n\n\n\n\n\nHoff, G. R. (2016). Results of the 2016 eastern Bering Sea upper continental slope survey of groundfishes and invertebrate resources (NOAA Tech. Memo. NOAA-AFSC-339). U.S. Dep. Commer. https://doi.org/10.7289/V5/TM-AFSC-339\n\n\nMarkowitz, E. H., Dawson, E. J., Wassermann, S., Anderson, C. B., Rohan, S. K., Charriere, B. K., and Stevenson, D. E. (2024). Results of the 2023 eastern and northern Bering Sea continental shelf bottom trawl survey of groundfish and invertebrate fauna (NOAA Tech. Memo. NMFS-AFSC-487; p. 242). U.S. Dep. Commer. https://doi.org/10.25923/2mry-yx09\n\n\nMarkowitz, E. H., Wassermann, S., Rohan, S. K., Charriere, B. K., Anderson, C. B., and Stevenson, D. E. (2025). Results of the 2024 eastern and northern Bering Sea continental shelf bottom trawl survey of groundfish and invertebrate fauna (NOAA Tech. Memo. NMFS-AFSC-499; p. 203). U.S. Dep. Commer. https://doi.org/10.25923/8qa3-x785\n\n\nSiple, M. C., Szalay, P. G. von, Raring, N. W., Dowlin, A. N., and Riggle, B. C. (2024). Data report: 2023 gulf of alaska bottom trawl survey (NOAA Tech. Memo. AFSC processed report; 2024-09). U.S. Dep. Commer. https://doi.org/10.25923/gbb1-x748\n\n\nVon Szalay, P. G., Raring, N. W., Siple, M. C., Dowlin, A. N., Riggle, B. C., and Laman, E. A. and. (2023). Data report: 2022 Aleutian Islands bottom trawl survey (AFSC Processed Rep. 2023-07; p. 230). U.S. Dep. Commer. https://doi.org/10.25923/85cy-g225",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Survey Background</span>"
    ]
  },
  {
    "objectID": "content/intro-workflow.html",
    "href": "content/intro-workflow.html",
    "title": "Workflow",
    "section": "",
    "text": "Operational Product Development Timeline\nOver the course of the year, the survey team is developing a variety of different data products. Planning and preparation for surveys happens in the late winter and spring, surveys occur in the summer, data validation takes place over the course of the survey and after the survey, and data products are produced through fall and late winter.\nOperational product development timeline. JanuaryFebruaryMarchAprilMayJuneJulyAugustSeptemberOctoberNovemberDecemberSurveys1111Planning1111111Development11111111Deployment (survey deliverables)1111Deployment (survey operations)1111Triage (fixing bugs and errors)111111111111User feedback and brainstorming111111111111",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Workflow</span>"
    ]
  },
  {
    "objectID": "content/intro-workflow.html#data-workflow-from-boat-to-production",
    "href": "content/intro-workflow.html#data-workflow-from-boat-to-production",
    "title": "Workflow",
    "section": "Data workflow from boat to production",
    "text": "Data workflow from boat to production\nOrganisms first need to be collected aboard the vessel before data can be entered into tablets.\n\n\n\n\n\n\nflowchart \n  A1[Net and catch\\ntotal weight/volume] --&gt; A2\n  A1 --&gt; |Catch tablet|BB\n  A2[Fish are collected and\\ndumped on the table] --&gt; A3[Initial on deck\\nsampling decisions\\n and sort by\\nspecies and mix]\n  P1[Specimen bag and tag] --&gt; P5[Observer collections]\n  P1 --&gt; P6[Museum collections]\n  P1 --&gt; P7[Research samples]\n  P2[SAT/PAT fish and crab tagging]\n  P3[Species condition]\n  P4[Genetics]\n  A3 --&gt; C1[Crab:\\nSex, weight]\n  A3 --&gt; C2[Fish, size varying:\\nWeight, sex, length]\n  A3 --&gt; |Catch tablet|C3[Fish, small:\\nWeight, sex]\n  A3 --&gt; C4[Invertebrates, colonial:\\nWeight]\n  A3 --&gt; C5[Invertebrates, other:\\nWeight, count]\n  C1 --&gt; |Crab tablet|S1[Length, width, weight, \\nshell condition]\n  C2 --&gt; |Specimen tablet|S2[Otolith, length, width, \\nweight, sex]\n  C2 --&gt; |Length tablet|S3[Length, sex]\n  C2 --&gt; |Stomach tablet|S4[Diet/stomach samples]\n  V1[Fish collections in formalin 10%]\n  V2[Invertebrate collections in ethanol]\n  subgraph AA[Net on deck]\n  A1\n  A2\n  A3\n  subgraph BB[Benthic bag]\n  B[Identify,\\npresence/absence]\n  end\n  end\n  subgraph CC[Bag composition data]\n  C1\n  C2\n  C3\n  C4\n  C5\n  subgraph VV[Voucher collections]\n  V1\n  V2\n  end\n  end\n  subgraph SS[Individual specimen data]\n  S1\n  S2\n  S3\n  S4\n  subgraph PP[Non-core science project requests]\n  P1\n  P2\n  P3\n  P4\n  P5\n  P6\n  P7\n  end\n  end\n  style AA fill:white,::\n  style SS fill:beige,::\n  style BB fill:beige,::\n  style CC fill:beige,::\n  style PP fill:white,::\n  style VV fill:white,::\n\n\n\n\nFigure 2.1: Simplified boat deck processing workflow.\n\n\n\n\n\nThe objective of this process is to take raw data, QA/QC and clean these data, curate standard data products for these survey. Please note, through this process we are not providing “data” (what we consider lower level data material; see the data levels section below) but “data products”, which is intended to facilitate the most fool-proof standard interpretation of the data. These data products only use data from standard and validated hauls, and has undergone careful review.\nOnce survey data collected on the vessel has been checked and validated, the gap_products/code/run.R script is used to orchestrate a sequence of programs that calculate the standard data products resulting from the NOAA AFSC GAP bottom trawl surveys. Standard data products are the CPUE, BIOMASS, SIZECOMP, and AGECOMP tables in the GAP_PRODUCTS Oracle schema. The tables are slated to be updated twice a year: once after the survey season following finalization of that summer’s bottom trawl survey data to incorporate the new catch, size, and effort data and once prior to an upcoming survey to incorporate new age data that were processed after the prior summer’s survey season ended. This second pre-survey production run will also incorporate changes in the data due to the specimen voucher process as well as other post-hoc changes in the survey data.\n\nThe data from these surveys constitute a living data set so we can continue to provide the best available data to all partners, stakeholders, and fellow scientists.\n\n\n\n\n\n\n\nflowchart LR\n  A([Catch data\\ndeck tablet]) --&gt; B1[METIS Biological\\ndata editing\\nsoftware]\n  A1([Length data\\ndeck tablets]) --&gt; B1\n  A2([Specimen data\\ndeck tablet]) --&gt; B1\n  A3([Haul performance w/ Marport sensors]) --&gt; B2[Wheelhouse &\\nCalyposo \\nhaul data] \n  A4([CTD]) --&gt; B2\n  A5([sea state\\nobersvations]) --&gt; B2\n  A6([HOBO bottom\\ncontact sensor]) --&gt; B2\n  A7{{navmaps\\nR package\\nfor navigation}} --&gt; B2\n  B1 --&gt; C[GIDES &\\nRACE_EDIT\\nOracle schema\\n& whole-survey\\nreview &\\ndata checking]\n  B2 --&gt; C\n  C --&gt; D[RACEBASE\\nand RACE_DATA\\nOracle schemata]\n  D1{{gapindex R package}} --&gt; F[Public Data Product:\\ntables in\\nGAP_PRODUCTS\\nOracle schema]\n  D2{{gap_products\\nR scripts}} --&gt; F\n  D --&gt; D1\n  D1 --&gt; D2\n  D --&gt; F\n  subgraph AA[Data Level 0: Raw]\n  A\n  A1\n  A2\n  A3\n  A4\n  A5\n  A6\n  A7\n  end\n  subgraph BB[Data Level 1:\\nQA/QC'ed data]\n  B1\n  B2\n  end\n  subgraph CC[Data Level 2:\\nAnalysis ready product for internal use]\n  C\n  D\n  end\n  subgraph FF[Data Level 3:\\nAnalysis ready product\\nfor external/public use]\n  F\n  end\n  style AA fill:beige,::\n  style BB fill:white,::\n  style CC fill:beige,::\n  style FF fill:white,::\n\n\n\n\nFigure 2.2: Simplified data workflow from boat to production.\n\n\n\n\n\nDuring each data product run cycle:\n\nVersions of the tables in GAP_PRODUCTS are locally imported within the gap_products repository to compare with the updated production tables. Any changes to a production table will be compared and checked to make sure those changes are intentional and documented.\nUse the gapindex R package to calculate the four major standard data products: CPUE, BIOMASS, SIZECOMP, AGECOMP. These tables are compared and checked to their respective locally saved copies and any changes to the tables are vetted and documented. These tables are then uploaded to the GAP_PRODUCTS Oracle schema.\nCalculate the various materialized views for AKFIN and FOSS purposes. Since these are derivative of the tables in GAP_PRODUCTS as well as other base tables in RACEBASE and RACE_DATA, it is not necessary to check these views in addition to the data checks done in the previous steps.\n\n\n\n\n\n\n\nflowchart\n  subgraph AA[Data Level 4]\n  A[GAP_PRODUCTS\\nOracle data\\nproduct tables] --&gt; C[Data process\\nreports &\\npresentations]\n  A --&gt; G3{{esrindex R package}}\n  G3 --&gt; G1[ESP: Ecosystem\\nStatus Reports]\n  G3 --&gt; G2[ESR: Ecosystem\\nand Socioeconomic\\nProfiles]\n  G3 --&gt; C\n  G3 --&gt; G4[Stock assessment\\nrisk assessment\\ntables]\n  A --&gt; D[Outreach]\n  D --&gt; E[Plan Team\\nPresentations]\n  D --&gt; F[Community\\nHighlight\\nDocuments]\n  D --&gt; H[Survey progress\\n& temperature maps]\n  A --&gt; I[Data Platforms]\n  I --&gt; J[AKFIN: Alaska\\nFisheries\\nInformation\\nNetwork]\n  I --&gt; K[FOSS: Fisheries One\\nStop Shop]\n  I --&gt; L{{afscgap\\nPython package}}\n  A --&gt; M[Model-Based\\nIndices]\n  M --&gt; N{{VAST/tinyVAST}}\n  M --&gt; O{{sdmTMB}}\n  M --&gt; P[EFH: Essential\\nFish Habitat]\n  F\n  end\n  style AA fill:beige,::\n\n\n\n\n\nFigure 2.3: Major end-users of the GAP data product tables.",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Workflow</span>"
    ]
  },
  {
    "objectID": "content/intro-workflow.html#data-levels",
    "href": "content/intro-workflow.html#data-levels",
    "title": "Workflow",
    "section": "Data levels",
    "text": "Data levels\nGAP produces numerous data products that are subjected to different levels of processing, ranging from raw to highly-derived. The suitability of these data products for analysis varies and there is ambiguity about which data products can be used for which purpose. This ambiguity can create challenges in communicating about data products and potentially lead to misunderstanding and misuse of data. One approach to communicating about the level of processing applied to data products and their suitability for analysis is to describe data products using a Data Processing Level system. Data Processing Level systems are widely used in earth system sciences to characterize the extent of processing that has been applied to data products. For example, the NOAA National Centers for Environmental Information (NCEI) Satellite Program uses a Data Processing Level system to describe data on a scale of 0-4, where Level 0 is raw data and Level 4 is model output or results from analysis. Example of how NASA remote sensing data products are shared through a public data portal with levels of data processing and documentation.\nFor more information, see Sean Rohan’s October 2022 SCRUGS presentation on the topic.\n\nLevel 0: Raw and unprocessed data. Ex: Data on the G drive, some tables in RACE_DATA\nLevel 1: Data products with QA/QC applied that may or may not be expanded to analysis units, but either not georeferenced or does not include full metadata. Ex: Some tables in RACE_DATA and RACEBASE\nLevel 2: Analysis-ready data products that are derived for a standardized extent and account for zeros and missing/bad data. Ex: CPUE tables, some data products in public-facing archives and repositories\nLevel 3: Data products that are synthesized across a standardized extent, often inputs in a higher-level analytical product. Ex: Abundance indices, some data products in public-facing archives and repositories\nLevel 4: Analytically generated data products that are derived from lower-level data, often to inform management. Ex: Biological reference points from stock assessments, Essential Fish Habitat layers, indicators in Ecosystem Status Reports and Ecosystem and Socioeconomic Profiles",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Workflow</span>"
    ]
  },
  {
    "objectID": "content/intro-news.html",
    "href": "content/intro-news.html",
    "title": "News",
    "section": "",
    "text": "News/change logs\n– GAP_PRODUCTS ChangeLog (last produced on 2025-09-22) using gapindex v3.0.3: Run completed by: Duane Stevenson\n– GAP_PRODUCTS ChangeLog (last produced on 2025-08-25) using gapindex v3.0.2: Run completed by: Zack Oyafuso\n– GAP_PRODUCTS ChangeLog (last produced on 2025-07-15) using gapindex v2.2.0: Run completed by: Zack Oyafuso\n– GAP_PRODUCTS ChangeLog (last produced on 2025-06-05) using gapindex v3.0.2: Run completed by: Zack Oyafuso\n– GAP_PRODUCTS ChangeLog (last produced on 2025-05-20) using gapindex v3.0.2: Run completed by: Zack Oyafuso\n– GAP_PRODUCTS ChangeLog (last produced on 2025-04-30) using gapindex v3.0.2: Run completed by: Zack Oyafuso\n– GAP_PRODUCTS ChangeLog (last produced on 2025-03-20) using gapindex v3.0.2: Run completed by: Zack Oyafuso\n– GAP_PRODUCTS ChangeLog (last produced on 2024-12-10) using gapindex v3.0.2: Run completed by: Sean Rooney\n– GAP_PRODUCTS ChangeLog (last produced on 2024-10-22) using gapindex v2.2.0: Run completed by: Zack Oyafuso\n– GAP_PRODUCTS ChangeLog (last produced on 2024-10-21) using gapindex v2.2.0: Run completed by: Duane Stevenson, Ned Laman, Zack Oyafuso\n– GAP_PRODUCTS ChangeLog (last produced on 2024-09-05) using gapindex v2.2.0: Run completed by: Ned Laman, Zack Oyafuso\n– GAP_PRODUCTS ChangeLog (last produced on 2024-09-03) using gapindex v2.2.0: Run completed by: Ned Laman, Zack Oyafuso\n– GAP_PRODUCTS ChangeLog (last produced on 2024-08-29) using gapindex v2.2.0: The additions of previous years’ age data and 2024 EBS catch, effort, and size data\n– GAP_PRODUCTS ChangeLog (last produced on 2024-08-20) using gapindex v2.2.0: Initial 2024 post-survey run with new ages since last run and all of EBS Shelf 2024 survey data but none of AI 2024 survey data. While trying to update the records in the GAP_PRODUCTS table, the connection was terminated, partially uploading records in the agecomp tables and outputting NA to the N_HAUL and N_LENGTH fields in the biomass tables. At this point, the GAP_PRODUCTS tables are incomplete. The AKFIN and FOSS tables were NOT updated in this run.\n– GAP_PRODUCTS ChangeLog (last produced on 2024-05-04) using gapindex v2.2.0: A development branch version of gapindex called using_datatable uses the data.table package for many dataframe manipulations, which greatly decreased the computation time of many of the functions. There were no major changes in the calculations in this version of the gapindex package and thus the major changes listed below are not related to the gapindex package. The only major change from this run was the addition of GOA 2023 Pacific Ocean perch read otolith data.\n– GAP_PRODUCTS ChangeLog (last produced on 2024-04-09) using gapindex v2.2.0: A development branch version of gapindex called using_datatable uses the data.table package for many dataframe manipulations, which greatly decreased the computation time of many of the functions. There were no major changes in the calculations in this version of the gapindex package and thus the major changes listed below are not related to the gapindex package.\n– GAP_PRODUCTS ChangeLog (last produced on 2024-02-29) using gapindex v2.2.0: A new version of gapindex 2.2.0 was used for this production run and now accesses taxonomic information from RACEBASE.SPECIES instead of GAP_PRODUCTS.TAXONOMIC_CLASSIFICATION. As a result, there will be some SPECIES_CODE values that are supported due to slight differences between the two tables. Discussion in this github issue #54. As a result there are new cpue records for SPECIES_CODE values 22290 and 22292 and removed cpue records for SPECIES_CODE values 21345, 22200 and 69326.\n– GAP_PRODUCTS ChangeLog (last produced on 2024-01-09) using gapindex v2.1.3: A new version of gapindex (v2.1.3) was used to produced these data. Data for SPECIES_CODE 68590 (Chionoecetes hybrids) are now removed, per this issue (https://github.com/afsc-gap-products/gap_products/issues/3). New read otolith data were incorporated into the age compositions. GOA depth subareas are now included in the size comps, and there were some modifications with EBS skate length data that are now incorporated into the length compositions.\n– GAP_PRODUCTS ChangeLog (last produced on 2023-11-17) using gapindex v2.1.2: A new version of gapindex (v2.1.2) was used to produced these data. There was a slight change to how subarea biomass totals are calculated that was not fully addressed in v2.1.1. The modified biomass records reflect this change.\n– GAP_PRODUCTS ChangeLog (last produced on 2023-11-14) using gapindex v2.1.1: A new version of gapindex (v2.1.1) was used to produced these data. There was a slight change to how subarea biomass totals are calculated. The modified biomass records reflect this change. New 2022 otolith data were available since the last iteration of the GAP_PRODUCTS for Aleutian Island Pacific ocean perch and northern rockifsh and Eastern Bering Sea northern rock sole. Zero-filled CPUE records for four GOA species codes (SPECIES_CODE: 21210, 30010, 30360, 77102, 98101) were added due to how the 1990 data were integrated in the last production run of GAP_PRODUCTS. Two Arctic cod (SPECIES_CODE: 21725) and one plain sculpin (SPECIES_CODE: 21371) count records were modified in the NBS data, which changes the numerical CPUE estimates for those hauls which changes the estimated population abundance and size composition for those species.\n– Groundfish Assessment Program Survey Data Serving and Data Improvements: Initial data changes brief distributed to SSMA and other partners by Ned Laman, Zack Oyafuso, and Emily Markowitz\n– Run 2023-06-01 gapindex v2.1.0: Initial compiling and planning notes",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>News</span>"
    ]
  },
  {
    "objectID": "content/intro-code-of-conduct.html",
    "href": "content/intro-code-of-conduct.html",
    "title": "Code of Conduct",
    "section": "",
    "text": "What are Codes of Conduct?\nCodes of Conduct are voluntary sets of rules that assist creators, developers, and users of code and data with data protection compliance and accountability in specific sectors or relating to particular processing operations.\nCodes can help organizations to ensure all participants follow best practices and rules designed specifically for their sector or processing operations, thus enhancing compliance and collaboration. They are developed and managed by an association or other body (the ‘Code Owner’) which is representative of a sector (or category of data controllers or processors), with the expert and sectoral knowledge of how to enhance data protection in their area.",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Code of Conduct</span>"
    ]
  },
  {
    "objectID": "content/intro-code-of-conduct.html#what-are-codes-of-conduct",
    "href": "content/intro-code-of-conduct.html#what-are-codes-of-conduct",
    "title": "Code of Conduct",
    "section": "",
    "text": "Code of Conduct from the nmfs-opensci GitHub.",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Code of Conduct</span>"
    ]
  },
  {
    "objectID": "content/intro-code-of-conduct.html#our-pledge",
    "href": "content/intro-code-of-conduct.html#our-pledge",
    "title": "Code of Conduct",
    "section": "Our Pledge",
    "text": "Our Pledge\nIn the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Code of Conduct</span>"
    ]
  },
  {
    "objectID": "content/intro-code-of-conduct.html#our-standards",
    "href": "content/intro-code-of-conduct.html#our-standards",
    "title": "Code of Conduct",
    "section": "Our Standards",
    "text": "Our Standards\nExamples of behavior that contributes to creating a positive environment include:\n\nUsing welcoming and inclusive language\nBeing respectful of differing viewpoints and experiences\nGracefully accepting constructive criticism\nFocusing on what is best for the community\nShowing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\nThe use of sexualized language or imagery and unwelcome sexual attention or advances\nTrolling, insulting/derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others’ private information, such as a physical or electronic address, without explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Code of Conduct</span>"
    ]
  },
  {
    "objectID": "content/intro-code-of-conduct.html#our-responsibilities",
    "href": "content/intro-code-of-conduct.html#our-responsibilities",
    "title": "Code of Conduct",
    "section": "Our Responsibilities",
    "text": "Our Responsibilities\nProject maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Code of Conduct</span>"
    ]
  },
  {
    "objectID": "content/intro-code-of-conduct.html#scope",
    "href": "content/intro-code-of-conduct.html#scope",
    "title": "Code of Conduct",
    "section": "Scope",
    "text": "Scope\nThis Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Code of Conduct</span>"
    ]
  },
  {
    "objectID": "content/intro-code-of-conduct.html#enforcement",
    "href": "content/intro-code-of-conduct.html#enforcement",
    "title": "Code of Conduct",
    "section": "Enforcement",
    "text": "Enforcement\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. Further details of specific enforcement policies may be posted separately.",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Code of Conduct</span>"
    ]
  },
  {
    "objectID": "content/intro-code-of-conduct.html#attribution",
    "href": "content/intro-code-of-conduct.html#attribution",
    "title": "Code of Conduct",
    "section": "Attribution",
    "text": "Attribution\nThis Code of Conduct is adapted from the Contributor Covenant, version 1.4, available at https://contributor-covenant.org/version/1/4",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Code of Conduct</span>"
    ]
  },
  {
    "objectID": "content/product-intro.html",
    "href": "content/product-intro.html",
    "title": "GAP Production Data",
    "section": "",
    "text": "Data Description\nThe Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC) conducts fisheries-independent bottom trawl surveys to monitor the condition of the demersal fish and crab stocks of Alaska. These data are developed to describe the temporal distribution and abundance of commercially and ecologically important groundfish species, examine the changes in the species composition of the fauna over time and space, and describe the physical environment of the groundfish habitat. These data are created using the gapindex R package v2.1.0.\nUsers must read and fully comprehend the metadata prior to use. Data should not be used beyond the limits of the source scale. Acknowledgement of NOAA, as the source from which these data were obtained, in any publications and/or other representations of these data, is suggested. These data are compiled and approved annually after each summer survey season. The data from previous years are unlikely to change substantially once published. Some survey data are excluded, such as non-standard stations, surveys completed in earlier years using different/non-standard gear, and special tows and non-standard data collections.",
    "crumbs": [
      "GAP Production Data"
    ]
  },
  {
    "objectID": "content/product-intro.html#gapindex",
    "href": "content/product-intro.html#gapindex",
    "title": "GAP Production Data",
    "section": "gapindex",
    "text": "gapindex\nCode to generate design-based catch-per-unit-effort (CPUE), indices of abundance, biomass, and size and age compositions from survey data is avaialble from gapindex. See the gapindex documentation for more information. Make sure you have installed R packages devtools, RODBC, and getPass and are connected to the AFSC network or VPN while using this package.",
    "crumbs": [
      "GAP Production Data"
    ]
  },
  {
    "objectID": "content/product-intro.html#cite-this-data",
    "href": "content/product-intro.html#cite-this-data",
    "title": "GAP Production Data",
    "section": "Cite this data",
    "text": "Cite this data\nUse the below bibtext citation, as cited in our group’s citation repository for citing the data created and maintained in this repository. Add “note = {Accessed: mm/dd/yyyy}” to append the day this data was accessed.\n\n\n[1] \"@misc{GAPProducts,\"                                                                                                       \n[2] \"  author = {{NOAA Fisheries Alaska Fisheries Science Center, Goundfish Assessment Program}},\"                             \n[3] \"  year = {2024}, \"                                                                                                        \n[4] \"  title = {AFSC Goundfish Assessment Program Design-Based Production Data},\"                                              \n[5] \"  howpublished = {https://www.fisheries.noaa.gov/alaska/science-data/groundfish-assessment-program-bottom-trawl-surveys},\"\n[6] \"  publisher = {{U.S. Dep. Commer.}},\"                                                                                     \n[7] \"  copyright = {Public Domain} \"                                                                                           \n[8] \"}\"",
    "crumbs": [
      "GAP Production Data"
    ]
  },
  {
    "objectID": "content/product-metadata.html",
    "href": "content/product-metadata.html",
    "title": "Data description",
    "section": "",
    "text": "Data tables",
    "crumbs": [
      "GAP Production Data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data description</span>"
    ]
  },
  {
    "objectID": "content/product-metadata.html#data-tables",
    "href": "content/product-metadata.html#data-tables",
    "title": "Data description",
    "section": "",
    "text": "AGECOMP\nStratum- and region-level age compositions by sex. This table was created by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). The GitHub repository for the scripts that created this code can be found at (https://github.com/afsc-gap-products/gap_products). There are no legal restrictions on access to the data. Last updated on 22 September 2025.\nNumber of rows: 680,450\nNumber of columns: 10\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code is an integer that uniquely identifies a survey region/survey design. The column survey_definition_id is associated with the srvy and survey columns. Full list of survey definition IDs are in RACE_DATA.SURVEY_DEFINITIONS and in the code books.\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\nAREA_ID\n\n\nArea ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nAn ID code representing a broad range of spatial areas from statistical sampling strata to management and regional areas composed of multiple strata.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the common_name and scientific_name columns. For a complete species list, review the code books.\n\n\n\n\nSEX\n\n\nSex of a specimen\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nSex of a specimen where “1” = “Male”, “2” = “Female”, “3” = Unsexed.\n\n\n\n\nAGE\n\n\nTaxon age bin (yrs)\n\n\ninteger\n\n\nNUMBER(38,0)\n\n\nAge bin of taxon. Age bin of a taxon in years estimated by the age comp estimate. Age -9 indicates unaged lengths for a particular sex because no otoliths were collected for that sex/length combination. Age -99 indicates a case where no lengths were collected within a stratum for a species/year even though catch numbers were recorded.\n\n\n\n\nPOPULATION_COUNT\n\n\nEstimated population\n\n\nnumeric\n\n\nNUMBER(38,0)\n\n\nThe estimated population caught in the survey for a species, group, or total for a given survey.\n\n\n\n\nLENGTH_MM_MEAN\n\n\nMean length at age weighted by numbers at length\n\n\nnumeric\n\n\nNUMBER(38,3)\n\n\nMean length (millimeters).\n\n\n\n\nLENGTH_MM_SD\n\n\nStandard deviation of length at age weighted by numbers at length\n\n\nnumeric\n\n\nNUMBER(38,3)\n\n\nVariance of mean length.\n\n\n\n\nAREA_ID_FOOTPRINT\n\n\nSurvey Footprint\n\n\ntext\n\n\nVARCHAR2(4000 BYTE)\n\n\nSurvey footprint, usually equivalent to the SURVEY_DEFINITION_ID with the exception of the Standard and Standard +NW survey footprints in the Eastern Bering Sea shelf bottom trawl survey.\n\n\n\n\n\n\nAREA\nInformation related to the various strata, subareas, INPFC and NMFS management areas, and regions for the Aleutian Islands, Gulf of Alaska, and Bering Sea shelf and slope bottom trawl surveys. This table was created by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). The GitHub repository for the scripts that created this code can be found at (https://github.com/afsc-gap-products/gap_products). There are no legal restrictions on access to the data. Last updated on 22 September 2025.\nNumber of rows: 499\nNumber of columns: 9\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nDESIGN_YEAR\n\n\nDesign year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear ID associated with a given value AREA_ID. This field describes the changes in the survey design over time.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code is an integer that uniquely identifies a survey region/survey design. The column survey_definition_id is associated with the srvy and survey columns. Full list of survey definition IDs are in RACE_DATA.SURVEY_DEFINITIONS and in the code books.\n\n\n\n\nAREA_ID\n\n\nArea ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nAn ID code representing a broad range of spatial areas from statistical sampling strata to management and regional areas composed of multiple strata.\n\n\n\n\nAREA_TYPE\n\n\nArea ID type description\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nThe type of stratum that AREA_ID represents. Types include: STRATUM (the smallest building-block unit of area in these surveys), REGION, DEPTH, SUBAREA, INPFC BY DEPTH, INPFC, SUBAREA BY DEPTH, REGULATORY AREA, NMFS STATISTICAL AREA.\n\n\n\n\nAREA_NAME\n\n\nArea ID name\n\n\ntext\n\n\nVARCHAR2(4000 BYTE)\n\n\nDescriptive name of each AREA_ID. These names often identify the region, depth ranges, or other regional information for the area ID.\n\n\n\n\nDESCRIPTION\n\n\nDescription\n\n\ntext\n\n\nVARCHAR2(4000 BYTE)\n\n\nDescription of row observation.\n\n\n\n\nAREA_KM2\n\n\nArea (km2)\n\n\nkilometers squared\n\n\nNUMBER(38,3)\n\n\nArea in square kilometers.\n\n\n\n\nDEPTH_MIN_M\n\n\nArea ID minimum depth (m)\n\n\nmeters\n\n\nNUMBER(38,3)\n\n\nMinimum depth (meters).\n\n\n\n\nDEPTH_MAX_M\n\n\nArea ID maximum depth (m)\n\n\nmeters\n\n\nNUMBER(38,3)\n\n\nMaximum depth (meters).\n\n\n\n\n\n\nBIOMASS\nStratum/subarea/region-level mean CPUE (weight and numbers), total biomass, and total abundance with associated variances. This table was created by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). The GitHub repository for the scripts that created this code can be found at (https://github.com/afsc-gap-products/gap_products). There are no legal restrictions on access to the data. Last updated on 22 September 2025.\nNumber of rows: 2,654,421\nNumber of columns: 16\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code is an integer that uniquely identifies a survey region/survey design. The column survey_definition_id is associated with the srvy and survey columns. Full list of survey definition IDs are in RACE_DATA.SURVEY_DEFINITIONS and in the code books.\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the common_name and scientific_name columns. For a complete species list, review the code books.\n\n\n\n\nAREA_ID\n\n\nArea ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nAn ID code representing a broad range of spatial areas from statistical sampling strata to management and regional areas composed of multiple strata.\n\n\n\n\nCPUE_KGKM2_MEAN\n\n\nMean weight CPUE\n\n\nkilograms per kilometers squared\n\n\nNUMBER(38,6)\n\n\nThe mean catch weight (kilograms) per unit effort (area swept by the net, units squared kilometers).\n\n\n\n\nCPUE_NOKM2_MEAN\n\n\nMean numeric CPUE\n\n\ncount per kilometers squared\n\n\nNUMBER(38,6)\n\n\nThe mean of numerical catch per unit effort (area swept by the net, units square kilometers).\n\n\n\n\nN_HAUL\n\n\nValid hauls\n\n\ncount\n\n\nNUMBER(38,0)\n\n\nTotal number of hauls.\n\n\n\n\nN_WEIGHT\n\n\nHauls with catch\n\n\ncount\n\n\nNUMBER(38,0)\n\n\nTotal number of hauls with positive catch biomass.\n\n\n\n\nN_COUNT\n\n\nHauls with taxon counts\n\n\nnumeric\n\n\nNUMBER(38,0)\n\n\nTotal number of hauls with positive count data.\n\n\n\n\nN_LENGTH\n\n\nHauls with taxon lengths\n\n\ncount\n\n\nNUMBER(38,0)\n\n\nTotal number of hauls with length data.\n\n\n\n\nBIOMASS_MT\n\n\nEstimated biomass\n\n\nnumeric\n\n\nNUMBER(38,6)\n\n\nThe estimated total biomass.\n\n\n\n\nBIOMASS_VAR\n\n\nEstimated biomass variance\n\n\nnumeric\n\n\nNUMBER(38,6)\n\n\nThe estimated variance associated with the total biomass.\n\n\n\n\nPOPULATION_COUNT\n\n\nEstimated population\n\n\nnumeric\n\n\nNUMBER(38,0)\n\n\nThe estimated population caught in the survey for a species, group, or total for a given survey.\n\n\n\n\nPOPULATION_VAR\n\n\nEstimated population variance\n\n\nnumeric\n\n\nNUMBER(38,6)\n\n\nThe estimated population variance caught in the survey for a species, group, or total for a given survey.\n\n\n\n\nCPUE_KGKM2_VAR\n\n\nVariance of the mean weight CPUE\n\n\nkilograms per kilometers squared\n\n\nNUMBER(38,6)\n\n\nThe variance of mean catch weight (kilograms) per unit effort (area swept by the net, units squared kilometers).\n\n\n\n\nCPUE_NOKM2_VAR\n\n\nVariance of the mean numeric CPUE\n\n\ncount per kilometers squared\n\n\nNUMBER(38,6)\n\n\nThe variance of mean numerical catch per unit effort (area swept by the net, units square kilometers).\n\n\n\n\n\n\nCPUE\nHaul-level zero-filled weight and numerical catch-per-unit-effort. This table was created by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). The GitHub repository for the scripts that created this code can be found at (https://github.com/afsc-gap-products/gap_products). There are no legal restrictions on access to the data. Last updated on 22 September 2025.\nNumber of rows: 21,558,257\nNumber of columns: 7\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nHAULJOIN\n\n\nHaul ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThis is a unique numeric identifier assigned to each (vessel, cruise, and haul) combination.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the common_name and scientific_name columns. For a complete species list, review the code books.\n\n\n\n\nWEIGHT_KG\n\n\nSample or taxon weight (kg)\n\n\nkilograms\n\n\nNUMBER(38,3)\n\n\nWeight (thousandths of a kilogram) of individuals in a haul by taxon.\n\n\n\n\nCOUNT\n\n\nTaxon count\n\n\ncount, whole number resolution\n\n\nNUMBER(38,0)\n\n\nTotal whole number of individuals caught in haul or samples collected.\n\n\n\n\nAREA_SWEPT_KM2\n\n\nArea swept (km)\n\n\nkilometers\n\n\nNUMBER(38,6)\n\n\nThe area the net covered while the net was fishing (kilometers squared), defined as the distance fished times the net width.\n\n\n\n\nCPUE_KGKM2\n\n\nWeight CPUE (kg/km2)\n\n\nkilograms per kilometers squared\n\n\nNUMBER(38,6)\n\n\nCatch weight (kilograms) per unit effort (area swept by the net, units square kilometers).\n\n\n\n\nCPUE_NOKM2\n\n\nNumber CPUE (no/km2)\n\n\ncount per kilometers squared\n\n\nNUMBER(38,6)\n\n\nNumerical catch per unit effort (area swept by the net, units square kilometers).\n\n\n\n\n\n\nSIZECOMP\nStratum/subarea/region-level size compositions by sex. This table was created by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). The GitHub repository for the scripts that created this code can be found at (https://github.com/afsc-gap-products/gap_products). There are no legal restrictions on access to the data. Last updated on 22 September 2025.\nNumber of rows: 3,234,183\nNumber of columns: 7\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code is an integer that uniquely identifies a survey region/survey design. The column survey_definition_id is associated with the srvy and survey columns. Full list of survey definition IDs are in RACE_DATA.SURVEY_DEFINITIONS and in the code books.\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\nAREA_ID\n\n\nArea ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nAn ID code representing a broad range of spatial areas from statistical sampling strata to management and regional areas composed of multiple strata.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the common_name and scientific_name columns. For a complete species list, review the code books.\n\n\n\n\nLENGTH_MM\n\n\nLength of a specimen\n\n\nmillimeters\n\n\nNUMBER(10,0)\n\n\nLength bin in millimeters. A length of -9 indicates cases where no lengths were collected within a stratum for a species/year, even though catch numbers were recorded.\n\n\n\n\nSEX\n\n\nSex of a specimen\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nSex of a specimen where “1” = “Male”, “2” = “Female”, “3” = Unsexed.\n\n\n\n\nPOPULATION_COUNT\n\n\nEstimated population\n\n\nnumeric\n\n\nNUMBER(38,0)\n\n\nThe estimated population caught in the survey for a species, group, or total for a given survey.\n\n\n\n\n\n\nSPECIES_YEAR\nThis is a table\nNumber of rows: 18\nNumber of columns: 2\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the common_name and scientific_name columns. For a complete species list, review the code books.\n\n\n\n\n\n\nSTRATUM_GROUPS\nLookup table for which strata are contained within a given subarea, INPFC or NMFS management area, or region for the Aleutian Islands, Gulf of Alaska, and Bering Sea shelf and slope bottom trawl surveys. This table was created by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). The GitHub repository for the scripts that created this code can be found at (https://github.com/afsc-gap-products/gap_products). There are no legal restrictions on access to the data. Last updated on 22 September 2025.\nNumber of rows: 1,063\nNumber of columns: 4\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAREA_ID\n\n\nArea ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nAn ID code representing a broad range of spatial areas from statistical sampling strata to management and regional areas composed of multiple strata.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code is an integer that uniquely identifies a survey region/survey design. The column survey_definition_id is associated with the srvy and survey columns. Full list of survey definition IDs are in RACE_DATA.SURVEY_DEFINITIONS and in the code books.\n\n\n\n\nDESIGN_YEAR\n\n\nDesign year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear ID associated with a given value AREA_ID. This field describes the changes in the survey design over time.\n\n\n\n\nSTRATUM\n\n\nStratum ID\n\n\nID key code\n\n\nNUMBER(10,0)\n\n\nRACE database statistical area for analyzing data. Strata were designed using bathymetry and other geographic and habitat-related elements. The strata are unique to each survey region. Stratum of value 0 indicates experimental tows.\n\n\n\n\n\n\nSURVEY_DESIGN\nThis table contains for a given survey (via SURVEY_DEFINITION_ID) and survey year (YEAR), which version (DESIGN_YEAR) of the AREA_IDs that were used to calculate the various standard data products. This table was created by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). The GitHub repository for the scripts that created this code can be found at (https://github.com/afsc-gap-products/gap_products). There are no legal restrictions on access to the data. Last updated on 22 September 2025.\nNumber of rows: 87\nNumber of columns: 3\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code is an integer that uniquely identifies a survey region/survey design. The column survey_definition_id is associated with the srvy and survey columns. Full list of survey definition IDs are in RACE_DATA.SURVEY_DEFINITIONS and in the code books.\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\nDESIGN_YEAR\n\n\nDesign year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear ID associated with a given value AREA_ID. This field describes the changes in the survey design over time.\n\n\n\n\n\n\nTAXON_GROUPS\nGAP_PRODUCTS.TAXONOMIC_CLASSIFICATION subsetted for taxonomic classifications accepted by the GAP bottom trawl survey and added GROUP_CODE to denote taxonomic aggregations. This table was created by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). The GitHub repository for the scripts that created this code can be found at (https://github.com/afsc-gap-products/gap_products). There are no legal restrictions on access to the data. Last updated on 25 October 2024.\nNumber of rows: 2,777\nNumber of columns: 22\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the common_name and scientific_name columns. For a complete species list, review the code books.\n\n\n\n\nSPECIES_NAME\n\n\nScientific name of species\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nScientific name of species.\n\n\n\n\nCOMMON_NAME\n\n\nTaxon common name\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nThe common name of the marine organism associated with the scientific_name and species_code columns. For a complete species list, review the code books.\n\n\n\n\nID_RANK\n\n\nLowest taxonomic rank\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nLowest taxonomic rank of a given species entry.\n\n\n\n\nDATABASE\n\n\nDatabase source\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nTaxonomic database source, either ITIS or WoRMS.\n\n\n\n\nDATABASE_ID\n\n\nSpecies ID in database\n\n\nID key code\n\n\nVARCHAR2(255 BYTE)\n\n\nSpecies ID key code of a species in the taxonomic “DATABASE” source.\n\n\n\n\nGENUS_TAXON\n\n\nGenus phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of genus of a given species.\n\n\n\n\nSUBFAMILY_TAXON\n\n\nSubfamily phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of subfamily of a given species.\n\n\n\n\nFAMILY_TAXON\n\n\nFamily phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of family of a given species.\n\n\n\n\nSUPERFAMILY_TAXON\n\n\nSuperfamily phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of superfamily of a given species.\n\n\n\n\nINFRAORDER_TAXON\n\n\nInfraorder phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nInfraorder phylogenetic rank. Phylogenetic latin rank of infraorder of a given speices.\n\n\n\n\nSUBORDER_TAXON\n\n\nSuborder phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of suborder of a given species.\n\n\n\n\nORDER_TAXON\n\n\nOrder phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of order of a given species.\n\n\n\n\nSUPERORDER_TAXON\n\n\nSuperorder phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of superorder of a given species.\n\n\n\n\nINFRACLASS_TAXON\n\n\nInfraclass phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nInfraclass phylogenetic rank. Phylogenetic latin rank of infraclass of a given speices.\n\n\n\n\nSUBCLASS_TAXON\n\n\nSubclass phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of subclass of a given species.\n\n\n\n\nCLASS_TAXON\n\n\nClass phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of class of a given species.\n\n\n\n\nSUPERCLASS_TAXON\n\n\nSuperclass phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of superclass of a given species.\n\n\n\n\nSUBPHYLUM_TAXON\n\n\nSubphylum phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of subphylum of a given species.\n\n\n\n\nPHYLUM_TAXON\n\n\nPhylum phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of phylum of a given species.\n\n\n\n\nKINGDOM_TAXON\n\n\nKingdom phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of kingdom of a given species.\n\n\n\n\nGROUP_CODE\n\n\nSpecies or Complex ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nEquivalent to the SPECIES_CODE if the taxon is reported as a single taxon in GAP_PRODUCTS, otherwise denotes a SPECIES_CODE of a higher taxonomic group to which the taxon is aggregated in the GAP_PRODUCTS CPUE and BIOMASS tables.",
    "crumbs": [
      "GAP Production Data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data description</span>"
    ]
  },
  {
    "objectID": "content/product-metadata-column.html",
    "href": "content/product-metadata-column.html",
    "title": "Universal Column Metadata",
    "section": "",
    "text": "This table is used to string together the various field comments for the tables in GAP_PRODUCTS. This table was created by the Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC). The GitHub repository for the scripts that created this code can be found at (https://github.com/afsc-gap-products/gap_products). There are no legal restrictions on access to the data. Last updated on 22 September 2025.\n\n\nUniversal stock metadata that users can use to document their table\ncolumns.Column name from dataDescriptive column NameUnitsOracle data typeColumn descriptionABUNDANCE_HAULDesign-based index approved haullogicalVARCHAR2(255 BYTE)Logical, describing if this haul was conducted in a standard manner and thus used for design-based index estimates (TRUE) or not (FALSE).ACCESSORIESType of gear accessories used on the netID key codeNUMBER(38,0)Type of accessories used on net. For a complete list of accessories ID key codes, review the [code books](https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual).ACTIONDatabase actiontextVARCHAR2(255 BYTE)Standard action taken to alter current database recordACTIVEVessel active/inactivelogicalVARCHAR2(255 BYTE)Logical, describing if a vessel is active (TRUE) or not (FALSE).AGETaxon age bin (yrs)integerNUMBER(38,0)Age bin of taxon. Age bin of a taxon in years estimated by the age comp estimate. Age -9 indicates unaged lengths for a particular sex because no otoliths were collected for that sex/length combination. Age -99 indicates a case where no lengths were collected within a stratum for a species/year even though catch numbers were recorded.AGENCY_ACRONYMAcronym of listed Agencytext abbreviatedVARCHAR2(255 BYTE)Abbreviated agencies that are affiliated with the Alaska bottom trawl survey. The column agency_acronym is associated with the agency_short and agency_long columns.AGENCY_JOINAgency IDID key codeNUMBER(38,0)Affiliated agency ID key code.AGENCY_LONGOfficial name of agencytextVARCHAR2(255 BYTE)Full official name of affiliated agencies to the Alaska bottom trawl survey. The column agency_long is associated with the agency_acronym and agency_short columns.AGENCY_SHORTAgency shorthand nametextVARCHAR2(255 BYTE)A sort version of the full official name of affiliated agencies to the Alaska bottom trawl survey. The column agency_short is associated with the agency_acronym and agency_long columns.AGE_DETERMINATION_METHODAging methodID key codeNUMBER(10,0)Numeric code corresponding to the method of age determination. For a complete list of age determination codes, review the [code books](https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual).AGE_DETERMINATION_METHODSAge determination methodID key codeNUMBER(38,0)A unique ID used to identify this age determination method.AGE_YEARAge bin of taxonyearNUMBER(38,0)Age bin of a taxon in years estimated by the age comp estimate.AREAJOINArea polygon IDID key codeNUMBER(38,0)A call sign is a designated sequence of letters and numbers that are assigned when a vessel, whether it be a sailing yacht, motor yacht, rib or commercial vessel, receives its Ship Radio Licence. The vessel also receives its MMSI number, so that each vessel is uniquely identified.AREA_IDArea IDID key codeNUMBER(38,0)An ID code representing a broad range of spatial areas from statistical sampling strata to management and regional areas composed of multiple strata.AREA_ID_FOOTPRINTSurvey FootprinttextVARCHAR2(4000 BYTE)Survey footprint, usually equivalent to the SURVEY_DEFINITION_ID with the exception of the Standard and Standard +NW survey footprints in the Eastern Bering Sea shelf bottom trawl survey.AREA_KM2Area (km2)kilometers squaredNUMBER(38,3)Area in square kilometers.AREA_NAMEArea ID nametextVARCHAR2(4000 BYTE)Descriptive name of each AREA_ID. These names often identify the region, depth ranges, or other regional information for the area ID.AREA_SWEPT_KM2Area swept (km)kilometersNUMBER(38,6)The area the net covered while the net was fishing (kilometers squared), defined as the distance fished times the net width.AREA_TYPEArea ID type descriptioncategoryVARCHAR2(255 BYTE)The type of stratum that AREA_ID represents. Types include: STRATUM (the smallest building-block unit of area in these surveys), REGION, DEPTH, SUBAREA, INPFC BY DEPTH, INPFC, SUBAREA BY DEPTH, REGULATORY AREA, NMFS STATISTICAL AREA.BIOMASS_MTEstimated biomassnumericNUMBER(38,6)The estimated total biomass.BIOMASS_VAREstimated biomass variancenumericNUMBER(38,6)The estimated variance associated with the total biomass.BOTTOM_TEMPERATURE_CBottom temperature (degrees Celsius)degrees CelsiusNUMBER(38,1)Bottom temperature (tenths of a degree Celsius); NA indicates removed or missing values.BOTTOM_TYPESeafloor bottom type codeID key codeNUMBER(38,0)Bottom type on sea floor at haul location. For a complete list of bottom type ID key codes, review the [code books](https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual).CATALOG_NUMCatalog numbertextVARCHAR2(255 BYTE)Museum catalog number associated with recordCATCHJOINCatch observation IDID key codeNUMBER(38,0)Unique integer ID assigned to each survey, vessel, year, and catch observation combination.CLASSIFICATIONTaxonomic classification rank groupcategoryVARCHAR2(255 BYTE)Phylogenetic classification group rank for a given species.CLASS_TAXONClass phylogenetic rankcategoryVARCHAR2(255 BYTE)Phylogenetic latin rank of class of a given species.COLLECTED_BYPerson who collected specimentextVARCHAR2(255 BYTE)Initials of person who collected specimen in the fieldCOMMENTSCommentstextVARCHAR2(4000 BYTE)Comments regarding row observation.COMMON_NAMETaxon common nametextVARCHAR2(255 BYTE)The common name of the marine organism associated with the scientific_name and species_code columns. For a complete species list, review the [code books](https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual).COUNTTaxon countcount, whole number resolutionNUMBER(38,0)Total whole number of individuals caught in haul or samples collected.COUNTRY_IDCountry codeID key codeNUMBER(38,0)Country ID key code of where a vessel, for example, may be from. For a complete list of country ID key codes, review the [code books](https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual).CPUE_KGHAWeight CPUE (kg/ha)kilograms per hectareNUMBER(38,6)Catch weight (kilograms) per unit effort (area swept by the net, units hectares).CPUE_KGKM2Weight CPUE (kg/km2)kilograms per kilometers squaredNUMBER(38,6)Catch weight (kilograms) per unit effort (area swept by the net, units square kilometers).CPUE_KGKM2_MEANMean weight CPUEkilograms per kilometers squaredNUMBER(38,6)The mean catch weight (kilograms) per unit effort (area swept by the net, units squared kilometers).CPUE_KGKM2_VARVariance of the mean weight CPUEkilograms per kilometers squaredNUMBER(38,6)The variance of mean catch weight (kilograms) per unit effort (area swept by the net, units squared kilometers).CPUE_NOHANumber CPUE (no/ha)count per hectareNUMBER(38,6)Numerical catch per unit effort (area swept by the net, units hectares).CPUE_NOKM2Number CPUE (no/km2)count per kilometers squaredNUMBER(38,6)Numerical catch per unit effort (area swept by the net, units square kilometers).CPUE_NOKM2_MEANMean numeric CPUEcount per kilometers squaredNUMBER(38,6)The mean of numerical catch per unit effort (area swept by the net, units square kilometers).CPUE_NOKM2_VARVariance of the mean numeric CPUEcount per kilometers squaredNUMBER(38,6)The variance of mean numerical catch per unit effort (area swept by the net, units square kilometers).CRSCoordinate reference systemID key codeVARCHAR2(255 BYTE)The coordinate reference system (CRS) that shapefiles were created in or areas (like AREA_KM2) are calculated in, as defined by https://spatialreference.org/ (e.g., \"+proj=longlat\", \"EPSG:3338\").CRUISECruise NameID key codeNUMBER(38,0)This is a six-digit integer identifying the cruise number of the form: YYYY99 (where YYYY = year of the cruise; 99 = 2-digit number and is sequential; 01 denotes the first cruise that vessel made in this year, 02 is the second, etc.).CRUISEJOINCruise IDID key codeNUMBER(38,0)Unique integer ID assigned to each survey, vessel, and year combination.DATABASEDatabase sourcecategoryVARCHAR2(255 BYTE)Taxonomic database source, either ITIS or WoRMS.DATABASE_IDSpecies ID in databaseID key codeVARCHAR2(255 BYTE)Species ID key code of a species in the taxonomic \"DATABASE\" source.DATEDateYYYY-MM-DDDATEThe date (YYYY-MM-DD) of the event (e.g., cruise).DATE_ENDEnd dateYYYY-MM-DDDATEThe date (YYYY-MM-DD) of the end of the event (e.g., cruise).DATE_STARTStart dateYYYY-MM-DDDATEThe date (YYYY-MM-DD) of the beginning of the event (e.g., cruise).DATE_TIMEDate and timeMM/DD/YYYY HH::MMDATEThe date (MM/DD/YYYY) and time (HH:MM) of the haul. All dates and times are in Alaska time (AKDT) of Anchorage, AK, USA (UTC/GMT -8 hours).DATE_TIME_ENDEnd date and timeMM/DD/YYYY HH::MMTIMESTAMPThe date (MM/DD/YYYY) and time (HH:MM) of the end of the haul. All dates and times are in Alaska time (AKDT) of Anchorage, AK, USA (UTC/GMT -8 hours).DATE_TIME_STARTStart date and timeMM/DD/YYYY HH::MMTIMESTAMPThe date (MM/DD/YYYY) and time (HH:MM) of the beginning of the haul. All dates and times are in Alaska time (AKDT) of Anchorage, AK, USA (UTC/GMT -8 hours).DEPTH_GEAR_MDepth of gear (m)degrees CelsiusNUMBER(38,1)Depth of gear (meters).DEPTH_MDepth (m)degrees CelsiusNUMBER(38,1)Bottom depth (meters).DEPTH_MAX_MArea ID maximum depth (m)metersNUMBER(38,3)Maximum depth (meters).DEPTH_MIN_MArea ID minimum depth (m)metersNUMBER(38,3)Minimum depth (meters).DESCRIPTIONDescriptiontextVARCHAR2(4000 BYTE)Description of row observation.DESIGN_YEARDesign yearyearNUMBER(10,0)Year ID associated with a given value AREA_ID. This field describes the changes in the survey design over time.DISTANCE_FISHED_KMDistance fished (km)kilometersNUMBER(38,3)Distance the net fished (kilometers).DUMMYdummydummyVARCHAR2(255 BYTE)dummy.DURATION_HRTow duration (decimal hr)hoursNUMBER(38,1)This is the elapsed time between start and end of a haul (decimal hours).FAMILY_TAXONFamily phylogenetic rankcategoryVARCHAR2(255 BYTE)Phylogenetic latin rank of family of a given species.FIELD_IDField specimen identificationtextVARCHAR2(255 BYTE)Field identification for the vouchered specimenFREQUENCYCount of observationcountNUMBER(38,0)Frequency, or count, of an observation.GEARType of gear used on the netID key codeNUMBER(38,0)Type of gear used on net. For a complete list of gear ID key codes, review the [code books](https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual).GEAR_DEPTH_MGear depthmetersNUMBER(38,1)Depth gear was deployed at (tenths of a meter). Gear depth plus net height equals bottom depth.GEAR_IDGear IDID key codeNUMBER(38,0)Type of trawl or gear deployed. For a complete list of vessel gear type ID key codes, review the [code books](https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual).GEAR_TEMPERATURE_CGear temperature (degrees Celsius)degrees CelsiusNUMBER(38,1)Temperature recorded by net gear (tenths of a degree Celsius); NA indicates removed or missing values.GENUS_TAXONGenus phylogenetic rankcategoryVARCHAR2(255 BYTE)Phylogenetic latin rank of genus of a given species.GEOMETRYSpatial geometrytextVARCHAR2(255 BYTE)Spatial geometry information (like points, lines, or polygons) a feature.GONAD_GWeight of gonads (g)gramsNUMBER(38,1)Weight of specimen gonads (grams).GROUP_CODESpecies or Complex IDID key codeNUMBER(38,0)Equivalent to the SPECIES_CODE if the taxon is reported as a single taxon in GAP_PRODUCTS, otherwise denotes a SPECIES_CODE of a higher taxonomic group to which the taxon is aggregated in the GAP_PRODUCTS CPUE and BIOMASS tables.HAULHaul numberID key codeNUMBER(38,0)This number uniquely identifies a sampling event (haul) within a cruise. It is a sequential number, in chronological order of occurrence.HAULJOINHaul IDID key codeNUMBER(38,0)This is a unique numeric identifier assigned to each (vessel, cruise, and haul) combination.HAUL_TYPEHaul sampling typeID key codeNUMBER(38,0)Type of haul sampling method. For a complete list of haul type ID key codes, review the [code books](https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual).ID_RANKLowest taxonomic ranktextVARCHAR2(255 BYTE)Lowest taxonomic rank of a given species entry.INFRACLASS_TAXONInfraclass phylogenetic rankcategoryVARCHAR2(255 BYTE)Infraclass phylogenetic rank. Phylogenetic latin rank of infraclass of a given speices.INFRAORDER_TAXONInfraorder phylogenetic rankcategoryVARCHAR2(255 BYTE)Infraorder phylogenetic rank. Phylogenetic latin rank of infraorder of a given speices.ITISIntegrated taxonomic information system (ITIS) serial numberID key codeNUMBER(38,0)Species code as identified in the Integrated Taxonomic Information System (https://itis.gov/).KINGDOM_TAXONKingdom phylogenetic rankcategoryVARCHAR2(255 BYTE)Phylogenetic latin rank of kingdom of a given species.LATITUDE_DDLatitude (decimal degrees)decimal degreesNUMBER(38,6)Latitude (one hundred thousandth of a decimal degree).LATITUDE_DD_ENDEnd latitude (decimal degrees)decimal degreesNUMBER(38,6)Latitude (one hundred thousandth of a decimal degree) of the end of the haul.LATITUDE_DD_STARTStart latitude (decimal degrees)decimal degreesNUMBER(38,6)Latitude (one hundred thousandth of a decimal degree) of the start of the haul.LENGTH_MMLength of a specimenmillimetersNUMBER(10,0)Length bin in millimeters. A length of -9 indicates cases where no lengths were collected within a stratum for a species/year, even though catch numbers were recorded.LENGTH_MM_MEANMean length at age weighted by numbers at lengthnumericNUMBER(38,3)Mean length (millimeters).LENGTH_MM_SDStandard deviation of length at age weighted by numbers at lengthnumericNUMBER(38,3)Variance of mean length.LENGTH_TYPELength typeID key codeNUMBER(38,0)How the taxon was measured (e.g., fork length, carapace width). For a complete list of length_type ID key codes, review the [code books](https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual).LONGITUDE_DDLongitude (decimal degrees)decimal degreesNUMBER(38,6)Longitude (one hundred thousandth of a decimal degree).LONGITUDE_DD_ENDEnd longitude (decimal degrees)decimal degreesNUMBER(38,6)Longitude (one hundred thousandth of a decimal degree) of the end of the haul.LONGITUDE_DD_STARTStart longitude (decimal degrees)decimal degreesNUMBER(38,6)Longitude (one hundred thousandth of a decimal degree) of the start of the haul.MATURITYSpecimen maturity codeID key codeNUMBER(38,0)The maturity code or the condition identified by the maturity code.METADATA_COLNAMEColumn nametextVARCHAR2(4000 BYTE)Name of the column in a table.METADATA_COLNAME_DESCColumn descriptiontextVARCHAR2(4000 BYTE)Description of the column.METADATA_COLNAME_LONGColumn name spelled outtextVARCHAR2(4000 BYTE)Long name for the column.METADATA_DATATYPEOracle datatype codetextVARCHAR2(4000 BYTE)Oracle data type of data column.METADATA_SENTENCESentencetextVARCHAR2(4000 BYTE)Table metadata sentence.METADATA_SENTENCE_NAMEMetadata sentence nametextVARCHAR2(4000 BYTE)Name of table metadata sentence.METADATA_SENTENCE_TYPESentence typetextVARCHAR2(4000 BYTE)Type of sentence to have in table metadata.METADATA_UNITSUnitscategoryVARCHAR2(4000 BYTE)Units of the column.NET_HEIGHT_MNet height (m)metersNUMBER(38,1)Measured or estimated distance (meters) between footrope and headrope of the trawl.NET_MEASUREDNet measured during haullogicalBINARY_DOUBLELogical, describing if the net was measured (TRUE) or not (FALSE) by wheelhouse and marport programs during the haul.NET_WIDTH_MNet width (m)metersNUMBER(38,1)Measured or estimated distance (meters) between wingtips of the trawl.NEW_IDNew specimen identificationtextVARCHAR2(255 BYTE)Confirmed taxonomist identification of the vouchered specimenNEW_SPECIES_CODENew species codeID key codeNUMBER(10,0)Species code associated with new species nameNEW_SPECIES_NAMENew species nametextVARCHAR2(255 BYTE)Updated taxonomic nameN_COUNTHauls with taxon countsnumericNUMBER(38,0)Total number of hauls with positive count data.N_HAULValid haulscountNUMBER(38,0)Total number of hauls.N_LENGTHHauls with taxon lengthscountNUMBER(38,0)Total number of hauls with length data.N_SAMPLEHauls with samplecountNUMBER(38,0)Total number of hauls with positive sample collection.N_SPECIMENSNumber of specimens in the lotcountNUMBER(38,0)Number of specimens in the voucher lotN_WEIGHTHauls with catchcountNUMBER(38,0)Total number of hauls with positive catch biomass.OLD_SPECIES_CODEOld species codeID key codeNUMBER(10,0)Species code associated with old species nameOLD_SPECIES_NAMEOld species nametextVARCHAR2(255 BYTE)Taxonomic name previously used in the databaseORDER_TAXONOrder phylogenetic rankcategoryVARCHAR2(255 BYTE)Phylogenetic latin rank of order of a given species.PERFORMANCEHaul performance codecategoryNUMBER(38,0)This denotes what, if any, issues arose during the haul. For more information, review the [code books](https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual).PHYLUM_TAXONPhylum phylogenetic rankcategoryVARCHAR2(255 BYTE)Phylogenetic latin rank of phylum of a given species.POLYGON_WKBPolygon binary stringcode stringVARCHAR2(255 BYTE)Well-known binary (WKB) representation of geometry for a AREA_JOIN polygon. WKB is used to transfer and store the same information in a more compact form convenient for computer processing but that is not human-readable.POLYGON_WKTPolygon well known textcode stringVARCHAR2(255 BYTE)Well-known text (WKT) representation of geometry for a AREA_JOIN polygon. WKT is a text markup language for representing vector geometry objects.POPULATION_COUNTEstimated populationnumericNUMBER(38,0)The estimated population caught in the survey for a species, group, or total for a given survey.POPULATION_VAREstimated population variancenumericNUMBER(38,6)The estimated population variance caught in the survey for a species, group, or total for a given survey.PRESERVATIVEChemical specimen stored intextVARCHAR2(255 BYTE)Chemical specimen currently stored inPRINCIPAL_INVESTIGATORPrinciple investigatortextVARCHAR2(255 BYTE)First and last name of principal investigator for a project.PROJECT_TITLETitle of special projecttextVARCHAR2(255 BYTE)Special project title.PROJECT_TITLE_SHORTShort title of special projecttextVARCHAR2(255 BYTE)Special project short title (short version of PROJECT_TITLE).RANK_IDTaxonomic rankcategoryVARCHAR2(255 BYTE)The taxonomic rank of a taxon identification.REASONReason for taxonomic changetextVARCHAR2(255 BYTE)Reason for taxonomic change; pulled directly from online database (i.e. WoRMS or ITIS)SAMPLE_TYPESample typeID key codeNUMBER(38,0)Sampling information on how the taxon was sampled. For a complete list of length_type ID key codes, review the [code books](https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual).SCIENTIFIC_NAMETaxon scientific nametextVARCHAR2(255 BYTE)The scientific name of the organism associated with the common_name and species_code columns. For a complete taxon list, review the [code books](https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual).SEXSex of a specimenID key codeNUMBER(38,0)Sex of a specimen where \"1\" = \"Male\", \"2\" = \"Female\", \"3\" = Unsexed.SPECIES_CODETaxon codeID key codeNUMBER(38,0)The species code of the organism associated with the common_name and scientific_name columns. For a complete species list, review the [code books](https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual).SPECIES_NAMEScientific name of speciestextVARCHAR2(255 BYTE)Scientific name of species.SPECIES_NAME_ACCEPTEDScientific name used in taxonomic databasetextVARCHAR2(255 BYTE)Scientific name of species used in taxonomic \"DATABASE\" column.SPECIES_NAME_SURVEYScientific name used in survey datatextVARCHAR2(255 BYTE)Scientific name of species historically or currently used in the survey.SPECIMEN_IDSpecimen unique IDID key codeNUMBER(38,0)Each individual examined must have a number assigned to it that is unique within each haul (0001 to 9999), though specimen numbers may be repeated between haulsSPECIMEN_SAMPLE_TYPESpecimen sample typeID key codeNUMBER(38,0)The specimen sample type ID key code as defined in the RACE_DATA.SPECIMEN_SAMPLE_TYPES table. For a complete list of Specimen sample type ID key codes, review the [code books](https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual).SPECIMEN_SUBSAMPLE_METHODSpecimen subsample methodID key codeNUMBER(38,0)For a complete list of specimen subsample method ID key codes, review the [code books](https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual).SRVYSurvey abbreviationtext abbreviatedVARCHAR2(255 BYTE)Abbreviated survey names. The column srvy is associated with the survey and survey_definition_id columns. Northern Bering Sea (NBS), Southeastern Bering Sea (EBS), Bering Sea Slope (BSS), Gulf of Alaska (GOA), Aleutian Islands (AI).STANDARD_LENGTH_MMStandard length of specimens (mm)numericVARCHAR2(255 BYTE)Standard length of specimen or range of lengths if multiple specimens in lot; measured by taxonomists in labSTATIONStation IDID key codeVARCHAR2(255 BYTE)Alpha-numeric designation for the station established in the design of a survey.STRATUMStratum IDID key codeNUMBER(10,0)RACE database statistical area for analyzing data. Strata were designed using bathymetry and other geographic and habitat-related elements. The strata are unique to each survey region. Stratum of value 0 indicates experimental tows.SUBCLASS_TAXONSubclass phylogenetic rankcategoryVARCHAR2(255 BYTE)Phylogenetic latin rank of subclass of a given species.SUBFAMILY_TAXONSubfamily phylogenetic rankcategoryVARCHAR2(255 BYTE)Phylogenetic latin rank of subfamily of a given species.SUBMISSION_DATEDateYYYY-MM-DDDATEDate special projects were due to be submitted for the upcoming survey season.SUBORDER_TAXONSuborder phylogenetic rankcategoryVARCHAR2(255 BYTE)Phylogenetic latin rank of suborder of a given species.SUBPHYLUM_TAXONSubphylum phylogenetic rankcategoryVARCHAR2(255 BYTE)Phylogenetic latin rank of subphylum of a given species.SUPERCLASS_TAXONSuperclass phylogenetic rankcategoryVARCHAR2(255 BYTE)Phylogenetic latin rank of superclass of a given species.SUPERFAMILY_TAXONSuperfamily phylogenetic rankcategoryVARCHAR2(255 BYTE)Phylogenetic latin rank of superfamily of a given species.SUPERORDER_TAXONSuperorder phylogenetic rankcategoryVARCHAR2(255 BYTE)Phylogenetic latin rank of superorder of a given species.SURFACE_TEMPERATURE_CSurface temperature (degrees Celsius)degrees CelsiusNUMBER(38,1)Surface temperature (tenths of a degree Celsius); NA indicates removed or missing values.SURVEYSurvey nametextVARCHAR2(255 BYTE)Name and description of survey. The column survey is associated with the srvy and survey_definition_id columns.SURVEY_DEFINITION_IDSurvey IDID key codeNUMBER(38,0)The survey definition ID key code is an integer that uniquely identifies a survey region/survey design. The column survey_definition_id is associated with the srvy and survey columns. Full list of survey definition IDs are in RACE_DATA.SURVEY_DEFINITIONS and in the [code books](https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual).SURVEY_IDSurvey ID rawID key codeNUMBER(38,0)The survey ID uniquely identifies a survey instance.SURVEY_NAMESurvey name officialtextVARCHAR2(255 BYTE)Long name of the survey conductedSURVEY_SPECIESSpecies used in surveylogicalBINARY_DOUBLEDesignates whether or not species name is accepted/actively used in the RACE surveysTAXONOMISTTaxonomisttextVARCHAR2(255 BYTE)Taxonomist(s) who re-identified specimen(s)TAXON_CONFIDENCETaxon confidence ratingcategoryVARCHAR2(255 BYTE)Confidence in the ability of the survey team to correctly identify the taxon to the specified level, based solely on identification skill (e.g., not likelihood of a taxon being caught at that station on a location-by-location basis). Quality codes follow: **High**: High confidence and consistency. Taxonomy is stable and reliable at this level, and field identification characteristics are well known and reliable. **Moderate**: Moderate confidence. Taxonomy may be questionable at this level, or field identification characteristics may be variable and difficult to assess consistently. **Low**: Low confidence. Taxonomy is incompletely known, or reliable field identification characteristics are unknown. Documentation: [Species identification confidence in the eastern Bering Sea shelf survey (1982-2008)](http://apps-afsc.fisheries.noaa.gov/Publications/ProcRpt/PR2009-04.pdf), [Species identification confidence in the eastern Bering Sea slope survey (1976-2010)](http://apps-afsc.fisheries.noaa.gov/Publications/ProcRpt/PR2014-05.pdf), and [Species identification confidence in the Gulf of Alaska and Aleutian Islands surveys (1980-2011)](http://apps-afsc.fisheries.noaa.gov/Publications/ProcRpt/PR2014-01.pdf).TAXON_CONFIDENCE_CODETaxon confidence ratingcategoryNUMBER(38,0)Confidence in the ability of the survey team to correctly identify the taxon to the specified level, based solely on identification skill (e.g., not likelihood of a taxon being caught at that station on a location-by-location basis). Quality codes follow: **High**: High confidence and consistency. Taxonomy is stable and reliable at this level, and field identification characteristics are well known and reliable. **Moderate**: Moderate confidence. Taxonomy may be questionable at this level, or field identification characteristics may be variable and difficult to assess consistently. **Low**: Low confidence. Taxonomy is incompletely known, or reliable field identification characteristics are unknown. Documentation: [Species identification confidence in the eastern Bering Sea shelf survey (1982-2008)](http://apps-afsc.fisheries.noaa.gov/Publications/ProcRpt/PR2009-04.pdf), [Species identification confidence in the eastern Bering Sea slope survey (1976-2010)](http://apps-afsc.fisheries.noaa.gov/Publications/ProcRpt/PR2014-05.pdf), and [Species identification confidence in the Gulf of Alaska and Aleutian Islands surveys (1980-2011)](http://apps-afsc.fisheries.noaa.gov/Publications/ProcRpt/PR2014-01.pdf).TRAWLABLETrawlable stationslogicalBINARY_DOUBLELogical, describing if stations are trawlable (TRUE) or not (FALSE).VESSEL_CALLSIGNVessel call signID key codeNUMBER(38,0)A call sign is a designated sequence of letters and numbers that are assigned when a vessel, whether it be a sailing yacht, motor yacht, rib or commercial vessel, receives its Ship Radio Licence. The vessel also receives its MMSI number, so that each vessel is uniquely identified.VESSEL_COAST_GUARD_NUMBERVessel coast guard numberID key codeNUMBER(38,0)Official Identification number as defined by www.dco.uscg.mil. The Official Number (O/N) is the 6 or 7 digit number awarded to the vessel at the time it is first documented with the US Coast Guard. This number remains with the vessel indefinitely and should be marked in accordance with 46 CFR 67.121.VESSEL_IDVessel IDID key codeNUMBER(38,0)ID number of the vessel used to collect data for that haul. The column vessel_id is associated with the vessel_name column. Note that it is possible for a vessel to have a new name but the same vessel id number. For a complete list of vessel ID key codes, review the [code books](https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual).VESSEL_IMOVessel international maritime organization numberID key codeNUMBER(38,0)The International Maritime Organization (IMO) number consists of the letters \"IMO\" followed by a unique, seven-digit number: the pattern is \"NNNNNNN\", where N is a single-digit number, e.g., \"1234567\"VESSEL_LENGTH_MVessel length (m)metersNUMBER(38,0)The length of vessel in meters.VESSEL_MMSIVessel maritime mobile service identitiesID key codeNUMBER(38,0)Maritime Mobile Service Identities (MMSIs) are nine-digit numbers used by maritime digital selective calling (DSC), automatic identification systems (AIS) and certain other equipment to uniquely identify a ship or a coast radio station.VESSEL_NAMEVessel nametextVARCHAR2(255 BYTE)Name of the vessel used to collect data for that haul. The column vessel_name is associated with the vessel_id column. Note that it is possible for a vessel to have a new name but the same vessel id number. For a complete list of vessel ID key codes, review the [code books](https://www.fisheries.noaa.gov/resource/document/groundfish-survey-species-code-manual-and-data-codes-manual).VESSEL_OWNERVessel ownertextVARCHAR2(255 BYTE)Name of vessel owner or company.VESSEL_TONNAGEVessel tonnagemetric tonsNUMBER(38,0)The tonnage of vessel in metric tons.VOUCHERVoucher numbernumericNUMBER(38,0)The voucher number of the specimen within a single haulWEIGHT_GSpecimen weight (g)gramsNUMBER(38,1)Weight of specimen (grams).WEIGHT_KGSample or taxon weight (kg)kilogramsNUMBER(38,3)Weight (thousandths of a kilogram) of individuals in a haul by taxon.WIRE_LENGTH_MTrawl wire lengthmetersNUMBER(38,0)Length of wire deployed during a given haul in meters.WORMSWorld register of marine species (WoRMS) taxonomic serial numberID key codeNUMBER(38,0)Species code as identified in the World Register of Marine Species (WoRMS) (https://www.marinespecies.org/).YEARSurvey yearyearNUMBER(10,0)Year the observation (survey) was collected.YEAR_CHANGEDYear changednumericDATEYear change implemented in database",
    "crumbs": [
      "GAP Production Data",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Universal Column Metadata</span>"
    ]
  },
  {
    "objectID": "content/akfin-intro.html",
    "href": "content/akfin-intro.html",
    "title": "AKFIN",
    "section": "",
    "text": "The Alaska Fisheries Information Network\nThese data are used directly by stock assessors and are provided to The Alaska Fisheries Information Network (AKFIN).\nThe Alaska Fisheries Information Network (AKFIN) is a regional program that consolidates and supports the processing, analysis, and reporting of fisheries data for Alaskan fisheries. AKFIN integrates this information into a single data management system using consistent methods and standardized formats. The resulting data enables fishery managers, scientists, and associated agencies to supervise fisheries resources more effectively and efficiently. The AKFIN database contains much of the data needed to complete stock assessments, including GAP trawl survey data.",
    "crumbs": [
      "AKFIN"
    ]
  },
  {
    "objectID": "content/akfin-intro.html#data-access-options",
    "href": "content/akfin-intro.html#data-access-options",
    "title": "AKFIN",
    "section": "Data Access Options",
    "text": "Data Access Options\nDirect database connection If you are an AFSC employee you may access the AKFIN oracle database directly while on the NOAA network or VPN. Note that this is a separate database from the AFSC oracle database referenced above, and requires separate credentials. If you do not already have an AKFIN account you can request one here. NOAA IT will need to add AKFIN access to your tnsnames.ora file (they do this frequently). Once your connection is established data may be accessed through SQL queries using SQL developer, R, or python.",
    "crumbs": [
      "AKFIN"
    ]
  },
  {
    "objectID": "content/akfin-intro.html#akfin-answers",
    "href": "content/akfin-intro.html#akfin-answers",
    "title": "AKFIN",
    "section": "AKFIN Answers",
    "text": "AKFIN Answers\n(AKFIN Answers)[https://akfin.psmfc.org/akfin-answers/] is an Oracle BI tool used for distributing data to stock assessors and other users. Usernames and passwords are distinct from AKFIN direct database credentials. The distribution of GAP_PRODUCTS on AKFIN Answers is planned but not yet implemented. The RACE Survey tab on the stock assessment dashboard contains reports generated from now depreciated tables that predated the GAP_PRODUCTS tables. AKFIN will keep these reports for reference but they will not be updated 2024 onward.\n\n\n\n\n\nAKFIN platfrom.",
    "crumbs": [
      "AKFIN"
    ]
  },
  {
    "objectID": "content/akfin-intro.html#web-service",
    "href": "content/akfin-intro.html#web-service",
    "title": "AKFIN",
    "section": "Web Service",
    "text": "Web Service\nAKFIN has developed web services (apis) to distribute GAP data. Like the GAP_PRODUCTS schema, these are under active development. These do not require VPN or an oracle connection but they are protected by Oracle authentication, please contact matt.callahan@noaa.gov for information on how to get an api token to use this option.\nThe url structure is “https://apex.psmfc.org/akfin/data_marts/gap_products/gap_[base table name]” . For example “https://apex.psmfc.org/akfin/data_marts/gap_products/gap_biomass” is the base url to get data from the akfin_biomass table. Web services linked to large tables have mandatory parameters to reduce data download size. For example to get agecomp data for Bering Sea pollock in area_id 10 in 2022 you would use “https://apex.psmfc.org/akfin/data_marts/gap_products/gap_biomass?survey_definition_id=98&area_id=10&species_code=21740&start_year=2022&end_year=2022”.\nIf you’re using R to pull data through web services you might find the akfingapdata (pronounced akfin-gap-data not ak-eff-ing-app-data) R package helpful.",
    "crumbs": [
      "AKFIN"
    ]
  },
  {
    "objectID": "content/akfin-intro.html#cite-this-data",
    "href": "content/akfin-intro.html#cite-this-data",
    "title": "AKFIN",
    "section": "Cite this data",
    "text": "Cite this data\nUse the below bibtext citation, as cited in our group’s citation repository for citing the data created and maintained in this repo (Alaska Fisheries Information Network (AKFIN), 2024). Add “note = {Accessed: mm/dd/yyyy}” to append the day this data was accessed.\n\n\n [1] \"@misc{GAPakfin,\"                                                                                   \n [2] \"  author = {{Alaska Fisheries Information Network (AKFIN)}}, \"                                     \n [3] \"  institution = {{NOAA Fisheries Alaska Fisheries Science Center, Groundfish Assessment Program}},\"\n [4] \"  year = {2024}, \"                                                                                 \n [5] \"  title = {AFSC Groundfish Assessment Program Design-Based Production Data},\"                      \n [6] \"  howpublished = {https://akfinbi.psmfc.org/analytics/},\"                                          \n [7] \"  url = {https://www.psmfc.org/program/alaska-fisheries-information-network-akfin},\"               \n [8] \"  publisher = {{U.S. Dep. Commer.}},\"                                                              \n [9] \"  copyright = {Public Domain} \"                                                                    \n[10] \"}\"                                                                                                 \n\n\n\n\n\n\nAlaska Fisheries Information Network (AKFIN). (2024). AFSC groundfish assessment program design-based production data. NOAA Fisheries Alaska Fisheries Science Center, Groundfish Assessment Program; https://akfinbi.psmfc.org/analytics/; U.S. Dep. Commer. https://www.psmfc.org/program/alaska-fisheries-information-network-akfin",
    "crumbs": [
      "AKFIN"
    ]
  },
  {
    "objectID": "content/akfin-metadata.html",
    "href": "content/akfin-metadata.html",
    "title": "Data description",
    "section": "",
    "text": "Data tables\nAKFIN Answers is an Oracle BI tool used for distributing data to stock assessors and other users. Usernames and passwords are distinct from direct AKFIN database credentials.",
    "crumbs": [
      "AKFIN",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data description</span>"
    ]
  },
  {
    "objectID": "content/akfin-metadata.html#data-tables",
    "href": "content/akfin-metadata.html#data-tables",
    "title": "Data description",
    "section": "",
    "text": "AKFIN_AGECOMP\nsnapshot table for snapshot GAP_PRODUCTS.AKFIN_AGECOMP\nNumber of rows: 687,698\nNumber of columns: 10\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code is an integer that uniquely identifies a survey region/survey design. The column survey_definition_id is associated with the srvy and survey columns. Full list of survey definition IDs are in RACE_DATA.SURVEY_DEFINITIONS and in the code books.\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\nAREA_ID\n\n\nArea ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nAn ID code representing a broad range of spatial areas from statistical sampling strata to management and regional areas composed of multiple strata.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the common_name and scientific_name columns. For a complete species list, review the code books.\n\n\n\n\nSEX\n\n\nSex of a specimen\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nSex of a specimen where “1” = “Male”, “2” = “Female”, “3” = Unsexed.\n\n\n\n\nAGE\n\n\nTaxon age bin (yrs)\n\n\ninteger\n\n\nNUMBER(38,0)\n\n\nAge bin of taxon. Age bin of a taxon in years estimated by the age comp estimate. Age -9 indicates unaged lengths for a particular sex because no otoliths were collected for that sex/length combination. Age -99 indicates a case where no lengths were collected within a stratum for a species/year even though catch numbers were recorded.\n\n\n\n\nPOPULATION_COUNT\n\n\nEstimated population\n\n\nnumeric\n\n\nNUMBER(38,0)\n\n\nThe estimated population caught in the survey for a species, group, or total for a given survey.\n\n\n\n\nLENGTH_MM_MEAN\n\n\nMean length at age weighted by numbers at length\n\n\nnumeric\n\n\nNUMBER(38,3)\n\n\nMean length (millimeters).\n\n\n\n\nLENGTH_MM_SD\n\n\nStandard deviation of length at age weighted by numbers at length\n\n\nnumeric\n\n\nNUMBER(38,3)\n\n\nVariance of mean length.\n\n\n\n\nAREA_ID_FOOTPRINT\n\n\nSurvey Footprint\n\n\ntext\n\n\nVARCHAR2(4000 BYTE)\n\n\nSurvey footprint, usually equivalent to the SURVEY_DEFINITION_ID with the exception of the Standard and Standard +NW survey footprints in the Eastern Bering Sea shelf bottom trawl survey.\n\n\n\n\n\n\nAKFIN_AREA\nsnapshot table for snapshot GAP_PRODUCTS.AKFIN_AREA\nNumber of rows: 503\nNumber of columns: 9\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nDESIGN_YEAR\n\n\nDesign year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear ID associated with a given value AREA_ID. This field describes the changes in the survey design over time.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code is an integer that uniquely identifies a survey region/survey design. The column survey_definition_id is associated with the srvy and survey columns. Full list of survey definition IDs are in RACE_DATA.SURVEY_DEFINITIONS and in the code books.\n\n\n\n\nAREA_ID\n\n\nArea ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nAn ID code representing a broad range of spatial areas from statistical sampling strata to management and regional areas composed of multiple strata.\n\n\n\n\nAREA_TYPE\n\n\nArea ID type description\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nThe type of stratum that AREA_ID represents. Types include: STRATUM (the smallest building-block unit of area in these surveys), REGION, DEPTH, SUBAREA, INPFC BY DEPTH, INPFC, SUBAREA BY DEPTH, REGULATORY AREA, NMFS STATISTICAL AREA.\n\n\n\n\nAREA_NAME\n\n\nArea ID name\n\n\ntext\n\n\nVARCHAR2(4000 BYTE)\n\n\nDescriptive name of each AREA_ID. These names often identify the region, depth ranges, or other regional information for the area ID.\n\n\n\n\nDESCRIPTION\n\n\nDescription\n\n\ntext\n\n\nVARCHAR2(4000 BYTE)\n\n\nDescription of row observation.\n\n\n\n\nAREA_KM2\n\n\nArea (km2)\n\n\nkilometers squared\n\n\nNUMBER(38,3)\n\n\nArea in square kilometers.\n\n\n\n\nDEPTH_MIN_M\n\n\nArea ID minimum depth (m)\n\n\nmeters\n\n\nNUMBER(38,3)\n\n\nMinimum depth (meters).\n\n\n\n\nDEPTH_MAX_M\n\n\nArea ID maximum depth (m)\n\n\nmeters\n\n\nNUMBER(38,3)\n\n\nMaximum depth (meters).\n\n\n\n\n\n\nAKFIN_BIOMASS\nsnapshot table for snapshot GAP_PRODUCTS.AKFIN_BIOMASS\nNumber of rows: 2,655,773\nNumber of columns: 16\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code is an integer that uniquely identifies a survey region/survey design. The column survey_definition_id is associated with the srvy and survey columns. Full list of survey definition IDs are in RACE_DATA.SURVEY_DEFINITIONS and in the code books.\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the common_name and scientific_name columns. For a complete species list, review the code books.\n\n\n\n\nAREA_ID\n\n\nArea ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nAn ID code representing a broad range of spatial areas from statistical sampling strata to management and regional areas composed of multiple strata.\n\n\n\n\nCPUE_KGKM2_MEAN\n\n\nMean weight CPUE\n\n\nkilograms per kilometers squared\n\n\nNUMBER(38,6)\n\n\nThe mean catch weight (kilograms) per unit effort (area swept by the net, units squared kilometers).\n\n\n\n\nCPUE_NOKM2_MEAN\n\n\nMean numeric CPUE\n\n\ncount per kilometers squared\n\n\nNUMBER(38,6)\n\n\nThe mean of numerical catch per unit effort (area swept by the net, units square kilometers).\n\n\n\n\nN_HAUL\n\n\nValid hauls\n\n\ncount\n\n\nNUMBER(38,0)\n\n\nTotal number of hauls.\n\n\n\n\nN_WEIGHT\n\n\nHauls with catch\n\n\ncount\n\n\nNUMBER(38,0)\n\n\nTotal number of hauls with positive catch biomass.\n\n\n\n\nN_COUNT\n\n\nHauls with taxon counts\n\n\nnumeric\n\n\nNUMBER(38,0)\n\n\nTotal number of hauls with positive count data.\n\n\n\n\nN_LENGTH\n\n\nHauls with taxon lengths\n\n\ncount\n\n\nNUMBER(38,0)\n\n\nTotal number of hauls with length data.\n\n\n\n\nBIOMASS_MT\n\n\nEstimated biomass\n\n\nnumeric\n\n\nNUMBER(38,6)\n\n\nThe estimated total biomass.\n\n\n\n\nBIOMASS_VAR\n\n\nEstimated biomass variance\n\n\nnumeric\n\n\nNUMBER(38,6)\n\n\nThe estimated variance associated with the total biomass.\n\n\n\n\nPOPULATION_COUNT\n\n\nEstimated population\n\n\nnumeric\n\n\nNUMBER(38,0)\n\n\nThe estimated population caught in the survey for a species, group, or total for a given survey.\n\n\n\n\nPOPULATION_VAR\n\n\nEstimated population variance\n\n\nnumeric\n\n\nNUMBER(38,6)\n\n\nThe estimated population variance caught in the survey for a species, group, or total for a given survey.\n\n\n\n\nCPUE_KGKM2_VAR\n\n\nVariance of the mean weight CPUE\n\n\nkilograms per kilometers squared\n\n\nNUMBER(38,6)\n\n\nThe variance of mean catch weight (kilograms) per unit effort (area swept by the net, units squared kilometers).\n\n\n\n\nCPUE_NOKM2_VAR\n\n\nVariance of the mean numeric CPUE\n\n\ncount per kilometers squared\n\n\nNUMBER(38,6)\n\n\nThe variance of mean numerical catch per unit effort (area swept by the net, units square kilometers).\n\n\n\n\n\n\nAKFIN_CATCH\nsnapshot table for snapshot GAP_PRODUCTS.AKFIN_CATCH\nNumber of rows: 998,924\nNumber of columns: 6\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nCRUISEJOIN\n\n\nCruise ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nUnique integer ID assigned to each survey, vessel, and year combination.\n\n\n\n\nHAULJOIN\n\n\nHaul ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThis is a unique numeric identifier assigned to each (vessel, cruise, and haul) combination.\n\n\n\n\nCATCHJOIN\n\n\nCatch observation ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nUnique integer ID assigned to each survey, vessel, year, and catch observation combination.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the common_name and scientific_name columns. For a complete species list, review the code books.\n\n\n\n\nWEIGHT_KG\n\n\nSample or taxon weight (kg)\n\n\nkilograms\n\n\nNUMBER(38,3)\n\n\nWeight (thousandths of a kilogram) of individuals in a haul by taxon.\n\n\n\n\nCOUNT\n\n\nTaxon count\n\n\ncount, whole number resolution\n\n\nNUMBER(38,0)\n\n\nTotal whole number of individuals caught in haul or samples collected.\n\n\n\n\n\n\nAKFIN_CPUE\nsnapshot table for snapshot GAP_PRODUCTS.AKFIN_CPUE\nNumber of rows: 21,915,584\nNumber of columns: 7\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nHAULJOIN\n\n\nHaul ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThis is a unique numeric identifier assigned to each (vessel, cruise, and haul) combination.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the common_name and scientific_name columns. For a complete species list, review the code books.\n\n\n\n\nWEIGHT_KG\n\n\nSample or taxon weight (kg)\n\n\nkilograms\n\n\nNUMBER(38,3)\n\n\nWeight (thousandths of a kilogram) of individuals in a haul by taxon.\n\n\n\n\nCOUNT\n\n\nTaxon count\n\n\ncount, whole number resolution\n\n\nNUMBER(38,0)\n\n\nTotal whole number of individuals caught in haul or samples collected.\n\n\n\n\nAREA_SWEPT_KM2\n\n\nArea swept (km)\n\n\nkilometers\n\n\nNUMBER(38,6)\n\n\nThe area the net covered while the net was fishing (kilometers squared), defined as the distance fished times the net width.\n\n\n\n\nCPUE_KGKM2\n\n\nWeight CPUE (kg/km2)\n\n\nkilograms per kilometers squared\n\n\nNUMBER(38,6)\n\n\nCatch weight (kilograms) per unit effort (area swept by the net, units square kilometers).\n\n\n\n\nCPUE_NOKM2\n\n\nNumber CPUE (no/km2)\n\n\ncount per kilometers squared\n\n\nNUMBER(38,6)\n\n\nNumerical catch per unit effort (area swept by the net, units square kilometers).\n\n\n\n\n\n\nAKFIN_CRUISE\nsnapshot table for snapshot GAP_PRODUCTS.AKFIN_CRUISE\nNumber of rows: 180\nNumber of columns: 10\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nCRUISEJOIN\n\n\nCruise ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nUnique integer ID assigned to each survey, vessel, and year combination.\n\n\n\n\nCRUISE\n\n\nCruise Name\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThis is a six-digit integer identifying the cruise number of the form: YYYY99 (where YYYY = year of the cruise; 99 = 2-digit number and is sequential; 01 denotes the first cruise that vessel made in this year, 02 is the second, etc.).\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code is an integer that uniquely identifies a survey region/survey design. The column survey_definition_id is associated with the srvy and survey columns. Full list of survey definition IDs are in RACE_DATA.SURVEY_DEFINITIONS and in the code books.\n\n\n\n\nSURVEY_NAME\n\n\nSurvey name official\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nLong name of the survey conducted\n\n\n\n\nVESSEL_ID\n\n\nVessel ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nID number of the vessel used to collect data for that haul. The column vessel_id is associated with the vessel_name column. Note that it is possible for a vessel to have a new name but the same vessel id number. For a complete list of vessel ID key codes, review the code books.\n\n\n\n\nVESSEL_NAME\n\n\nVessel name\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nName of the vessel used to collect data for that haul. The column vessel_name is associated with the vessel_id column. Note that it is possible for a vessel to have a new name but the same vessel id number. For a complete list of vessel ID key codes, review the code books.\n\n\n\n\nDATE_START\n\n\nStart date\n\n\nYYYY-MM-DD\n\n\nDATE\n\n\nThe date (YYYY-MM-DD) of the beginning of the event (e.g., cruise).\n\n\n\n\nDATE_END\n\n\nEnd date\n\n\nYYYY-MM-DD\n\n\nDATE\n\n\nThe date (YYYY-MM-DD) of the end of the event (e.g., cruise).\n\n\n\n\n\n\nAKFIN_HAUL\nsnapshot table for snapshot GAP_PRODUCTS.AKFIN_HAUL\nNumber of rows: 35,111\nNumber of columns: 25\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nCRUISEJOIN\n\n\nCruise ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nUnique integer ID assigned to each survey, vessel, and year combination.\n\n\n\n\nHAULJOIN\n\n\nHaul ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThis is a unique numeric identifier assigned to each (vessel, cruise, and haul) combination.\n\n\n\n\nHAUL\n\n\nHaul number\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThis number uniquely identifies a sampling event (haul) within a cruise. It is a sequential number, in chronological order of occurrence.\n\n\n\n\nHAUL_TYPE\n\n\nHaul sampling type\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nType of haul sampling method. For a complete list of haul type ID key codes, review the code books.\n\n\n\n\nPERFORMANCE\n\n\nHaul performance code\n\n\ncategory\n\n\nNUMBER(38,0)\n\n\nThis denotes what, if any, issues arose during the haul. For more information, review the code books.\n\n\n\n\nDATE_TIME_START\n\n\nStart date and time\n\n\nMM/DD/YYYY HH::MM\n\n\nTIMESTAMP\n\n\nThe date (MM/DD/YYYY) and time (HH:MM) of the beginning of the haul. All dates and times are in Alaska time (AKDT) of Anchorage, AK, USA (UTC/GMT -8 hours).\n\n\n\n\nDURATION_HR\n\n\nTow duration (decimal hr)\n\n\nhours\n\n\nNUMBER(38,1)\n\n\nThis is the elapsed time between start and end of a haul (decimal hours).\n\n\n\n\nDISTANCE_FISHED_KM\n\n\nDistance fished (km)\n\n\nkilometers\n\n\nNUMBER(38,3)\n\n\nDistance the net fished (kilometers).\n\n\n\n\nNET_WIDTH_M\n\n\nNet width (m)\n\n\nmeters\n\n\nNUMBER(38,1)\n\n\nMeasured or estimated distance (meters) between wingtips of the trawl.\n\n\n\n\nNET_MEASURED\n\n\nNet measured during haul\n\n\nlogical\n\n\nBINARY_DOUBLE\n\n\nLogical, describing if the net was measured (TRUE) or not (FALSE) by wheelhouse and marport programs during the haul.\n\n\n\n\nNET_HEIGHT_M\n\n\nNet height (m)\n\n\nmeters\n\n\nNUMBER(38,1)\n\n\nMeasured or estimated distance (meters) between footrope and headrope of the trawl.\n\n\n\n\nSTRATUM\n\n\nStratum ID\n\n\nID key code\n\n\nNUMBER(10,0)\n\n\nRACE database statistical area for analyzing data. Strata were designed using bathymetry and other geographic and habitat-related elements. The strata are unique to each survey region. Stratum of value 0 indicates experimental tows.\n\n\n\n\nLATITUDE_DD_START\n\n\nStart latitude (decimal degrees)\n\n\ndecimal degrees\n\n\nNUMBER(38,6)\n\n\nLatitude (one hundred thousandth of a decimal degree) of the start of the haul.\n\n\n\n\nLATITUDE_DD_END\n\n\nEnd latitude (decimal degrees)\n\n\ndecimal degrees\n\n\nNUMBER(38,6)\n\n\nLatitude (one hundred thousandth of a decimal degree) of the end of the haul.\n\n\n\n\nLONGITUDE_DD_START\n\n\nStart longitude (decimal degrees)\n\n\ndecimal degrees\n\n\nNUMBER(38,6)\n\n\nLongitude (one hundred thousandth of a decimal degree) of the start of the haul.\n\n\n\n\nLONGITUDE_DD_END\n\n\nEnd longitude (decimal degrees)\n\n\ndecimal degrees\n\n\nNUMBER(38,6)\n\n\nLongitude (one hundred thousandth of a decimal degree) of the end of the haul.\n\n\n\n\nSTATION\n\n\nStation ID\n\n\nID key code\n\n\nVARCHAR2(255 BYTE)\n\n\nAlpha-numeric designation for the station established in the design of a survey.\n\n\n\n\nDEPTH_GEAR_M\n\n\nDepth of gear (m)\n\n\ndegrees Celsius\n\n\nNUMBER(38,1)\n\n\nDepth of gear (meters).\n\n\n\n\nDEPTH_M\n\n\nDepth (m)\n\n\ndegrees Celsius\n\n\nNUMBER(38,1)\n\n\nBottom depth (meters).\n\n\n\n\nBOTTOM_TYPE\n\n\nSeafloor bottom type code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nBottom type on sea floor at haul location. For a complete list of bottom type ID key codes, review the code books.\n\n\n\n\nSURFACE_TEMPERATURE_C\n\n\nSurface temperature (degrees Celsius)\n\n\ndegrees Celsius\n\n\nNUMBER(38,1)\n\n\nSurface temperature (tenths of a degree Celsius); NA indicates removed or missing values.\n\n\n\n\nGEAR_TEMPERATURE_C\n\n\nGear temperature (degrees Celsius)\n\n\ndegrees Celsius\n\n\nNUMBER(38,1)\n\n\nTemperature recorded by net gear (tenths of a degree Celsius); NA indicates removed or missing values.\n\n\n\n\nWIRE_LENGTH_M\n\n\nTrawl wire length\n\n\nmeters\n\n\nNUMBER(38,0)\n\n\nLength of wire deployed during a given haul in meters.\n\n\n\n\nGEAR\n\n\nType of gear used on the net\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nType of gear used on net. For a complete list of gear ID key codes, review the code books.\n\n\n\n\nACCESSORIES\n\n\nType of gear accessories used on the net\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nType of accessories used on net. For a complete list of accessories ID key codes, review the code books.\n\n\n\n\n\n\nAKFIN_LENGTH\nsnapshot table for snapshot GAP_PRODUCTS.AKFIN_LENGTH\nNumber of rows: 4,573,329\nNumber of columns: 7\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nHAULJOIN\n\n\nHaul ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThis is a unique numeric identifier assigned to each (vessel, cruise, and haul) combination.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the common_name and scientific_name columns. For a complete species list, review the code books.\n\n\n\n\nSEX\n\n\nSex of a specimen\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nSex of a specimen where “1” = “Male”, “2” = “Female”, “3” = Unsexed.\n\n\n\n\nFREQUENCY\n\n\nCount of observation\n\n\ncount\n\n\nNUMBER(38,0)\n\n\nFrequency, or count, of an observation.\n\n\n\n\nLENGTH_MM\n\n\nLength of a specimen\n\n\nmillimeters\n\n\nNUMBER(10,0)\n\n\nLength bin in millimeters. A length of -9 indicates cases where no lengths were collected within a stratum for a species/year, even though catch numbers were recorded.\n\n\n\n\nLENGTH_TYPE\n\n\nLength type\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nHow the taxon was measured (e.g., fork length, carapace width). For a complete list of length_type ID key codes, review the code books.\n\n\n\n\nSAMPLE_TYPE\n\n\nSample type\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nSampling information on how the taxon was sampled. For a complete list of length_type ID key codes, review the code books.\n\n\n\n\n\n\nAKFIN_METADATA_COLUMN\nsnapshot table for snapshot GAP_PRODUCTS.AKFIN_METADATA_COLUMN\nNumber of rows: 173\nNumber of columns: 5\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nMETADATA_COLNAME_DESC\n\n\nColumn description\n\n\ntext\n\n\nVARCHAR2(4000 BYTE)\n\n\nDescription of the column.\n\n\n\n\nMETADATA_COLNAME\n\n\nColumn name\n\n\ntext\n\n\nVARCHAR2(4000 BYTE)\n\n\nName of the column in a table.\n\n\n\n\nMETADATA_COLNAME_LONG\n\n\nColumn name spelled out\n\n\ntext\n\n\nVARCHAR2(4000 BYTE)\n\n\nLong name for the column.\n\n\n\n\nMETADATA_UNITS\n\n\nUnits\n\n\ncategory\n\n\nVARCHAR2(4000 BYTE)\n\n\nUnits of the column.\n\n\n\n\nMETADATA_DATATYPE\n\n\nOracle datatype code\n\n\ntext\n\n\nVARCHAR2(4000 BYTE)\n\n\nOracle data type of data column.\n\n\n\n\n\n\nAKFIN_SIZECOMP\nsnapshot table for snapshot GAP_PRODUCTS.AKFIN_SIZECOMP\nNumber of rows: 3,305,896\nNumber of columns: 7\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code is an integer that uniquely identifies a survey region/survey design. The column survey_definition_id is associated with the srvy and survey columns. Full list of survey definition IDs are in RACE_DATA.SURVEY_DEFINITIONS and in the code books.\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\nAREA_ID\n\n\nArea ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nAn ID code representing a broad range of spatial areas from statistical sampling strata to management and regional areas composed of multiple strata.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the common_name and scientific_name columns. For a complete species list, review the code books.\n\n\n\n\nLENGTH_MM\n\n\nLength of a specimen\n\n\nmillimeters\n\n\nNUMBER(10,0)\n\n\nLength bin in millimeters. A length of -9 indicates cases where no lengths were collected within a stratum for a species/year, even though catch numbers were recorded.\n\n\n\n\nSEX\n\n\nSex of a specimen\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nSex of a specimen where “1” = “Male”, “2” = “Female”, “3” = Unsexed.\n\n\n\n\nPOPULATION_COUNT\n\n\nEstimated population\n\n\nnumeric\n\n\nNUMBER(38,0)\n\n\nThe estimated population caught in the survey for a species, group, or total for a given survey.\n\n\n\n\n\n\nAKFIN_SPECIMEN\nsnapshot table for snapshot GAP_PRODUCTS.AKFIN_SPECIMEN\nNumber of rows: 604,594\nNumber of columns: 12\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nHAULJOIN\n\n\nHaul ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThis is a unique numeric identifier assigned to each (vessel, cruise, and haul) combination.\n\n\n\n\nSPECIMEN_ID\n\n\nSpecimen unique ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nEach individual examined must have a number assigned to it that is unique within each haul (0001 to 9999), though specimen numbers may be repeated between hauls\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the common_name and scientific_name columns. For a complete species list, review the code books.\n\n\n\n\nLENGTH_MM\n\n\nLength of a specimen\n\n\nmillimeters\n\n\nNUMBER(10,0)\n\n\nLength bin in millimeters. A length of -9 indicates cases where no lengths were collected within a stratum for a species/year, even though catch numbers were recorded.\n\n\n\n\nSEX\n\n\nSex of a specimen\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nSex of a specimen where “1” = “Male”, “2” = “Female”, “3” = Unsexed.\n\n\n\n\nWEIGHT_G\n\n\nSpecimen weight (g)\n\n\ngrams\n\n\nNUMBER(38,1)\n\n\nWeight of specimen (grams).\n\n\n\n\nAGE\n\n\nTaxon age bin (yrs)\n\n\ninteger\n\n\nNUMBER(38,0)\n\n\nAge bin of taxon. Age bin of a taxon in years estimated by the age comp estimate. Age -9 indicates unaged lengths for a particular sex because no otoliths were collected for that sex/length combination. Age -99 indicates a case where no lengths were collected within a stratum for a species/year even though catch numbers were recorded.\n\n\n\n\nMATURITY\n\n\nSpecimen maturity code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe maturity code or the condition identified by the maturity code.\n\n\n\n\nGONAD_G\n\n\nWeight of gonads (g)\n\n\ngrams\n\n\nNUMBER(38,1)\n\n\nWeight of specimen gonads (grams).\n\n\n\n\nSPECIMEN_SUBSAMPLE_METHOD\n\n\nSpecimen subsample method\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nFor a complete list of specimen subsample method ID key codes, review the code books.\n\n\n\n\nSPECIMEN_SAMPLE_TYPE\n\n\nSpecimen sample type\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe specimen sample type ID key code as defined in the RACE_DATA.SPECIMEN_SAMPLE_TYPES table. For a complete list of Specimen sample type ID key codes, review the code books.\n\n\n\n\nAGE_DETERMINATION_METHOD\n\n\nAging method\n\n\nID key code\n\n\nNUMBER(10,0)\n\n\nNumeric code corresponding to the method of age determination. For a complete list of age determination codes, review the code books.\n\n\n\n\n\n\nAKFIN_STRATUM_GROUPS\nsnapshot table for snapshot GAP_PRODUCTS.AKFIN_STRATUM_GROUPS\nNumber of rows: 1,066\nNumber of columns: 4\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nAREA_ID\n\n\nArea ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nAn ID code representing a broad range of spatial areas from statistical sampling strata to management and regional areas composed of multiple strata.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code is an integer that uniquely identifies a survey region/survey design. The column survey_definition_id is associated with the srvy and survey columns. Full list of survey definition IDs are in RACE_DATA.SURVEY_DEFINITIONS and in the code books.\n\n\n\n\nDESIGN_YEAR\n\n\nDesign year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear ID associated with a given value AREA_ID. This field describes the changes in the survey design over time.\n\n\n\n\nSTRATUM\n\n\nStratum ID\n\n\nID key code\n\n\nNUMBER(10,0)\n\n\nRACE database statistical area for analyzing data. Strata were designed using bathymetry and other geographic and habitat-related elements. The strata are unique to each survey region. Stratum of value 0 indicates experimental tows.\n\n\n\n\n\n\nAKFIN_SURVEY_DESIGN\nsnapshot table for snapshot GAP_PRODUCTS.AKFIN_SURVEY_DESIGN\nNumber of rows: 88\nNumber of columns: 3\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code is an integer that uniquely identifies a survey region/survey design. The column survey_definition_id is associated with the srvy and survey columns. Full list of survey definition IDs are in RACE_DATA.SURVEY_DEFINITIONS and in the code books.\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\nDESIGN_YEAR\n\n\nDesign year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear ID associated with a given value AREA_ID. This field describes the changes in the survey design over time.\n\n\n\n\n\n\nAKFIN_TAXONOMIC_CLASSIFICATION\nsnapshot table for snapshot GAP_PRODUCTS.AKFIN_TAXONOMIC_CLASSIFICATION\nNumber of rows: 2,718\nNumber of columns: 19\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nCLASS_TAXON\n\n\nClass phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of class of a given species.\n\n\n\n\nSUPERCLASS_TAXON\n\n\nSuperclass phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of superclass of a given species.\n\n\n\n\nSUBPHYLUM_TAXON\n\n\nSubphylum phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of subphylum of a given species.\n\n\n\n\nPHYLUM_TAXON\n\n\nPhylum phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of phylum of a given species.\n\n\n\n\nKINGDOM_TAXON\n\n\nKingdom phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of kingdom of a given species.\n\n\n\n\nSPECIES_NAME\n\n\nScientific name of species\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nScientific name of species.\n\n\n\n\nCOMMON_NAME\n\n\nTaxon common name\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nThe common name of the marine organism associated with the scientific_name and species_code columns. For a complete species list, review the code books.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the common_name and scientific_name columns. For a complete species list, review the code books.\n\n\n\n\nID_RANK\n\n\nLowest taxonomic rank\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nLowest taxonomic rank of a given species entry.\n\n\n\n\nDATABASE_ID\n\n\nSpecies ID in database\n\n\nID key code\n\n\nVARCHAR2(255 BYTE)\n\n\nSpecies ID key code of a species in the taxonomic “DATABASE” source.\n\n\n\n\nDATABASE\n\n\nDatabase source\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nTaxonomic database source, either ITIS or WoRMS.\n\n\n\n\nGENUS_TAXON\n\n\nGenus phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of genus of a given species.\n\n\n\n\nSUBFAMILY_TAXON\n\n\nSubfamily phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of subfamily of a given species.\n\n\n\n\nFAMILY_TAXON\n\n\nFamily phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of family of a given species.\n\n\n\n\nSUPERFAMILY_TAXON\n\n\nSuperfamily phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of superfamily of a given species.\n\n\n\n\nSUBORDER_TAXON\n\n\nSuborder phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of suborder of a given species.\n\n\n\n\nORDER_TAXON\n\n\nOrder phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of order of a given species.\n\n\n\n\nSUPERORDER_TAXON\n\n\nSuperorder phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of superorder of a given species.\n\n\n\n\nSUBCLASS_TAXON\n\n\nSubclass phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of subclass of a given species.\n\n\n\n\n\n\nAKFIN_TAXONOMIC_GROUPS\nsnapshot table for snapshot GAP_PRODUCTS.AKFIN_TAXONOMIC_GROUPS\nNumber of rows: 2,777\nNumber of columns: 22\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the common_name and scientific_name columns. For a complete species list, review the code books.\n\n\n\n\nSPECIES_NAME\n\n\nScientific name of species\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nScientific name of species.\n\n\n\n\nCOMMON_NAME\n\n\nTaxon common name\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nThe common name of the marine organism associated with the scientific_name and species_code columns. For a complete species list, review the code books.\n\n\n\n\nID_RANK\n\n\nLowest taxonomic rank\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nLowest taxonomic rank of a given species entry.\n\n\n\n\nDATABASE\n\n\nDatabase source\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nTaxonomic database source, either ITIS or WoRMS.\n\n\n\n\nDATABASE_ID\n\n\nSpecies ID in database\n\n\nID key code\n\n\nVARCHAR2(255 BYTE)\n\n\nSpecies ID key code of a species in the taxonomic “DATABASE” source.\n\n\n\n\nGENUS_TAXON\n\n\nGenus phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of genus of a given species.\n\n\n\n\nSUBFAMILY_TAXON\n\n\nSubfamily phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of subfamily of a given species.\n\n\n\n\nFAMILY_TAXON\n\n\nFamily phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of family of a given species.\n\n\n\n\nSUPERFAMILY_TAXON\n\n\nSuperfamily phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of superfamily of a given species.\n\n\n\n\nINFRAORDER_TAXON\n\n\nInfraorder phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nInfraorder phylogenetic rank. Phylogenetic latin rank of infraorder of a given speices.\n\n\n\n\nSUBORDER_TAXON\n\n\nSuborder phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of suborder of a given species.\n\n\n\n\nORDER_TAXON\n\n\nOrder phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of order of a given species.\n\n\n\n\nSUPERORDER_TAXON\n\n\nSuperorder phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of superorder of a given species.\n\n\n\n\nINFRACLASS_TAXON\n\n\nInfraclass phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nInfraclass phylogenetic rank. Phylogenetic latin rank of infraclass of a given speices.\n\n\n\n\nSUBCLASS_TAXON\n\n\nSubclass phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of subclass of a given species.\n\n\n\n\nCLASS_TAXON\n\n\nClass phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of class of a given species.\n\n\n\n\nSUPERCLASS_TAXON\n\n\nSuperclass phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of superclass of a given species.\n\n\n\n\nSUBPHYLUM_TAXON\n\n\nSubphylum phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of subphylum of a given species.\n\n\n\n\nPHYLUM_TAXON\n\n\nPhylum phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of phylum of a given species.\n\n\n\n\nKINGDOM_TAXON\n\n\nKingdom phylogenetic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic latin rank of kingdom of a given species.\n\n\n\n\nGROUP_CODE\n\n\nSpecies or Complex ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nEquivalent to the SPECIES_CODE if the taxon is reported as a single taxon in GAP_PRODUCTS, otherwise denotes a SPECIES_CODE of a higher taxonomic group to which the taxon is aggregated in the GAP_PRODUCTS CPUE and BIOMASS tables.",
    "crumbs": [
      "AKFIN",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data description</span>"
    ]
  },
  {
    "objectID": "content/akfin-oracle-sql-r.html",
    "href": "content/akfin-oracle-sql-r.html",
    "title": "Access data via Oracle and R",
    "section": "",
    "text": "Access data via Oracle (AFSC only)\nAFSC Oracle users can access the database via SQL developer to view and pull the production data directly from the GAP_PRODUCTS Oracle schema. The user can also use SQL developer to view and pull the GAP Products data directly from the GAP_PRODUCTS Oracle schema.",
    "crumbs": [
      "AKFIN",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Access data via Oracle and R</span>"
    ]
  },
  {
    "objectID": "content/akfin-oracle-sql-r.html#access-data-via-oracle-afsc-only",
    "href": "content/akfin-oracle-sql-r.html#access-data-via-oracle-afsc-only",
    "title": "Access data via Oracle and R",
    "section": "",
    "text": "8.0.1 Connect to Oracle from R\nMany users will want to access the data from Oracle using R. The user will need to install the RODBC R package and ask OFIS (IT) connect R to Oracle. Then, use the following code in R to establish a connection from R to Oracle:\nHere, the user can establish the oracle connection by entering their username and password in the channel &lt;- gapindex::oracle_connect() function. Never save usernames or passwords in scripts that may be intentionally or unintentionally shared with others. If no username and password is entered in the function, pop-ups will appear on the screen asking for the username and password.\nAfter you connect to VPN, you’ll be able to log into Oracle.\n\nlibrary(RODBC)\nchannel &lt;- gapindex::get_connected()",
    "crumbs": [
      "AKFIN",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Access data via Oracle and R</span>"
    ]
  },
  {
    "objectID": "content/akfin-oracle-sql-r.html#data-sql-query-examples",
    "href": "content/akfin-oracle-sql-r.html#data-sql-query-examples",
    "title": "Access data via Oracle and R",
    "section": "Data SQL Query Examples:",
    "text": "Data SQL Query Examples:\n\nlibrary(gapindex)\nlibrary(RODBC)\nlibrary(flextable)\nlibrary(ggplot2)\nlibrary(magrittr)\nlibrary(dplyr)\n\n\n8.0.2 Ex. Select all data from tables\nYou can download all of the tables locally using a variation of the code below. Once connected, pull and save the tables of interest into the R environment.\n\nlocations &lt;- c(\n  \"GAP_PRODUCTS.AKFIN_AGECOMP\", \n  \"GAP_PRODUCTS.AKFIN_AREA\", \n  \"GAP_PRODUCTS.AKFIN_BIOMASS\", \n  \"GAP_PRODUCTS.AKFIN_CATCH\", \n  \"GAP_PRODUCTS.AKFIN_CPUE\", \n  \"GAP_PRODUCTS.AKFIN_CRUISE\", \n  \"GAP_PRODUCTS.AKFIN_HAUL\", \n  \"GAP_PRODUCTS.AKFIN_LENGTH\", \n  \"GAP_PRODUCTS.AKFIN_METADATA_COLUMN\", \n  \"GAP_PRODUCTS.AKFIN_SIZECOMP\", \n  \"GAP_PRODUCTS.AKFIN_SPECIMEN\", \n  \"GAP_PRODUCTS.AKFIN_STRATUM_GROUPS\", \n  \"GAP_PRODUCTS.AKFIN_SURVEY_DESIGN\", \n  \"GAP_PRODUCTS.AKFIN_TAXONOMIC_CLASSIFICATION\"\n)\n\nfor (i in 1:length(locations)) {\n  print(locations[i])\n  a &lt;- RODBC::sqlQuery(channel, paste0(\"SELECT * FROM \", locations[i]))\n  write.csv(x = a, file = here::here(\"data\", paste0(locations[i], \".csv\")))\n}\n\n\nlibrary(odbc)\nlibrary(RODBC)\nlibrary(dbplyr)\n\nmy_spp_codes &lt;- c(\n  30010, #  Sebastolobus sp.    thornyhead unid.\n  30020, #  Sebastolobus alascanus  shortspine thornyhead\n  30025, #  Sebastolobus macrochir  broadfin thornyhead\n  30330, #  Sebastes melanops   black rockfish\n  30430, #  Sebastes proriger   redstripe rockfish\n  30470, #  Sebastes ruberrimus yelloweye rockfish\n  30475, #  Sebastes babcocki   redbanded rockfish\n  30535, #  Sebastes variegatus harlequin rockfish\n  30560, # Sebastes zacentrus   sharpchin rockfish\n  30600, # Sebastes reedi   yellowmouth rockfish\n  30030, # Sebastolobus altivelis   longspine thornyhead\n  30040, # Sebastes sp. rockfish unid.\n  30100, # Sebastes brevispinis silvergray rockfish\n  30150, # NA   dusky and dark rockfishes unid.\n  30152, # Sebastes variabilis  dusky rockfish\n  30170, # Sebastes crameri darkblotched rockfish\n  30270) # Sebastes helvomaculatus  rosethorn rockfish\n\na &lt;- dplyr::tbl(channel, dplyr::sql('gap_products.akfin_biomass')) |&gt; \n  dplyr::rename_all(tolower) |&gt; \n  dplyr::select(survey_definition_id, area_id, species_code, year, biomass_mt, biomass_var) |&gt; \n  dplyr::filter(species_code %in% my_spp_codes & \n                  area_id %in% 99904 & \n                  year &gt;= 1991) |&gt; \n  dplyr::collect() \n\nflextable::flextable(head(a)) |&gt; \n  flextable::fit_to_width(max_width = 6) |&gt; \n  flextable::theme_zebra()\n\n\n\n8.0.3 Ex. CPUE for all EBS and NBS stations with associated haul, cruise, and species information.\n\na &lt;- RODBC::sqlQuery(channel = channel, # NOT RACEBASE.HAUL\n                     query = paste0(\n                       \"\n-- Select columns for output data\nSELECT\ncr.CRUISEJOIN,\ncr.CRUISE,\ncr.YEAR,\ncr.SURVEY_DEFINITION_ID,\ncr.SURVEY_NAME,\ncr.VESSEL_ID,\ncr.VESSEL_NAME,\ncp.HAULJOIN,\ncp.SPECIES_CODE,\ntt.SPECIES_NAME,\ntt.COMMON_NAME,\ncp.WEIGHT_KG,\ncp.COUNT,\ncp.AREA_SWEPT_KM2,\ncp.CPUE_KGKM2,\ncp.CPUE_NOKM2,\nhh.HAUL,\nhh.STATION\n\n-- Identify what tables to pull data from\nFROM GAP_PRODUCTS.AKFIN_HAUL hh\nLEFT JOIN GAP_PRODUCTS.AKFIN_CRUISE cr\nON hh.CRUISEJOIN = cr.CRUISEJOIN\nLEFT JOIN GAP_PRODUCTS.AKFIN_CPUE cp\nON hh.HAULJOIN = cp.HAULJOIN\nLEFT JOIN GAP_PRODUCTS.TAXONOMIC_CLASSIFICATION tt\nON cp.SPECIES_CODE = tt.SPECIES_CODE\n\n-- Filter for EBS and NBS observations\nWHERE SURVEY_DEFINITION_ID IN (143, 98) -- 143 NBS, 98 EBS\nAND tt.SURVEY_SPECIES = 1\n\n-- Only return the first 3 rows because otherwise this would be a huge table!\nFETCH FIRST 3 ROWS ONLY;\")) \n\nflextable::flextable(head(a[,2:8])) |&gt; \n  flextable::fit_to_width(max_width = 6) |&gt; \n  flextable::theme_zebra()\n\nCPUE for all EBS and NBS stations with associated haul, cruise, and\nspecies information.CRUISEYEARSURVEY_DEFINITION_IDSURVEY_NAMEVESSEL_IDVESSEL_NAMEHAULJOIN198,2031,98298Eastern Bering Sea Crab/Groundfish Bottom Trawl Survey1CHAPMAN877198,2031,98298Eastern Bering Sea Crab/Groundfish Bottom Trawl Survey1CHAPMAN877198,2031,98298Eastern Bering Sea Crab/Groundfish Bottom Trawl Survey1CHAPMAN877\n\n\n\n\n8.0.4 Ex. CPUE for all stations contained in the INPFC Shumagin region (AREA_ID = 919) for Pacific cod.\n\ndat &lt;- RODBC::sqlQuery(channel = channel,\n                       query =\n                         \"\n-- Select columns for output data\nSELECT \nHAULJOIN, \nSPECIES_CODE, \nSTRATUM, \nLATITUDE_DD_START, \nLONGITUDE_DD_START,\nCPUE_KGKM2, \nGEAR_TEMPERATURE_C\n\n-- Identify what tables to pull data from\nFROM GAP_PRODUCTS.AKFIN_CPUE cpue\nLEFT JOIN GAP_PRODUCTS.AKFIN_HAUL haul\nUSING (HAULJOIN) \n\n-- Filter for P. Cod observations\nWHERE SPECIES_CODE IN (21720)\n\n-- Select all stratum within the area_id 919 (INPFC Shumagin region)\nAND haul.STRATUM IN\n(\nSELECT \nSTRATUM\nFROM GAP_PRODUCTS.AKFIN_STRATUM_GROUPS \nWHERE AREA_ID = 919\n);\")\n\n\ndat &lt;- dat |&gt; \n  dplyr::select(HAULJOIN, STRATUM, SPECIES_CODE, LATITUDE_DD_START, LONGITUDE_DD_START, CPUE_KGKM2, GEAR_TEMPERATURE_C) |&gt; \n  dplyr::mutate(SPECIES_CODE = as.character(SPECIES_CODE), \n                STRATUM = as.character(STRATUM)) |&gt; \n  dplyr::arrange(SPECIES_CODE)\n\nflextable::flextable(head(dat)) |&gt;   \n  flextable::fit_to_width(max_width = 6) |&gt; \n  flextable::theme_zebra()\n\nCPUE for all stations contained in the Shumagin region (AREA_ID =\n919).HAULJOINSTRATUMSPECIES_CODELATITUDE_DD_STARTLONGITUDE_DD_STARTCPUE_KGKM2GEAR_TEMPERATURE_C-12,8802102172052.55793-169.78296,863.3672-12,881102172052.63840-169.78151,536.85944.9-12,8821112172052.67131-169.427910,044.84094.7-12,883102172053.24099-168.07251,937.72945.2-12,884102172053.16771-167.9810830.20395.1-12,8851112172053.06838-167.67132,891.80924.9\n\n\n\n\n8.0.5 Ex. EBS Pacific Ocean perch CPUE and akgfmaps map\nPacific Ocean perch catch-per-unit-effort estimates for EBS in 2021 from GAP_PRODUCTS.AKFIN_CPUE and map constructed using akgfmaps. Here, we’ll use AKFIN HAUL and CRUISES data also included in this repo, for convenience, though they are very similar to their RACEBASE analogs.\n\ndat &lt;- RODBC::sqlQuery(channel = channel, \n                       query = \n                         \"\n-- Select columns for output data\nSELECT \n(cp.CPUE_KGKM2/100) CPUE_KGHA, -- akgfmaps is expecting hectares, but can take any units\nhh.LATITUDE_DD_START LATITUDE,\nhh.LONGITUDE_DD_START LONGITUDE\n\n-- Use HAUL data to obtain LATITUDE & LONGITUDE and connect to cruisejoin\nFROM GAP_PRODUCTS.AKFIN_CPUE cp\nLEFT JOIN GAP_PRODUCTS.AKFIN_HAUL hh\nON cp.HAULJOIN = hh.HAULJOIN\n\n-- Use CRUISES data to obtain YEAR and SURVEY_DEFINITION_ID\nLEFT JOIN GAP_PRODUCTS.AKFIN_CRUISE cc\nON hh.CRUISEJOIN = cc.CRUISEJOIN\n\n-- Filter data\nWHERE cp.SPECIES_CODE = 30060 \nAND cc.SURVEY_DEFINITION_ID = 98 \nAND cc.YEAR = 2021;\")\n\n\ndat |&gt; \n  dplyr::arrange(desc(CPUE_KGHA)) |&gt; \n  head() |&gt; \n  flextable::flextable() |&gt;  \n  flextable::fit_to_width(max_width = 6) |&gt; \n  flextable::theme_zebra()\n\nEBS Pacific Ocean perch CPUE and akgfmaps\nmap.CPUE_KGHALATITUDELONGITUDE10.176896557.64871-173.37356.273447056.36952-169.46043.025203456.66253-171.95491.821462857.98912-173.48160.553567255.65865-168.18040.281353357.32545-173.3217\n\n\n\n# devtools::install_github(\"afsc-gap-products/akgfmaps\", build_vignettes = TRUE)\nlibrary(akgfmaps)\n\nfigure &lt;- akgfmaps::make_idw_map(\n  x = dat, # Pass data as a data frame\n  region = \"bs.south\", # Predefined EBS area\n  set.breaks = \"jenks\", # Gets Jenks breaks from classint::classIntervals()\n  in.crs = \"+proj=longlat\", # Set input coordinate reference system\n  out.crs = \"EPSG:3338\", # Set output coordinate reference system\n  grid.cell = c(20000, 20000), # 20x20km grid\n  key.title = \"Pacific Ocean perch\") # Include in the legend title\n\n[inverse distance weighted interpolation]\n[inverse distance weighted interpolation]\n\nfigure$plot\n\n\n\n\nEBS Pacific Ocean perch CPUE and akgfmaps map.\n\n\n\n\n\n\n8.0.6 Ex. GOA Pacific Ocean perch biomass and abundance\nBiomass and abundance for Pacific Ocean perch from 1990 – 2023 for the western/central/eastern GOA management areas as well as for the entire region.\n\ndat &lt;- RODBC::sqlQuery(channel = channel, \n                       query = \n                         \"\n-- Manipulate data to join to\nWITH FILTERED_STRATA AS (\nSELECT AREA_ID, DESCRIPTION FROM GAP_PRODUCTS.AKFIN_AREA\nWHERE AREA_TYPE in ('REGULATORY AREA', 'REGION') \nAND SURVEY_DEFINITION_ID = 47\n-- Use the AREA records associated with the GOA stratification prior to 2025\nAND DESIGN_YEAR = 1984)\n\n-- Select columns for output data\nSELECT \nBIOMASS_MT,\nPOPULATION_COUNT, \nYEAR, \nDESCRIPTION\n\n-- Identify what tables to pull data from\nFROM GAP_PRODUCTS.AKFIN_BIOMASS BIOMASS\nJOIN FILTERED_STRATA STRATA \nON STRATA.AREA_ID = BIOMASS.AREA_ID\n\n-- Filter data results\nWHERE BIOMASS.SPECIES_CODE = 30060\nAND BIOMASS.YEAR BETWEEN 1990 AND 2023\")\n\n\ndat0 &lt;- dat |&gt; \n  janitor::clean_names() |&gt; \n  dplyr::select(biomass_mt, population_count, year, area = description) |&gt;\n  pivot_longer(cols = c(\"biomass_mt\", \"population_count\"), \n               names_to = \"var\", \n               values_to = \"val\") |&gt; \n  dplyr::mutate(\n    val = ifelse(var == \"biomass_mt\", val/1e6, val/1e9), \n    var = ifelse(var == \"biomass_mt\", \"Biomass (Mmt)\", \"Population (B)\"), \n    area = gsub(x = area, pattern = \" - \", replacement = \"\\n\"), \n    area = gsub(x = area, pattern = \": \", replacement = \"\\n\"), \n    type = sapply(X = strsplit(x = area, split = \"\\n\", fixed = TRUE), `[[`, 2))  |&gt; \n  dplyr::arrange(type) |&gt; \n  dplyr::mutate(\n    area = factor(area, levels = unique(area), labels = unique(area), ordered = TRUE))\n\nflextable::flextable(head(dat)) |&gt; \n  flextable::fit_to_width(max_width = 6) |&gt; \n  flextable::theme_zebra() |&gt;\n  flextable::colformat_num(j = \"YEAR\", big.mark = \"\")\n\nGOA Pacific Ocean perch biomass and abundance.BIOMASS_MTPOPULATION_COUNTYEARDESCRIPTION31,073.1560,087,7111990CENTRAL GOA - INPFC100,321.48174,708,3611990EASTERN GOA - INPFC24,435.5679,343,9191990WESTERN GOA - INPFC155,830.19314,139,9911990GOA Region: All Strata256,345.03454,133,0281993CENTRAL GOA - INPFC147,912.16230,314,6541993EASTERN GOA - INPFC\n\n\n\n# install.packages(\"scales\")\nlibrary(scales)\nfigure &lt;- ggplot2::ggplot(\n  dat = dat0, \n  mapping = aes(x = year, y = val, color = type)) +\n  ggplot2::geom_point(size = 3) + \n  ggplot2::facet_grid(cols = vars(area), rows = vars(var), scales = \"free_y\") + \n  ggplot2::scale_x_continuous(name = \"Year\", n.breaks = 3) +\n  ggplot2::scale_y_continuous(name = \"Estimate\", labels = comma) +\n  ggplot2::labs(title = 'GOA Pacific Ocean perch biomass and abundance 1990 – 2023')  + \n  ggplot2::guides(color=guide_legend(title = \"Region Type\"))+\n  ggplot2::scale_color_grey() +\n  ggplot2::theme_bw() +\n  ggplot2::theme(legend.direction = \"horizontal\", \n                 legend.position = \"bottom\")\n\nfigure\n\n\n\n\nGOA Pacific Ocean perch biomass and abundance.\n\n\n\n\n\n\n8.0.7 Ex. AI rock sole size compositions and ridge plot\nNorthern and Southern rock sole size composition data from 1991 – 2022 for the Aleutian Islands, with Ridge plot from ggridges.\n\ndat &lt;- RODBC::sqlQuery(channel = channel, \n                       query = \"\nSELECT \nYEAR,\nLENGTH_MM / 10 AS LENGTH_CM, \nSUM(POPULATION_COUNT) AS POPULATION_COUNT\n\n-- Identify what tables to pull data from\nFROM GAP_PRODUCTS.AKFIN_SIZECOMP \n\n-- 99904 is the AREA_ID that codes for the whole AI survey region\nWHERE AREA_ID = 99904\n-- including northern rock sole, southern rock sole, and rock sole unid.\nAND SPECIES_CODE IN (10260, 10261, 10262)\n-- remove the -9 LENGTH_MM code\nAND LENGTH_MM &gt; 0\n-- sum over species_codes and sexes\nGROUP BY (YEAR, LENGTH_MM)\")\n\n\ndat0 &lt;- dat |&gt; \n  janitor::clean_names() |&gt; \n  head() |&gt; \n  flextable::flextable() |&gt; \n  flextable::fit_to_width(max_width = 6) |&gt; \n  flextable::theme_zebra() |&gt;\n  flextable::colformat_num(j = \"year\", big.mark = \"\")\ndat0\n\nAI Rock sole size compositions and ridge plot.yearlength_cmpopulation_count1991234,625,2361991382,254,964199142820,61419915211,225199416741,2461994269,762,322\n\n\n\n# install.packages(\"ggridges\")\nlibrary(ggridges)\nfigure &lt;- ggplot(dat, \n                 mapping = aes(x = LENGTH_CM, \n                               y = YEAR, \n                               height = POPULATION_COUNT, \n                               group = YEAR)) +\n  ggridges::geom_density_ridges(stat = \"identity\", scale = 1) +\n  ggplot2::ylab(label = \"Year\") +\n  ggplot2::scale_x_continuous(name = \"Length (cm)\") +\n  ggplot2::labs(title = paste0('Aleutian Islands Rock sole Size Compositions'), \n                subtitle = paste0(min(dat$YEAR), ' – ', max(dat$YEAR))) +\n  ggplot2::theme_bw()\n\nfigure\n\n\n\n\nAI Rock sole size compositions and ridge plot.\n\n\n\n\n\n\n8.0.8 Ex. 2023 EBS Walleye Pollock Age Compositions and Age Pyramid\nWalleye pollock age composition for the EBS standard + NW Area from 2023, with age pyramid plot.\n\ndat &lt;- RODBC::sqlQuery(channel = channel, \n                       query = \"\n-- Manipulate data to join to\nWITH FILTERED_STRATA AS (\nSELECT \nAREA_ID, \nDESCRIPTION \nFROM GAP_PRODUCTS.AKFIN_AREA\n-- Filter for EBS Standard + NW Area \nWHERE AREA_ID = 99900)\n\n-- Select columns for output data\nSELECT \nAGECOMP.AGE, \nAGECOMP.POPULATION_COUNT, \nAGECOMP.SEX\n\n-- Identify what tables to pull data from\nFROM GAP_PRODUCTS.AKFIN_AGECOMP AGECOMP\nJOIN FILTERED_STRATA STRATA \nON STRATA.AREA_ID = AGECOMP.AREA_ID\n\n-- Filter data results\nWHERE SPECIES_CODE = 21740\nAND YEAR = 2023\nAND AGE &gt;= 0\")\n\n\ndat0 &lt;- dat |&gt; \n  janitor::clean_names() |&gt; \n  dplyr::filter(sex %in% c(1,2)) |&gt;\n  dplyr::mutate(\n    sex = ifelse(sex == 1, \"M\", \"F\"),\n    population_count = # change male population to negative\n      ifelse(sex==\"M\", population_count*(-1), population_count*1)/1e9) \n\nflextable::flextable(head(dat)) |&gt; \n  flextable::fit_to_width(max_width = 6) |&gt; \n  flextable::theme_zebra()\n\nEBS Walleye Pollock Age Compositions and Age Pyramid.AGEPOPULATION_COUNTSEX122,060,17212123,165,36913136,542,62514252,538,74715964,790,93916242,135,7201\n\n\n\nfigure &lt;- ggplot2::ggplot(\n  data = dat0, \n  mapping = \n    aes(x = age,\n        y = population_count, \n        fill = sex)) +\n  ggplot2::scale_fill_grey() +\n  ggplot2::geom_bar(stat = \"identity\") +\n  ggplot2::coord_flip() +\n  ggplot2::scale_x_continuous(name = \"Age\") +\n  ggplot2::scale_y_continuous(name = \"Population (billions)\", labels = abs) +\n  ggplot2::ggtitle(label = \"2023 EBS (Standard Area + NW) walleye pollock Age Composition\")  + \n  ggplot2::guides(fill = guide_legend(title = \"Sex\"))+\n  ggplot2::theme_bw()\n\nfigure\n\n\n\n\n2023 EBS Walleye Pollock Age Compositions and Age Pyramid.\n\n\n\n\n\n\n8.0.9 Ex. NBS Pacific cod biomass and abundance\nPacific cod biomass and abundance data for the NBS by stratum.\n\ndat &lt;- RODBC::sqlQuery(channel = channel, \n                       query = \n                         \"\nSELECT YEAR, AREA_ID AS STRATUM, AREA_NAME, BIOMASS_MT, POPULATION_COUNT \nFROM GAP_PRODUCTS.AKFIN_BIOMASS\n\nJOIN ( -- join with area table\nSELECT AREA_ID, AREA_NAME\nFROM GAP_PRODUCTS.AKFIN_AREA\nWHERE AREA_TYPE = 'STRATUM'\nAND SURVEY_DEFINITION_ID = 143\nAND DESIGN_YEAR = 2022)\n\nUSING (AREA_ID)\n\n-- Filter data results to NBS Pacific cod\nWHERE SURVEY_DEFINITION_ID IN 143 \nAND SPECIES_CODE = 21720\nORDER BY YEAR, STRATUM\")\n\n\ndat0 &lt;- dat |&gt; \n  janitor::clean_names() |&gt; \n  dplyr::select(year, area_name, biomass_mt, population_count) |&gt;\n  pivot_longer(cols = c(\"biomass_mt\", \"population_count\"), \n               names_to = \"var\", \n               values_to = \"val\") |&gt; \n  dplyr::mutate(\n    val = ifelse(var == \"biomass_mt\", val/1e6, val/1e9), \n    var = ifelse(var == \"biomass_mt\", \"Biomass (Mmt)\", \"Population (B)\"), \n    area = factor(area_name, levels = unique(area_name), labels = unique(area_name), ordered = TRUE))\nflextable::flextable(dat) |&gt; \n  flextable::fit_to_width(max_width = 6) |&gt; \n  flextable::theme_zebra() |&gt;\n  flextable::colformat_num(j = \"YEAR\", big.mark = \"\")\n\nNBS Pacific cod biomass and abundance.YEARSTRATUMAREA_NAMEBIOMASS_MTPOPULATION_COUNT201070Inner Domain7,462.55864,724,153201071Inner Domain20,983.37573,928,600201081Middle Domain680.4357250,837201770Inner Domain132,490.151866,187,245201771Inner Domain147,971.454265,078,489201781Middle Domain7,089.87404,191,118201970Inner Domain107,096.7296102,734,142201971Inner Domain194,846.723073,495,085201981Middle Domain63,061.278625,926,805202170Inner Domain95,849.983368,767,498202171Inner Domain53,814.633217,941,471202181Middle Domain77,917.108342,991,939202270Inner Domain96,500.697560,433,135202271Inner Domain26,747.074710,447,602202281Middle Domain30,487.278215,157,597202370Inner Domain76,708.432739,605,860202371Inner Domain19,130.00468,459,469202381Middle Domain12,507.85664,128,368202570Inner Domain48,587.674531,324,540202571Inner Domain11,129.22874,456,827202581Middle Domain9,665.66217,262,957\n\n\n\nfigure &lt;- ggplot2::ggplot(\n  dat = dat0, \n  mapping = aes(y = val, x = year, fill = area))  + \n  ggplot2::geom_bar(position=\"stack\", stat=\"identity\") +  \n  ggplot2::facet_grid(rows = vars(var), scales = \"free_y\") +\n  ggplot2::scale_y_continuous(name = \"Estimate\", labels = comma) +\n  ggplot2::scale_x_continuous(name = \"Year\", breaks = unique(dat0$year)) +\n  ggplot2::labs(title = 'NBS Pacific cod biomass and abundance by stratum')  + \n  ggplot2::guides(fill=guide_legend(title = \"Domain Type \"))+\n  ggplot2::scale_fill_grey() +\n  ggplot2::theme_bw() +\n  ggplot2::theme(legend.direction = \"horizontal\", \n                 legend.position = \"bottom\")\n\nfigure\n\n\n\n\nNBS Pacific cod biomass and abundance.\n\n\n\n\n\n\n8.0.10 Ex. GOA Pacific Ocean perch biomass and line plot\nPacific Ocean perch biomass totals for GOA between 1984-2021 from GAP_PRODUCTS.AKFIN_BIOMASS\n\ndat &lt;- RODBC::sqlQuery(channel = channel,\n                       query = \"\n-- Select columns for output data\nSELECT\nSURVEY_DEFINITION_ID,\nBIOMASS_MT / 1000000 AS BIOMASS_MMT,\n(BIOMASS_MT - 2 * SQRT(BIOMASS_VAR)) / 1000000 AS BIOMASS_CI_DW,\n(BIOMASS_MT + 2 * SQRT(BIOMASS_VAR)) / 1000000 AS BIOMASS_CI_UP,\nYEAR\n\n-- Identify what tables to pull data from\nFROM GAP_PRODUCTS.AKFIN_BIOMASS\n\n-- Filter data results\nWHERE SPECIES_CODE = 30060\nAND SURVEY_DEFINITION_ID = 47\nAND AREA_ID = 99903\nAND YEAR BETWEEN 1990 AND 2023\" ) |&gt; \n  janitor::clean_names()\n\n\nflextable::flextable(head(dat)) |&gt;\n  flextable::fit_to_width(max_width = 6) |&gt; \n  flextable::theme_zebra() |&gt;\n  flextable::colformat_num(j = \"year\", big.mark = \"\")\n\nGOA Pacific Ocean perch biomass and line plot.survey_definition_idbiomass_mmtbiomass_ci_dwbiomass_ci_upyear470.15583020.061813700.24984671990470.47966870.265963290.69337411993470.76517050.360445981.16989501996470.7243655-0.052380291.50111131999470.67236730.229033751.11570082001470.45438990.310773530.59800632003\n\n\n\na_mean &lt;- dat |&gt; \n  dplyr::group_by(survey_definition_id) |&gt; \n  dplyr::summarise(biomass_mmt = mean(biomass_mmt, na.rm = TRUE), \n                   minyr = min(year, na.rm = TRUE), \n                   maxyr = max(year, na.rm = TRUE)) \n\nfigure &lt;-\n  ggplot(data = dat, \n         mapping = aes(x = year, \n                       y = biomass_mmt)) +\n  ggplot2::geom_point(size = 2.5, color = \"grey40\") + \n  ggplot2::scale_x_continuous(\n    name = \"Year\", \n    labels = scales::label_number(\n      accuracy = 1, \n      big.mark = \"\"))   +\n  ggplot2::scale_y_continuous(\n    name = \"Biomass (Mmt)\", \n    labels = comma) +\n  ggplot2::geom_segment(\n    data = a_mean,\n    mapping = aes(x = minyr, \n                  xend = maxyr, \n                  y = biomass_mmt, \n                  yend = biomass_mmt),\n    linetype = \"dashed\", \n    linewidth = 2) +\n  ggplot2::geom_errorbar(\n    mapping = aes(ymin = biomass_ci_dw, ymax = biomass_ci_up),\n    position = position_dodge(.9),\n    alpha = 0.5, width=.2) +\n  ggplot2::ggtitle(\n    label = \"GOA Pacific Ocean Perch Biomass 1984-2021\", \n    subtitle = paste0(\"Mean = \", \n                      formatC(x = a_mean$biomass_mmt, \n                              digits = 2, \n                              big.mark = \",\", \n                              format = \"f\"), \n                      \" Mmt\")) +\n  ggplot2::theme_bw()\n\nfigure\n\n\n\n\nGOA Pacific Ocean perch biomass and line plot.\n\n\n\n\n\n\n8.0.11 Ex. 2022 AI Atka mackerel age specimen summary\n\nAll ages determined:\n\ndat &lt;- RODBC::sqlQuery(channel = channel,\n                       query = \"\n-- Select columns for output data\nSELECT SURVEY_DEFINITION_ID, YEAR, SPECIES_CODE, AGE\n\n-- Identify what tables to pull data from\nFROM GAP_PRODUCTS.AKFIN_SPECIMEN\nJOIN (SELECT HAULJOIN, CRUISEJOIN FROM GAP_PRODUCTS.AKFIN_HAUL)\nUSING (HAULJOIN)\nJOIN (SELECT CRUISEJOIN, YEAR, SURVEY_DEFINITION_ID FROM GAP_PRODUCTS.AKFIN_CRUISE)\nUSING (CRUISEJOIN)\n\n-- Filter data results\nWHERE GAP_PRODUCTS.AKFIN_SPECIMEN.SPECIMEN_SAMPLE_TYPE = 1\nAND SPECIES_CODE = 21921\nAND YEAR = 2022\nAND SURVEY_DEFINITION_ID = 52\") |&gt; \n  janitor::clean_names()\n\n\nflextable::flextable(head(dat) |&gt; \n                       dplyr::arrange(age)) |&gt;\n  flextable::fit_to_width(max_width = 6) |&gt; \n  flextable::theme_zebra() |&gt;\n  flextable::colformat_num(j = c(\"year\", \"species_code\"), big.mark = \"\")\n\n2022 AI Atka mackerel age specimen summary: all ages determined.survey_definition_idyearspecies_codeage522022219213522022219213522022219214522022219214522022219214522022219217\n\n\n\n\nHow many of each age was found:\n\ndat &lt;- RODBC::sqlQuery(channel = channel,\n                       query = \"\n-- Select columns for output data\nSELECT SURVEY_DEFINITION_ID, YEAR, SPECIES_CODE, AGE, \nCOUNT(AGE) AS COUNTAGE\n\n-- Identify what tables to pull data from\nFROM GAP_PRODUCTS.AKFIN_SPECIMEN\nJOIN (SELECT HAULJOIN, CRUISEJOIN FROM GAP_PRODUCTS.AKFIN_HAUL)\nUSING (HAULJOIN)\nJOIN (SELECT CRUISEJOIN, YEAR, SURVEY_DEFINITION_ID FROM GAP_PRODUCTS.AKFIN_CRUISE)\nUSING (CRUISEJOIN)\n\n-- Filter data results\nWHERE AGE &gt;= 0\nAND SPECIES_CODE = 21921\nAND YEAR = 2022\nAND SURVEY_DEFINITION_ID = 52\nGROUP BY (YEAR, SURVEY_DEFINITION_ID, SPECIES_CODE, AGE)\n\nORDER BY AGE\") |&gt; \n  janitor::clean_names()\n\n\nflextable::flextable(dat) |&gt; \n  flextable::fit_to_width(max_width = 6) |&gt; \n  flextable::theme_zebra() |&gt;\n  flextable::colformat_num(j = c(\"year\", \"species_code\"), big.mark = \"\")\n\nEx.: 2022 AI Atka mackerel age specimen summary: how many of each age\nwere determined.survey_definition_idyearspecies_codeagecountage52202221921115220222192124052202221921329552202221921411952202221921513052202221921611652202221921710852202221921861522022219219885220222192110735220222192111205220222192112952202221921131\n\n\n\n\nHow many otoliths were aged:\nUsing SQL\n\ndat &lt;- RODBC::sqlQuery(channel = channel,\n                       query = \"\n-- Select columns for output data\nSELECT SURVEY_DEFINITION_ID, YEAR, SPECIES_CODE, \nCOUNT(AGE) AS COUNTAGE\n\n-- Identify what tables to pull data from\nFROM GAP_PRODUCTS.AKFIN_SPECIMEN\nJOIN (SELECT HAULJOIN, CRUISEJOIN FROM GAP_PRODUCTS.AKFIN_HAUL)\nUSING (HAULJOIN)\nJOIN (SELECT CRUISEJOIN, YEAR, SURVEY_DEFINITION_ID FROM GAP_PRODUCTS.AKFIN_CRUISE)\nUSING (CRUISEJOIN)\n\n-- Filter data results\nWHERE GAP_PRODUCTS.AKFIN_SPECIMEN.SPECIMEN_SAMPLE_TYPE = 1\nAND SPECIES_CODE = 21921\nAND YEAR = 2022\nAND SURVEY_DEFINITION_ID = 52\nGROUP BY (YEAR, SURVEY_DEFINITION_ID, SPECIES_CODE)\") |&gt; \n  janitor::clean_names()\n\nUsing dbplyr:\n\nlibrary(odbc)\nlibrary(keyring)\nlibrary(dplyr)\nlibrary(dbplyr)\n\nchannel &lt;- DBI::dbConnect(odbc::odbc(), \"akfin\", uid = keyring::key_list(\"akfin\")$username,\n                        pwd = keyring::key_get(\"akfin\", keyring::key_list(\"akfin\")$username))\n\ndat &lt;- dplyr::tbl(src = channel, dplyr::sql('gap_products.akfin_specimen')) |&gt; \n    dplyr::rename_all(tolower) |&gt; \n    dplyr::select(hauljoin, specimen = specimen_id, species_code, length = length_mm, \n                  weight = weight_g, age, sex, age_method = age_determination_method) |&gt; \n    dplyr::left_join(dplyr::tbl(akfin, dplyr::sql('gap_products.akfin_haul')) |&gt;\n                       dplyr::rename_all(tolower) |&gt; \n                       dplyr::select(cruisejoin, hauljoin, haul, date_collected = date_time_start, \n                                     latitude = latitude_dd_start, longitude = longitude_dd_start),\n                     by = join_by(hauljoin)) |&gt; \n    dplyr::left_join(dplyr::tbl(akfin, dplyr::sql('gap_products.akfin_cruise')) |&gt;\n                       dplyr::rename_all(tolower) |&gt; \n                       dplyr::select(cruisejoin, year, vessel = vessel_id, survey_definition_id),\n                     by = join_by(cruisejoin)) |&gt; \n    dplyr::filter(year == YEAR &\n             survey_definition_id == 52 & \n             species_code %in% spp_codes &\n             !is.na(age)) |&gt; \n    dplyr::collect()\n\nBoth scripts will produce this table:\n\nflextable::flextable(head(dat)) |&gt;\n  flextable::fit_to_width(max_width = 6) |&gt; \n  flextable::theme_zebra() |&gt;\n  flextable::colformat_num(j = c(\"year\", \"species_code\"), big.mark = \"\")\n\n2022 AI Atka mackerel age specimen summary: how many otoliths were\naged. This quiery was created using SQL.survey_definition_idyearspecies_codecountage522022219211,061",
    "crumbs": [
      "AKFIN",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Access data via Oracle and R</span>"
    ]
  },
  {
    "objectID": "content/akfin-api-r.html",
    "href": "content/akfin-api-r.html",
    "title": "Access API data via R",
    "section": "",
    "text": "9.0.1 Load packages and helpful functions\nAKFIN has developed web services (apis) to distribute GAP data. Like the GAP_PRODUCTS schema, these are under active development. These do not require VPN or an oracle connection but they are protected by Oracle authentication, please contact matt.callahan@noaa.gov for information on how to get an api token to use this option.\nThe url structure is “https://apex.psmfc.org/akfin/data_marts/gap_products/gap_[base table name]” . For example “https://apex.psmfc.org/akfin/data_marts/gap_products/gap_biomass” is the base url to get data from the akfin_biomass table. Web services linked to large tables have mandatory parameters to reduce data download size. For example to get agecomp data for Bering Sea pollock in area_id 10 in 2022 you would use “https://apex.psmfc.org/akfin/data_marts/gap_products/gap_biomass?survey_definition_id=98&area_id=10&species_code=21740&start_year=2022&end_year=2022”.\nIf you’re using R to pull data through web services you might find the akfingapdata (pronounced akfin-gap-data not ak-eff-ing-app-data) R package helpful.",
    "crumbs": [
      "AKFIN",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Access API data via R</span>"
    ]
  },
  {
    "objectID": "content/akfin-api-r.html#ex.-direct-database-query-in-r-using-the-akfingapdata-r-package-readme",
    "href": "content/akfin-api-r.html#ex.-direct-database-query-in-r-using-the-akfingapdata-r-package-readme",
    "title": "Access API data via R",
    "section": "9.1 Ex. Direct database query in R using the akfingapdata R package README:",
    "text": "9.1 Ex. Direct database query in R using the akfingapdata R package README:\nSign into akfin with token (need to request token from AKFIN)\n\nakfingapdata::get_gap_catch()[,1:6] |&gt; \n  head() |&gt; \n  flextable::flextable() |&gt;\n  flextable::theme_zebra()",
    "crumbs": [
      "AKFIN",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Access API data via R</span>"
    ]
  },
  {
    "objectID": "content/foss-intro.html",
    "href": "content/foss-intro.html",
    "title": "Public Data (FOSS)",
    "section": "",
    "text": "Collaborators and data users\nThe final, validated survey data are publicly accessible soon after surveys are completed on the Fisheries One Stop Shop (FOSS) platform. This data includes catch, haul, and environmental data collected at each station. On the FOSS data platform, users can interactively select, view, and download data. Descriptive documentation and user-examples are available on the metadata page.\nThis data contains all of the catch, environmental, and haul data from the fisheries-independent Groundfish and Shellfish Assessment Program surveys in the Bering Sea, Aleutian Islands, and Gulf of Alaska. This data is sought after by the general public, private entities, and NOAA partners alike, including tribal organizations, K-12 classrooms, academic institutions, for-profit groups, and non-profit groups. This data is compiled and approved once a year after each summer survey season and is available for open access.\nBelow are a few packages and products currently using this data. If you have developed a product, performed an analysis, or exhibited this data in any way, reach out so we can showcase your hard work.",
    "crumbs": [
      "Public Data (FOSS)"
    ]
  },
  {
    "objectID": "content/foss-intro.html#access-constraints",
    "href": "content/foss-intro.html#access-constraints",
    "title": "Public Data (FOSS)",
    "section": "Access Constraints",
    "text": "Access Constraints\nUser Constraints: Users must read and fully comprehend the metadata prior to use. Data should not be used beyond the limits of the source scale. Acknowledgment of AFSC Groundfish Assessment Program, as the source from which these data were obtained, in any publications and/or other representations of these data, is suggested.\nGeneral questions and more specific data requests can be sent to nmfs.afsc.gap.metadata@noaa.gov or submitted as an issue on our GitHub Organization. The version of this data used for stock assessments can be found through the Alaska Fisheries Information Network (AKFIN). For questions about the eastern Bering Sea surveys, contact Duane Stevenson (Duane.Stevenson@noaa.gov). For questions about the Gulf of Alaska or Aleutian Islands surveys, contact Ned Laman (Ned.Laman@noaa.gov). For questions specifically about crab data in any region, contact Mike Litzow (Mike.Litzow@noaa.gov), the Shellfish Assessment Program lead.\nFor questions, comments, and concerns specifically about the Fisheries One Stop Shop (FOSS) platform, please contact us using the Comments page on the FOSS webpage.",
    "crumbs": [
      "Public Data (FOSS)"
    ]
  },
  {
    "objectID": "content/foss-intro.html#cite-this-data",
    "href": "content/foss-intro.html#cite-this-data",
    "title": "Public Data (FOSS)",
    "section": "Cite this data",
    "text": "Cite this data\nUse the below bibtext citation, as cited in our group’s citation repository for citing the data created and maintained in this repository. Add “note = {Accessed: mm/dd/yyyy}” to append the day this data was accessed.\n\n\n[1] \"@misc{FOSSAFSCData,\"                                                                           \n[2] \"  author = {{NOAA Fisheries Alaska Fisheries Science Center}},\"                                \n[3] \"  year = {2024}, \"                                                                             \n[4] \"  title = {Fisheries One Stop Shop Public Data: RACE Division Bottom Trawl Survey Data Query},\"\n[5] \"  howpublished = {https://www.fisheries.noaa.gov/foss},\"                                       \n[6] \"  publisher = {{U.S. Dep. Commer.}},\"                                                          \n[7] \"  copyright = {Public Domain} \"                                                                \n[8] \"}\"",
    "crumbs": [
      "Public Data (FOSS)"
    ]
  },
  {
    "objectID": "content/foss-metadata.html",
    "href": "content/foss-metadata.html",
    "title": "Data description",
    "section": "",
    "text": "Data tables\nThe Resource Assessment and Conservation Engineering Division (RACE) Groundfish Assessment Program (GAP) of the Alaska Fisheries Science Center (AFSC) conducts fisheries-independent bottom trawl surveys to monitor the condition of the demersal fish and crab stocks of Alaska. These data are developed to describe the temporal distribution and abundance of commercially and ecologically important groundfish species, examine the changes in the species composition of the fauna over time and space, and describe the physical environment of the groundfish habitat.\nThere are no legal restrictions on access to the data. They reside in the public domain and can be freely distributed. Users must read and fully comprehend the metadata prior to use. Data should not be used beyond the limits of the source scale. Acknowledgement of NOAA, as the source from which these data were obtained, in any publications and/or other representations of these data, is suggested. These data are compiled and approved annually after each summer survey season. The data from previous years are unlikely to change substantially once published.\nThese data are zero-filled (presence and absence) observations from surveys conducted on fishing vessels. These surveys monitor trends in distribution and abundance of groundfish, crab, and bottom-dwelling species in Alaska’s marine ecosystems. These data include estimates of catch-per-unit-effort (CPUE) for all identified species for index stations. Some survey data are excluded, such as non-standard stations, surveys completed in earlier years using different/non-standard gear, and special tows and non-standard data collections.\nThough not included in the public data, these surveys also collect oceanographic and environmental data, and biological data such as length, weight, stomach contents (to learn more about diet), otoliths (fish ear bones to learn about age), and tissue samples for genetic analysis, all of which can be shared upon special request. Also not included in the public data are estimated biomass (average total weight of all fish and crabs sampled) of crabs and groundfish that support the creation of annual stock assessments.",
    "crumbs": [
      "Public Data (FOSS)",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Data description</span>"
    ]
  },
  {
    "objectID": "content/foss-metadata.html#data-tables",
    "href": "content/foss-metadata.html#data-tables",
    "title": "Data description",
    "section": "",
    "text": "FOSS_CATCH\nsnapshot table for snapshot GAP_PRODUCTS.FOSS_CATCH\nNumber of rows: 917,401\nNumber of columns: 7\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nCPUE_NOKM2\n\n\nNumber CPUE (no/km2)\n\n\ncount per kilometers squared\n\n\nNUMBER(38,6)\n\n\nNumerical catch per unit effort (area swept by the net, units square kilometers).\n\n\n\n\nCOUNT\n\n\nTaxon count\n\n\ncount, whole number resolution\n\n\nNUMBER(38,0)\n\n\nTotal whole number of individuals caught in haul or samples collected.\n\n\n\n\nWEIGHT_KG\n\n\nSample or taxon weight (kg)\n\n\nkilograms\n\n\nNUMBER(38,3)\n\n\nWeight (thousandths of a kilogram) of individuals in a haul by taxon.\n\n\n\n\nTAXON_CONFIDENCE\n\n\nTaxon confidence rating\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nConfidence in the ability of the survey team to correctly identify the taxon to the specified level, based solely on identification skill (e.g., not likelihood of a taxon being caught at that station on a location-by-location basis). Quality codes follow: High: High confidence and consistency. Taxonomy is stable and reliable at this level, and field identification characteristics are well known and reliable. Moderate: Moderate confidence. Taxonomy may be questionable at this level, or field identification characteristics may be variable and difficult to assess consistently. Low: Low confidence. Taxonomy is incompletely known, or reliable field identification characteristics are unknown. Documentation: Species identification confidence in the eastern Bering Sea shelf survey (1982-2008), Species identification confidence in the eastern Bering Sea slope survey (1976-2010), and Species identification confidence in the Gulf of Alaska and Aleutian Islands surveys (1980-2011).\n\n\n\n\nHAULJOIN\n\n\nHaul ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThis is a unique numeric identifier assigned to each (vessel, cruise, and haul) combination.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the common_name and scientific_name columns. For a complete species list, review the code books.\n\n\n\n\nCPUE_KGKM2\n\n\nWeight CPUE (kg/km2)\n\n\nkilograms per kilometers squared\n\n\nNUMBER(38,6)\n\n\nCatch weight (kilograms) per unit effort (area swept by the net, units square kilometers).\n\n\n\n\n\n\nFOSS_HAUL\nsnapshot table for snapshot GAP_PRODUCTS.FOSS_HAUL\nNumber of rows: 34,839\nNumber of columns: 27\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nYEAR\n\n\nSurvey year\n\n\nyear\n\n\nNUMBER(10,0)\n\n\nYear the observation (survey) was collected.\n\n\n\n\nSRVY\n\n\nSurvey abbreviation\n\n\ntext abbreviated\n\n\nVARCHAR2(255 BYTE)\n\n\nAbbreviated survey names. The column srvy is associated with the survey and survey_definition_id columns. Northern Bering Sea (NBS), Southeastern Bering Sea (EBS), Bering Sea Slope (BSS), Gulf of Alaska (GOA), Aleutian Islands (AI).\n\n\n\n\nSURVEY\n\n\nSurvey name\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nName and description of survey. The column survey is associated with the srvy and survey_definition_id columns.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code is an integer that uniquely identifies a survey region/survey design. The column survey_definition_id is associated with the srvy and survey columns. Full list of survey definition IDs are in RACE_DATA.SURVEY_DEFINITIONS and in the code books.\n\n\n\n\nSURVEY_NAME\n\n\nSurvey name official\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nLong name of the survey conducted\n\n\n\n\nCRUISE\n\n\nCruise Name\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThis is a six-digit integer identifying the cruise number of the form: YYYY99 (where YYYY = year of the cruise; 99 = 2-digit number and is sequential; 01 denotes the first cruise that vessel made in this year, 02 is the second, etc.).\n\n\n\n\nCRUISEJOIN\n\n\nCruise ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nUnique integer ID assigned to each survey, vessel, and year combination.\n\n\n\n\nHAULJOIN\n\n\nHaul ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThis is a unique numeric identifier assigned to each (vessel, cruise, and haul) combination.\n\n\n\n\nHAUL\n\n\nHaul number\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThis number uniquely identifies a sampling event (haul) within a cruise. It is a sequential number, in chronological order of occurrence.\n\n\n\n\nSTRATUM\n\n\nStratum ID\n\n\nID key code\n\n\nNUMBER(10,0)\n\n\nRACE database statistical area for analyzing data. Strata were designed using bathymetry and other geographic and habitat-related elements. The strata are unique to each survey region. Stratum of value 0 indicates experimental tows.\n\n\n\n\nSTATION\n\n\nStation ID\n\n\nID key code\n\n\nVARCHAR2(255 BYTE)\n\n\nAlpha-numeric designation for the station established in the design of a survey.\n\n\n\n\nVESSEL_ID\n\n\nVessel ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nID number of the vessel used to collect data for that haul. The column vessel_id is associated with the vessel_name column. Note that it is possible for a vessel to have a new name but the same vessel id number. For a complete list of vessel ID key codes, review the code books.\n\n\n\n\nVESSEL_NAME\n\n\nVessel name\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nName of the vessel used to collect data for that haul. The column vessel_name is associated with the vessel_id column. Note that it is possible for a vessel to have a new name but the same vessel id number. For a complete list of vessel ID key codes, review the code books.\n\n\n\n\nDATE_TIME\n\n\nDate and time\n\n\nMM/DD/YYYY HH::MM\n\n\nDATE\n\n\nThe date (MM/DD/YYYY) and time (HH:MM) of the haul. All dates and times are in Alaska time (AKDT) of Anchorage, AK, USA (UTC/GMT -8 hours).\n\n\n\n\nLATITUDE_DD_START\n\n\nStart latitude (decimal degrees)\n\n\ndecimal degrees\n\n\nNUMBER(38,6)\n\n\nLatitude (one hundred thousandth of a decimal degree) of the start of the haul.\n\n\n\n\nLONGITUDE_DD_START\n\n\nStart longitude (decimal degrees)\n\n\ndecimal degrees\n\n\nNUMBER(38,6)\n\n\nLongitude (one hundred thousandth of a decimal degree) of the start of the haul.\n\n\n\n\nLATITUDE_DD_END\n\n\nEnd latitude (decimal degrees)\n\n\ndecimal degrees\n\n\nNUMBER(38,6)\n\n\nLatitude (one hundred thousandth of a decimal degree) of the end of the haul.\n\n\n\n\nLONGITUDE_DD_END\n\n\nEnd longitude (decimal degrees)\n\n\ndecimal degrees\n\n\nNUMBER(38,6)\n\n\nLongitude (one hundred thousandth of a decimal degree) of the end of the haul.\n\n\n\n\nBOTTOM_TEMPERATURE_C\n\n\nBottom temperature (degrees Celsius)\n\n\ndegrees Celsius\n\n\nNUMBER(38,1)\n\n\nBottom temperature (tenths of a degree Celsius); NA indicates removed or missing values.\n\n\n\n\nSURFACE_TEMPERATURE_C\n\n\nSurface temperature (degrees Celsius)\n\n\ndegrees Celsius\n\n\nNUMBER(38,1)\n\n\nSurface temperature (tenths of a degree Celsius); NA indicates removed or missing values.\n\n\n\n\nDEPTH_M\n\n\nDepth (m)\n\n\ndegrees Celsius\n\n\nNUMBER(38,1)\n\n\nBottom depth (meters).\n\n\n\n\nDISTANCE_FISHED_KM\n\n\nDistance fished (km)\n\n\nkilometers\n\n\nNUMBER(38,3)\n\n\nDistance the net fished (kilometers).\n\n\n\n\nDURATION_HR\n\n\nTow duration (decimal hr)\n\n\nhours\n\n\nNUMBER(38,1)\n\n\nThis is the elapsed time between start and end of a haul (decimal hours).\n\n\n\n\nNET_WIDTH_M\n\n\nNet width (m)\n\n\nmeters\n\n\nNUMBER(38,1)\n\n\nMeasured or estimated distance (meters) between wingtips of the trawl.\n\n\n\n\nNET_HEIGHT_M\n\n\nNet height (m)\n\n\nmeters\n\n\nNUMBER(38,1)\n\n\nMeasured or estimated distance (meters) between footrope and headrope of the trawl.\n\n\n\n\nAREA_SWEPT_KM2\n\n\nArea swept (km)\n\n\nkilometers\n\n\nNUMBER(38,6)\n\n\nThe area the net covered while the net was fishing (kilometers squared), defined as the distance fished times the net width.\n\n\n\n\nPERFORMANCE\n\n\nHaul performance code\n\n\ncategory\n\n\nNUMBER(38,0)\n\n\nThis denotes what, if any, issues arose during the haul. For more information, review the code books.\n\n\n\n\n\n\nFOSS_SPECIES\nsnapshot table for snapshot GAP_PRODUCTS.FOSS_SPECIES\nNumber of rows: 1,000\nNumber of columns: 7\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the common_name and scientific_name columns. For a complete species list, review the code books.\n\n\n\n\nSCIENTIFIC_NAME\n\n\nTaxon scientific name\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nThe scientific name of the organism associated with the common_name and species_code columns. For a complete taxon list, review the code books.\n\n\n\n\nCOMMON_NAME\n\n\nTaxon common name\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nThe common name of the marine organism associated with the scientific_name and species_code columns. For a complete species list, review the code books.\n\n\n\n\nID_RANK\n\n\nLowest taxonomic rank\n\n\ntext\n\n\nVARCHAR2(255 BYTE)\n\n\nLowest taxonomic rank of a given species entry.\n\n\n\n\nWORMS\n\n\nWorld register of marine species (WoRMS) taxonomic serial number\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nSpecies code as identified in the World Register of Marine Species (WoRMS) (https://www.marinespecies.org/).\n\n\n\n\nITIS\n\n\nIntegrated taxonomic information system (ITIS) serial number\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nSpecies code as identified in the Integrated Taxonomic Information System (https://itis.gov/).\n\n\n\n\n\n\nFOSS_SURVEY_SPECIES\nsnapshot table for snapshot GAP_PRODUCTS.FOSS_SURVEY_SPECIES\nNumber of rows: 2,746\nNumber of columns: 2\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the common_name and scientific_name columns. For a complete species list, review the code books.\n\n\n\n\nSURVEY_DEFINITION_ID\n\n\nSurvey ID\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe survey definition ID key code is an integer that uniquely identifies a survey region/survey design. The column survey_definition_id is associated with the srvy and survey columns. Full list of survey definition IDs are in RACE_DATA.SURVEY_DEFINITIONS and in the code books.\n\n\n\n\n\n\nFOSS_TAXON_GROUP\nsnapshot table for snapshot GAP_PRODUCTS.FOSS_TAXON_GROUP\nNumber of rows: 10,309\nNumber of columns: 3\n\n\n\n\nColumn name from data\n\n\nDescriptive column Name\n\n\nUnits\n\n\nOracle data type\n\n\nColumn description\n\n\n\n\n\n\nRANK_ID\n\n\nTaxonomic rank\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nThe taxonomic rank of a taxon identification.\n\n\n\n\nCLASSIFICATION\n\n\nTaxonomic classification rank group\n\n\ncategory\n\n\nVARCHAR2(255 BYTE)\n\n\nPhylogenetic classification group rank for a given species.\n\n\n\n\nSPECIES_CODE\n\n\nTaxon code\n\n\nID key code\n\n\nNUMBER(38,0)\n\n\nThe species code of the organism associated with the common_name and scientific_name columns. For a complete species list, review the code books.",
    "crumbs": [
      "Public Data (FOSS)",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Data description</span>"
    ]
  },
  {
    "objectID": "content/foss-platform.html",
    "href": "content/foss-platform.html",
    "title": "Using the FOSS platform",
    "section": "",
    "text": "Select and filter\nAFSC Groundfish and Crab Assessment Program Bottom Trawl Survey data interface on the Fisheries One Stop Shop platform.\nSelect, filter, and download this and other NOAA Fisheries data from the Fisheries One Stop Shop (FOSS) platform. A user guide for the FOSS platform can be found here. To begin a report, select the kind of data you need: Haul and catch data, Haul data only, All observed species.",
    "crumbs": [
      "Public Data (FOSS)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Using the FOSS platform</span>"
    ]
  },
  {
    "objectID": "content/foss-platform.html#select-and-filter",
    "href": "content/foss-platform.html#select-and-filter",
    "title": "Using the FOSS platform",
    "section": "",
    "text": "In this example, we’ll select for 2023 eastern Bering Sea Arctic cod data. Here, we used the Search Species box to search for species with the term “cod” in their common names and selected “Pacific cod” from that shortened list.\n\n\nCatch and haul\n\n\n\n\n\nCatch data on the AFSC Groundfish and Crab Assessment Program Bottom Trawl Survey data interface on the Fisheries One Stop Shop platform.\n\n\n\n\n\n\nHaul\n\n\n\n\n\nHaul data on the AFSC Groundfish and Crab Assessment Program Bottom Trawl Survey data interface on the Fisheries One Stop Shop platform.\n\n\n\n\n\n\nSpecies\n\n\n\n\n\nAll species observed by survey on the AFSC Groundfish and Crab Assessment Program Bottom Trawl Survey data interface on the Fisheries One Stop Shop platform.",
    "crumbs": [
      "Public Data (FOSS)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Using the FOSS platform</span>"
    ]
  },
  {
    "objectID": "content/foss-platform.html#search-options",
    "href": "content/foss-platform.html#search-options",
    "title": "Using the FOSS platform",
    "section": "Search options",
    "text": "Search options\nThe user must select a option in each of the three option boxes as they appear for catch, haul, and species:\n\nSurvey: Each survey has different in design, time series, and history. More information on each survey and their designs can be found in our annual data reports.\nYear: Surveys are not conducted in all years, so only data from the years for which the survey was conducted will be returned.\nSpecies: Common name of all species ever encountered in the survey. Find more information about these species in our survey code books.\n\nFor a given box, select one or a few options from the options box (list on the left) to query. To select multiple options, hold down the CTRL key while clicking on the options of interest, or click and drag down the list. Once the options you wish to be included in your query are highlighted, click the right-pointing arrow (&gt;) to move them into the “selection box” (list on the right). This can also be achieved by double clicking the option item of interest. If you accidentally select an option that you do not want to query, simply select the unwanted option from the selection box and click the left-pointing arrow (&lt;).\nIf you wish to select all options from the options box and send them to the selection box, simply click the double right-pointing arrow (&gt;&gt;). If you want to unselect all options from the selection box, use the double left-pointing arrow (&lt;&lt;) or the reset icon.\nTo find a specific species or group more quickly you can use the Search Species option to quickly narrow the options. Search for parts of species common names in the Search Species box by entering a term and clicking the search button. The platform will return a shorter list in the Speices options box of only species that contain a match to that search term.\nUse the Reset All Parameters button to reset all parameters for entire form.\n\n\n\n\n\nDiagram of selection and search tools available on the FOSS platfrom.",
    "crumbs": [
      "Public Data (FOSS)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Using the FOSS platform</span>"
    ]
  },
  {
    "objectID": "content/foss-platform.html#run-report",
    "href": "content/foss-platform.html#run-report",
    "title": "Using the FOSS platform",
    "section": "Run report",
    "text": "Run report\nClick the RUN REPORT button. Below the select and filter area, the results of your query will appear below the page in the format you selected. To change the format, make a different selection and run the report again. Further modifications to your results can be made by clicking on the Actions button above your data. Here you can download your data, select columns included in your results, and apply a variety of filters and mathematical tools.\n\n\n\n\n\nExample data returned from running the report.",
    "crumbs": [
      "Public Data (FOSS)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Using the FOSS platform</span>"
    ]
  },
  {
    "objectID": "content/foss-platform.html#api",
    "href": "content/foss-platform.html#api",
    "title": "Using the FOSS platform",
    "section": "API",
    "text": "API\nAPIs, or Application Programming Interfaces, allows users to pull data through a IDE, or integrated development environment, like RStudio or VS Code. Explore the API pages for each of the data pages (Haul and catch data, Haul data only, All observed species).",
    "crumbs": [
      "Public Data (FOSS)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Using the FOSS platform</span>"
    ]
  },
  {
    "objectID": "content/foss-api-r.html",
    "href": "content/foss-api-r.html",
    "title": "Access via API and R",
    "section": "",
    "text": "12.1 Ex. Load all rows of the catch, haul, and species data tables\nAn application programming interface (API) is a way for two or more computer programs to communicate with each other. More information about how to amend API links can be found here. Useful introductions to using APIs in R can be found here.\nThere are three tables the user can pull from the API. Learn more about them on the FOSS data description page. Here, you can see them in their raw JSON format:\nHere are some examples of how to use the data with R:\nNote that without specifying, a basic query to the API will only return 25 entries.",
    "crumbs": [
      "Public Data (FOSS)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Access via API and R</span>"
    ]
  },
  {
    "objectID": "content/foss-api-r.html#ex.-load-all-rows-of-the-catch-haul-and-species-data-tables",
    "href": "content/foss-api-r.html#ex.-load-all-rows-of-the-catch-haul-and-species-data-tables",
    "title": "Access via API and R",
    "section": "",
    "text": "12.1.1 Load haul data\n\n# link to the API\napi_link_haul &lt;- 'https://apps-st.fisheries.noaa.gov/ods/foss/afsc_groundfish_survey_haul/'\n\n\n12.1.1.1 Load first 25 rows of data\n\nres &lt;- httr::GET(url = api_link_haul)\n# res ## Test connection\n\n## convert from JSON format\ndat &lt;- jsonlite::fromJSON(base::rawToChar(res$content))$items\n\n# Find how many rows and columns are in the data pull\nprint(paste0(\"rows: \", nrow(dat), \"; cols: \", ncol(dat)))\n\n[1] \"rows: 25; cols: 28\"\n\n\n\n\n12.1.1.2 Load all data:\nSince the maxim number of rows a user can pull is 10,000 rows in a query, the user needs to cycle through by offsetting to the next 10,000 rows (as is shown here).\n\ndat &lt;- data.frame()\nfor (i in seq(0, 500000, 10000)){\n  ## find how many iterations it takes to cycle through the data\n  print(i)\n  ## query the API link\n  res &lt;- httr::GET(url = paste0(api_link_haul, \"?offset=\",i,\"&limit=10000\"))\n  ## convert from JSON format\n  data &lt;- jsonlite::fromJSON(base::rawToChar(res$content)) \n  \n  ## if there are no data, stop the loop\n  if (is.null(nrow(data$items))) {\n    break\n  }\n  \n  ## bind sub-pull to dat data.frame\n  dat &lt;- dplyr::bind_rows(dat, \n                          data$items |&gt;\n                            dplyr::select(-links)) # necessary for API accounting, but not part of the dataset)\n}\n\n[1] 0\n[1] 10000\n[1] 20000\n[1] 30000\n[1] 40000\n\n\nExplore the data contents:\n\n# Find how many rows and columns are in the data pull\nprint(paste0(\"rows: \", nrow(dat), \"; cols: \", ncol(dat)))\n\n[1] \"rows: 33991; cols: 27\"\n\n# learn about the structure of the data\nsummary(dat)\n\n      year          srvy              survey          survey_name       \n Min.   :1982   Length:33991       Length:33991       Length:33991      \n 1st Qu.:1997   Class :character   Class :character   Class :character  \n Median :2006   Mode  :character   Mode  :character   Mode  :character  \n Mean   :2005                                                           \n 3rd Qu.:2015                                                           \n Max.   :2024                                                           \n                                                                        \n survey_definition_id     cruise         cruisejoin         hauljoin      \n Min.   : 47.00       Min.   :198201   Min.   :   -770   Min.   : -23911  \n 1st Qu.: 47.00       1st Qu.:199701   1st Qu.:   -697   1st Qu.: -14104  \n Median : 78.00       Median :200601   Median :   -616   Median :  -4314  \n Mean   : 74.55       Mean   :200543   Mean   : 294616   Mean   : 289722  \n 3rd Qu.: 98.00       3rd Qu.:201501   3rd Qu.: 837799   3rd Qu.: 816124  \n Max.   :143.00       Max.   :202401   Max.   :1225395   Max.   :1225635  \n                                                                          \n      haul          stratum        station            vessel_id    \n Min.   :  1.0   Min.   : 10.0   Length:33991       Min.   :  1.0  \n 1st Qu.: 56.0   1st Qu.: 31.0   Class :character   1st Qu.: 88.0  \n Median :112.0   Median : 50.0   Mode  :character   Median : 94.0  \n Mean   :117.3   Mean   :130.9                      Mean   :107.8  \n 3rd Qu.:170.0   3rd Qu.:142.0                      3rd Qu.:147.0  \n Max.   :355.0   Max.   :794.0                      Max.   :178.0  \n                                                                   \n vessel_name         date_time         latitude_dd_start longitude_dd_start\n Length:33991       Length:33991       Min.   :51.19     Min.   :-180.0    \n Class :character   Class :character   1st Qu.:55.00     1st Qu.:-170.7    \n Mode  :character   Mode  :character   Median :57.16     Median :-165.3    \n                                       Mean   :56.86     Mean   :-139.6    \n                                       3rd Qu.:58.97     3rd Qu.:-154.4    \n                                       Max.   :65.34     Max.   : 180.0    \n                                                                           \n latitude_dd_end longitude_dd_end bottom_temperature_c surface_temperature_c\n Min.   :51.19   Min.   :-180.0   Min.   :-2.100       Min.   :-1.100       \n 1st Qu.:55.00   1st Qu.:-170.7   1st Qu.: 2.700       1st Qu.: 5.800       \n Median :57.16   Median :-165.3   Median : 4.100       Median : 7.400       \n Mean   :56.86   Mean   :-139.6   Mean   : 3.829       Mean   : 7.794       \n 3rd Qu.:58.96   3rd Qu.:-154.4   3rd Qu.: 5.200       3rd Qu.: 9.300       \n Max.   :65.35   Max.   : 180.0   Max.   :15.300       Max.   :18.100       \n NA's   :4       NA's   :4        NA's   :1601         NA's   :852          \n    depth_m       distance_fished_km  duration_hr      net_width_m   \n Min.   :   9.0   Min.   :0.135      Min.   :0.0250   Min.   : 7.51  \n 1st Qu.:  68.0   1st Qu.:1.497      1st Qu.:0.2710   1st Qu.:15.58  \n Median : 102.0   Median :2.528      Median :0.4900   Median :16.40  \n Mean   : 137.8   Mean   :2.206      Mean   :0.4006   Mean   :16.42  \n 3rd Qu.: 156.0   3rd Qu.:2.833      3rd Qu.:0.5090   3rd Qu.:17.21  \n Max.   :1200.0   Max.   :4.334      Max.   :0.9800   Max.   :23.82  \n                                                                     \n  net_height_m    area_swept_km2      performance    \n Min.   : 0.000   Min.   :0.002314   Min.   :0.0000  \n 1st Qu.: 2.383   1st Qu.:0.024261   1st Qu.:0.0000  \n Median : 5.865   Median :0.039562   Median :0.0000  \n Mean   : 4.822   Mean   :0.036378   Mean   :0.2779  \n 3rd Qu.: 6.788   3rd Qu.:0.047281   3rd Qu.:0.0000  \n Max.   :11.038   Max.   :0.077795   Max.   :7.0000  \n NA's   :3269                                        \n\n# Print the first few lines of the data \ndat |&gt; \n  head(3) |&gt; \n  flextable::flextable() |&gt;\n  flextable::colformat_num(\n      j = c(\"year\", \"cruise\", \"cruisejoin\"), \n      big.mark = \"\") |&gt; \n  flextable::theme_zebra()\n\nyearsrvysurveysurvey_namesurvey_definition_idcruisecruisejoinhauljoinhaulstratumstationvessel_idvessel_namedate_timelatitude_dd_startlongitude_dd_startlatitude_dd_endlongitude_dd_endbottom_temperature_csurface_temperature_cdepth_mdistance_fished_kmduration_hrnet_width_mnet_height_marea_swept_km2performance2004EBSeastern Bering SeaEastern Bering Sea Crab/Groundfish Bottom Trawl Survey9820040111956161,195,89511042HG201989ALDEBARAN2004-06-30T16:19:47Z57.17397-169.316257.14825-169.32043.89.1722.8690.5117.5322.2190.05029902004EBSeastern Bering SeaEastern Bering Sea Crab/Groundfish Bottom Trawl Survey9820040111956161,195,89611142G-2189ALDEBARAN2004-07-02T08:09:22Z56.99756-170.187856.99808-170.14004.77.9702.9120.5117.5002.2900.05096002004EBSeastern Bering SeaEastern Bering Sea Crab/Groundfish Bottom Trawl Survey9820040111956161,195,89711342HG212089ALDEBARAN2004-07-02T13:36:10Z57.15147-169.910057.17434-169.88745.07.7502.8910.5116.9992.3660.0491440\n\n# save outputs for later comparison\ndat_haul_api &lt;- dat\n\n\n\n\n12.1.2 Load catch data\n\n# link to the API\napi_link_catch &lt;- 'https://apps-st.fisheries.noaa.gov/ods/foss/afsc_groundfish_survey_catch/'\n\n\n12.1.2.1 Load first 25 rows of data\n\nres &lt;- httr::GET(url = api_link_catch)\n# res ## Test connection\n\n## convert from JSON format\ndat &lt;- jsonlite::fromJSON(base::rawToChar(res$content))$items\n\n# Find how many rows and columns are in the data pull\nprint(paste0(\"rows: \", nrow(dat), \"; cols: \", ncol(dat)))\n\n[1] \"rows: 25; cols: 8\"\n\n\n\n\n12.1.2.2 Load all data\nSince the maxim number of rows a user can pull is 10,000 rows in a query, the user needs to cycle through by offsetting to the next 10,000 rows (as is shown here).\n\ndat &lt;- data.frame()\n# for (i in seq(0, 100000, 10000)){\nfor (i in seq(0, 1000000, 10000)){\n  ## find how many iterations it takes to cycle through the data\n  # print(i)\n  ## query the API link\n  res &lt;- httr::GET(url = paste0(api_link_catch, \"?offset=\",i,\"&limit=10000\"))\n  ## convert from JSON format\n  data &lt;- jsonlite::fromJSON(base::rawToChar(res$content)) \n  \n  ## if there are no data, stop the loop\n  if (is.null(nrow(data$items))) {\n    break\n  }\n  \n  ## bind sub-pull to dat data.frame\n  dat &lt;- dplyr::bind_rows(dat, \n                          data$items |&gt;\n                            dplyr::select(-links)) # necessary for API accounting, but not part of the dataset)\n}\n\nExplore the data contents:\n\n# Find how many rows and columns are in the data pull\nprint(paste0(\"rows: \", nrow(dat), \"; cols: \", ncol(dat)))\n\n[1] \"rows: 891144; cols: 7\"\n\n# learn about the structure of the data\nsummary(dat)\n\n    hauljoin        species_code     cpue_kgkm2          cpue_nokm2        \n Min.   : -23911   Min.   :    1   Min.   :      0.0   Min.   :      12.9  \n 1st Qu.: -14439   1st Qu.:20510   1st Qu.:      5.5   1st Qu.:      58.3  \n Median :  -5267   Median :40500   Median :     48.5   Median :     213.7  \n Mean   : 280338   Mean   :45195   Mean   :   1250.5   Mean   :    4605.1  \n 3rd Qu.: 802426   3rd Qu.:71800   3rd Qu.:    372.1   3rd Qu.:    1137.2  \n Max.   :1225635   Max.   :99999   Max.   :3226234.7   Max.   :21780780.3  \n                                                       NA's   :87811       \n     count            weight_kg         taxon_confidence  \n Min.   :     1.0   Min.   :    0.001   Length:891144     \n 1st Qu.:     2.0   1st Qu.:    0.199   Class :character  \n Median :     8.0   Median :    1.814   Mode  :character  \n Mean   :   180.5   Mean   :   41.720                     \n 3rd Qu.:    43.0   3rd Qu.:   13.780                     \n Max.   :867119.0   Max.   :18187.700                     \n NA's   :87811                                            \n\n# Print the first few lines of the data \ndat |&gt; \n  head(3) |&gt; \n  flextable::flextable() |&gt;\n  flextable::colformat_num(\n      j = c(\"species_code\"), \n      big.mark = \"\") |&gt; \n  flextable::theme_zebra()\n\nhauljoinspecies_codecpue_kgkm2cpue_nokm2countweight_kgtaxon_confidence-7,235205101,904.036558594.62021960.840High-7,235206220.68850862.591620.022High-7,23521230769.876715219.0706724.600High\n\n# save outputs for later comparison\ndat_catch_api &lt;- dat\n\n\n\n\n12.1.3 Load species data\nSince there are less than 10,000 rows of species data (and the maxim number of rows a user can pull from this API is 10,000 rows in a query), we can simply call ?offset=0&limit=10000 in our query call.\n\n# link to the API\napi_link_species &lt;- 'https://apps-st.fisheries.noaa.gov/ods/foss/afsc_groundfish_survey_species/'\n\n\nres &lt;- httr::GET(url = paste0(api_link_species, \"?offset=0&limit=10000\"))\n\n## convert from JSON format\ndata &lt;- jsonlite::fromJSON(base::rawToChar(res$content))\ndat &lt;- data$items  |&gt;\n  dplyr::select(-links) # necessary for API accounting, but not part of the dataset\n\nExplore the data contents:\n\n# Find how many rows and columns are in the data pull\nprint(paste0(\"rows: \", nrow(dat), \"; cols: \", ncol(dat)))\n\n[1] \"rows: 1014; cols: 6\"\n\n# learn about the structure of the data\nsummary(dat)\n\n  species_code   scientific_name    common_name          id_rank         \n Min.   :    1   Length:1014        Length:1014        Length:1014       \n 1st Qu.:22177   Class :character   Class :character   Class :character  \n Median :66868   Mode  :character   Mode  :character   Mode  :character  \n Mean   :50653                                                           \n 3rd Qu.:75077                                                           \n Max.   :99999                                                           \n                                                                         \n     worms              itis        \n Min.   :     51   Min.   :  46861  \n 1st Qu.: 127206   1st Qu.:  97781  \n Median : 254573   Median : 162045  \n Mean   : 293224   Mean   : 217907  \n 3rd Qu.: 342060   3rd Qu.: 167487  \n Max.   :1699296   Max.   :1206057  \n NA's   :82        NA's   :132      \n\n# Print the first few lines of the data \ndat |&gt; \n  head(3) |&gt; \n  flextable::flextable() |&gt;\n  flextable::colformat_num(\n      j = c(\"species_code\", \"worms\", \"itis\"), # \n      big.mark = \"\") |&gt; \n  flextable::theme_zebra()\n\nspecies_codescientific_namecommon_nameid_rankwormsitis1fish egg unid.2fish larvae unid.3fish unid.\n\n# save outputs for later comparison\ndat_species_api &lt;- dat",
    "crumbs": [
      "Public Data (FOSS)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Access via API and R</span>"
    ]
  },
  {
    "objectID": "content/foss-api-r.html#ex.-create-zero-filled-data-using-data-loaded-in-last-example",
    "href": "content/foss-api-r.html#ex.-create-zero-filled-data-using-data-loaded-in-last-example",
    "title": "Access via API and R",
    "section": "12.2 Ex. Create zero-filled data using data loaded in last example",
    "text": "12.2 Ex. Create zero-filled data using data loaded in last example\nIt is important to create and have access to zero-fill (presence and absence) so you can do simple analyses and plot data.\nFirst prepare a table with all combinations of what species should be listed for what hauls/surveys. For zero-filled data, all species caught in a survey need to have zero or non-zero row entries for a haul\n\ncomb &lt;- dplyr::full_join(\n  # find all species that have been caught, by survey\n  x = dplyr::left_join(dat_catch_api, dat_haul_api, by = \"hauljoin\") |&gt;\n    dplyr::select(survey_definition_id, species_code) |&gt;\n    dplyr::distinct(),\n  # find all haul events (hauljoins), by survey\n  y = dat_haul_api |&gt;\n    dplyr::select(survey_definition_id, hauljoin) |&gt;\n    dplyr::distinct(),\n  relationship = \"many-to-many\",\n  by = \"survey_definition_id\"\n) |&gt; \n  dplyr::select(-survey_definition_id) # now, redundant\n\nExplore the data contents:\n\nprint(paste0(\"rows: \", nrow(comb), \"; cols: \", ncol(comb)))\n\n[1] \"rows: 21733474; cols: 2\"\n\ncomb |&gt; head(3) |&gt; \n  flextable::flextable()  |&gt;\n  flextable::colformat_num(\n      j = c(\"species_code\", \"hauljoin\"), \n      big.mark = \"\") |&gt; \n  flextable::theme_zebra()\n\nspecies_codehauljoin205101225491205101225492205101225493\n\n\nNow, using that table of combinations (here, called comb), join data to make a full zero-filled CPUE dataset. When all of the data have been full joined together, there should be the maximum number of rows in comb.\n\ndat &lt;- comb |&gt;\n  # add species data\n  dplyr::left_join(dat_species_api) |&gt; # , \"species_code\"\n  # add haul data\n  dplyr::left_join(dat_haul_api) |&gt; # , c(\"hauljoin\")\n  # add catch data\n  dplyr::left_join(dat_catch_api) |&gt; # , c(\"species_code\", \"hauljoin\")\n  # modify/clean up zero-filled rows\n  dplyr::mutate(\n    cpue_kgkm2 = ifelse(is.na(cpue_kgkm2), 0, cpue_kgkm2),\n    cpue_nokm2 = ifelse(is.na(cpue_nokm2), 0, cpue_nokm2),\n    count = ifelse(is.na(count), 0, count),\n    weight_kg = ifelse(is.na(weight_kg), 0, weight_kg))\n\nTRUE Joining with `by = join_by(species_code)`\nTRUE Joining with `by = join_by(hauljoin)`\nTRUE Joining with `by = join_by(species_code, hauljoin)`\n\n\nExplore the data contents:\n\n# Find how many rows and columns are in the data pull\nprint(paste0(\"rows: \", nrow(dat), \"; cols: \", ncol(dat)))\n\n[1] \"rows: 21733474; cols: 38\"\n\n# learn about the structure of the data\nsummary(dat)\n\n  species_code      hauljoin       scientific_name    common_name       \n Min.   :    1   Min.   : -23911   Length:21733474    Length:21733474   \n 1st Qu.:21810   1st Qu.: -14004   Class :character   Class :character  \n Median :66839   Median :  -4364   Mode  :character   Mode  :character  \n Mean   :50538   Mean   : 298229                                        \n 3rd Qu.:74986   3rd Qu.: 821816                                        \n Max.   :99999   Max.   :1225635                                        \n                                                                        \n   id_rank              worms              itis              year     \n Length:21733474    Min.   :     51   Min.   :  46861   Min.   :1982  \n Class :character   1st Qu.: 126824   1st Qu.:  97160   1st Qu.:1997  \n Mode  :character   Median : 254510   Median : 160846   Median :2006  \n                    Mean   : 269709   Mean   : 203649   Mean   :2006  \n                    3rd Qu.: 292719   3rd Qu.: 167456   3rd Qu.:2015  \n                    Max.   :1699296   Max.   :1206057   Max.   :2024  \n                    NA's   :1584968   NA's   :2475974                 \n     srvy              survey          survey_name        survey_definition_id\n Length:21733474    Length:21733474    Length:21733474    Min.   : 47.00      \n Class :character   Class :character   Class :character   1st Qu.: 47.00      \n Mode  :character   Mode  :character   Mode  :character   Median : 52.00      \n                                                          Mean   : 68.95      \n                                                          3rd Qu.: 98.00      \n                                                          Max.   :143.00      \n                                                                              \n     cruise         cruisejoin           haul          stratum     \n Min.   :198201   Min.   :   -770   Min.   :  1.0   Min.   : 10.0  \n 1st Qu.:199701   1st Qu.:   -697   1st Qu.: 59.0   1st Qu.: 31.0  \n Median :200601   Median :   -616   Median :117.0   Median : 61.0  \n Mean   :200556   Mean   : 303023   Mean   :122.7   Mean   :142.1  \n 3rd Qu.:201501   3rd Qu.: 837800   3rd Qu.:177.0   3rd Qu.:212.0  \n Max.   :202401   Max.   :1225395   Max.   :355.0   Max.   :794.0  \n                                                                   \n   station            vessel_id   vessel_name         date_time        \n Length:21733474    Min.   :  1   Length:21733474    Length:21733474   \n Class :character   1st Qu.: 88   Class :character   Class :character  \n Mode  :character   Median : 94   Mode  :character   Mode  :character  \n                    Mean   :110                                        \n                    3rd Qu.:147                                        \n                    Max.   :178                                        \n                                                                       \n latitude_dd_start longitude_dd_start latitude_dd_end longitude_dd_end\n Min.   :51.19     Min.   :-180.0     Min.   :51.19   Min.   :-180.0  \n 1st Qu.:54.68     1st Qu.:-169.9     1st Qu.:54.68   1st Qu.:-169.9  \n Median :56.98     Median :-163.4     Median :56.98   Median :-163.4  \n Mean   :56.61     Mean   :-136.6     Mean   :56.61   Mean   :-136.6  \n 3rd Qu.:58.67     3rd Qu.:-152.1     3rd Qu.:58.67   3rd Qu.:-152.1  \n Max.   :65.34     Max.   : 180.0     Max.   :65.35   Max.   : 180.0  \n                                      NA's   :2268    NA's   :2268    \n bottom_temperature_c surface_temperature_c    depth_m     distance_fished_km\n Min.   :-2.1         Min.   :-1.10         Min.   :   9   Min.   :0.135     \n 1st Qu.: 3.1         1st Qu.: 5.90         1st Qu.:  71   1st Qu.:1.481     \n Median : 4.3         Median : 7.60         Median : 109   Median :1.677     \n Mean   : 4.1         Mean   : 8.05         Mean   : 142   Mean   :2.096     \n 3rd Qu.: 5.4         3rd Qu.: 9.70         3rd Qu.: 167   3rd Qu.:2.800     \n Max.   :15.3         Max.   :18.10         Max.   :1200   Max.   :4.334     \n NA's   :1106136      NA's   :598744                                         \n  duration_hr      net_width_m     net_height_m     area_swept_km2    \n Min.   :0.0250   Min.   : 7.51   Min.   : 0.00     Min.   :0.002314  \n 1st Qu.:0.2690   1st Qu.:15.54   1st Qu.: 2.60     1st Qu.:0.023802  \n Median :0.3050   Median :16.32   Median : 6.20     Median :0.027834  \n Mean   :0.3798   Mean   :16.36   Mean   : 5.21     Mean   :0.034427  \n 3rd Qu.:0.5000   3rd Qu.:17.12   3rd Qu.: 6.90     3rd Qu.:0.046295  \n Max.   :0.9800   Max.   :23.82   Max.   :11.04     Max.   :0.077795  \n                                  NA's   :1736222                     \n  performance       cpue_kgkm2          cpue_nokm2             count          \n Min.   :0.0000   Min.   :      0.0   Min.   :       0.0   Min.   :     0.00  \n 1st Qu.:0.0000   1st Qu.:      0.0   1st Qu.:       0.0   1st Qu.:     0.00  \n Median :0.0000   Median :      0.0   Median :       0.0   Median :     0.00  \n Mean   :0.2925   Mean   :     51.3   Mean   :     170.2   Mean   :     6.67  \n 3rd Qu.:0.0000   3rd Qu.:      0.0   3rd Qu.:       0.0   3rd Qu.:     0.00  \n Max.   :7.0000   Max.   :3226234.7   Max.   :21780780.3   Max.   :867119.00  \n                                                                              \n   weight_kg         taxon_confidence  \n Min.   :    0.000   Length:21733474   \n 1st Qu.:    0.000   Class :character  \n Median :    0.000   Mode  :character  \n Mean   :    1.711                     \n 3rd Qu.:    0.000                     \n Max.   :18187.700                     \n                                       \n\n# Print the first few lines of the data \ndat |&gt; \n  head(3) |&gt; \n  flextable::flextable() |&gt;\n  flextable::colformat_num(\n      j = c(\"species_code\", \"hauljoin\", \"year\", \"cruise\", \"cruisejoin\", \"worms\", \"itis\"), #\n      big.mark = \"\") |&gt; \n  flextable::theme_zebra()\n\nspecies_codehauljoinscientific_namecommon_nameid_rankwormsitisyearsrvysurveysurvey_namesurvey_definition_idcruisecruisejoinhaulstratumstationvessel_idvessel_namedate_timelatitude_dd_startlongitude_dd_startlatitude_dd_endlongitude_dd_endbottom_temperature_csurface_temperature_cdepth_mdistance_fished_kmduration_hrnet_width_mnet_height_marea_swept_km2performancecpue_kgkm2cpue_nokm2countweight_kgtaxon_confidence205101225491Anoplopoma fimbriasablefishspecies1594631671232004BSSBering Sea SlopeEastern Bering Sea Slope Bottom Trawl Survey7820040112253952251276134NORTHWEST EXPLORER2004-08-05T18:18:27Z54.57648-166.598954.57169-166.63623.99.34132.4700.5315.5766.9530.0384730520.3687233.93199920.02High205101225492Anoplopoma fimbriasablefishspecies1594631671232004BSSBering Sea SlopeEastern Bering Sea Slope Bottom Trawl Survey7820040112253951921289134NORTHWEST EXPLORER2004-07-29T18:02:55Z55.12762-167.810855.10951-167.78773.89.74302.4940.5215.7786.7680.0393500199.7442101.6509947.86High205101225493Anoplopoma fimbriasablefishspecies1594631671232004BSSBering Sea SlopeEastern Bering Sea Slope Bottom Trawl Survey78200401122539519315149134NORTHWEST EXPLORER2004-07-30T08:04:59Z54.94091-167.783754.92692-167.76852.88.61,0161.8270.3816.5196.2040.0301800440.686199.40288313.30High\n\n# save outputs for later comparison\ndat_zerofill_api &lt;- dat",
    "crumbs": [
      "Public Data (FOSS)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Access via API and R</span>"
    ]
  },
  {
    "objectID": "content/foss-api-r.html#ex.-visualize-zero-filled-data-for-2023-eastern-bering-sea-walleye-pollock-in-cpue-data-in-distribution-map",
    "href": "content/foss-api-r.html#ex.-visualize-zero-filled-data-for-2023-eastern-bering-sea-walleye-pollock-in-cpue-data-in-distribution-map",
    "title": "Access via API and R",
    "section": "12.3 Ex. Visualize zero-filled data for 2023 eastern Bering Sea walleye pollock in CPUE data in distribution map",
    "text": "12.3 Ex. Visualize zero-filled data for 2023 eastern Bering Sea walleye pollock in CPUE data in distribution map\nUsing the zero-filled data from the previous example, we can make a few plots!\nHere is some example data of 2023 through 2019 (year %in% 2019:2023) eastern and northern Bering Sea (srvy %in% c(\"EBS\", \"NBS)) walleye pollock (species_code == 21740).\n\ndat &lt;- dat_zerofill_api |&gt; \n  dplyr::filter(year %in% 2019:2023 & \n                  srvy %in% c(\"EBS\", \"NBS\") & \n                  species_code == 21740) |&gt; \n  dplyr::select(year, common_name, longitude_dd_start, latitude_dd_start, cpue_kgkm2)\n\n# Find how many rows and columns are in the data pull\nprint(paste0(\"rows: \", nrow(dat), \"; cols: \", ncol(dat)))\n\n[1] \"rows: 2052; cols: 5\"\n\n# # learn about the structure of the data\n# summary(dat)\n\n# Print the first few lines of the data \ndat |&gt; \n  head(3) |&gt; \n  flextable::flextable() |&gt;\n  flextable::colformat_num(\n      j = c(\"year\"), \n      big.mark = \"\") |&gt; \n  flextable::theme_zebra()\n\nyearcommon_namelongitude_dd_startlatitude_dd_startcpue_kgkm22023walleye pollock-168.274363.697792,970.5442023walleye pollock-168.217163.022981,291.4412023walleye pollock-168.832962.880964,573.617\n\n\n\n12.3.1 Plot locations on map\n\nlibrary(ggplot2)\n\nggplot2::ggplot(data = dat |&gt; dplyr::filter(cpue_kgkm2 != 0), \n                mapping = aes(x = longitude_dd_start, \n                              y = latitude_dd_start, \n                              size = cpue_kgkm2)) + \n  ggplot2::geom_point(alpha = .75) +\n  ggplot2::geom_point(data = dat |&gt; dplyr::filter(cpue_kgkm2 == 0), \n                      color = \"red\", \n                      shape = 17,\n                      alpha = .75,\n                      size = 3) +\n  ggplot2::xlab(\"Longitude *W\") +\n  ggplot2::ylab(\"Latitude *N\") +\n  ggplot2::ggtitle(label = \"CPUE (kg/km^2) of walleye pollock (Weight CPUE; kg/km2)\", \n                   subtitle = \"Eastern Bering Sea bottom trawl survey\") +\n  ggplot2::scale_size_continuous(name = \"Weight (kg)\") + \n  ggplot2::facet_wrap(facets = vars(year)) + \n  ggplot2::theme_bw()\n\n\n\n\n\n\n\n\n\n\n12.3.2 Plot inverse-distance weighted plot of CPUE\nThis map is constructed using akgfmaps. To make IDW plots, you must have data from all stations surveyed, even if no fish of interest were found there.\nThese plots are similar to those published in the annual Bering Sea data reports.\n\n# devtools::install_github(\"afsc-gap-products/akgfmaps\", build_vignettes = TRUE)\nlibrary(akgfmaps)\nidw &lt;- akgfmaps::make_idw_stack(\n  x = dat |&gt; \n    dplyr::select(COMMON_NAME = common_name, \n                  CPUE_KGHA = cpue_kgkm2, \n                  LATITUDE = latitude_dd_start, \n                  LONGITUDE = longitude_dd_start, \n                  year), \n  grouping.vars = \"year\", \n  region = \"bs.all\", # Predefined EBS area\n  set.breaks = \"jenks\", # Gets Jenks breaks from classint::classIntervals()\n  in.crs = \"+proj=longlat\", # Set input coordinate reference system\n  out.crs = \"EPSG:3338\", # Set output coordinate reference system\n  extrapolation.grid.type = \"sf\")\n\n[inverse distance weighted interpolation]\n[inverse distance weighted interpolation]\n\n\n[inverse distance weighted interpolation]\n[inverse distance weighted interpolation]\n\n\n[inverse distance weighted interpolation]\n[inverse distance weighted interpolation]\n\n\n[inverse distance weighted interpolation]\n[inverse distance weighted interpolation]\n\nshps &lt;- akgfmaps::get_base_layers(\n  select.region = \"bs.all\", \n  # include.corners = TRUE, \n  set.crs = \"EPSG:3338\")\n\nshps$survey.area$SRVY &lt;- c(\"EBS\", \"NBS\")\nshps$survey.area$SURVEY &lt;- c(\"EBS\", \"NBS\")\n\n# set.breaks &lt;- akgfmaps::eval_plot_breaks(CPUE = dat$cpue_kgkm2, n.breaks = 5)\n# set.breaks &lt;- as.vector(unlist(set.breaks[set.breaks$style == \"pretty\", -1]))\nset.breaks &lt;- c(0, 50000, 100000, 150000, 200000, 250000)\n\nfigure_print &lt;- ggplot() +\n  # add map of alaska\n  ggplot2::geom_sf(data = shps$akland,\n                   color = NA,\n                   fill = \"grey50\") +\n  # add IDW plots\n  geom_sf(data = idw$extrapolation.stack,\n          mapping = aes(fill = var1.pred),\n          na.rm = FALSE,\n          show.legend = TRUE, \n          color = NA) +\n  ggplot2::scale_fill_manual(\n    name = \"walleye pollock\\nCPUE (kg/km2)\",\n    values =  c(\"gray90\",\n                viridis::viridis(\n                  option = \"mako\",\n                  direction = -1,\n                  n = length(set.breaks)-1,\n                  begin = 0.20,\n                  end = 0.80)),\n    na.translate = FALSE, # Don't use NA\n    drop = FALSE) + \n  # seperate plots by year\n  ggplot2::facet_wrap(facets = vars(year), nrow = 2) + \n  # add survey area\n  ggplot2::geom_sf(\n    data = shps$survey.area, \n    mapping = aes(color = SURVEY, \n                  geometry = geometry), \n    fill = \"transparent\", \n    linewidth = 1, \n    show.legend = FALSE) +\n  ggplot2::scale_color_manual(\n    name = \" \", \n    values = c(\"grey30\", \"grey50\"),\n    breaks = shps$survey.area$SURVEY,\n    labels = shps$survey.area$SRVY) + \n  # lat/lon axis and map bounds\n  ggplot2::scale_x_continuous(name = \"Longitude °W\",\n                              breaks = seq(-180, -150, 5)) +\n  ggplot2::scale_y_continuous(name = \"Latitude °N\",\n                              breaks = seq(50, 65, 5)) + # seq(52, 62, 2)\n  ggplot2::coord_sf(xlim = sf::st_bbox(shps$survey.area)[c(1,3)],\n                    ylim = sf::st_bbox(shps$survey.area)[c(2,4)]) +\n  # add theme aesthetics\n  ggplot2::guides(\n    fill = guide_legend(\n      order = 1,\n      title.position = \"top\",\n      label.position = \"bottom\",\n      title.hjust = 0.5,\n      override.aes = list(color = NA),\n      nrow = 1),\n    color = \"none\") +\n  ggplot2::theme( \n    panel.background = element_rect(fill = \"white\", colour = NA), \n    panel.border = element_rect(fill = NA, colour = \"grey20\"), \n    strip.background = element_blank(), \n    strip.text = element_text(size = 10, face = \"bold\"), \n    legend.text = element_text(size = 9),\n    legend.background = element_rect(colour = \"transparent\", \n                                     fill = \"transparent\"),\n    legend.key = element_rect(colour = \"transparent\", \n                              fill = \"transparent\"),\n    legend.position = \"bottom\", \n    legend.box = \"horizontal\",\n    legend.box.spacing = unit(0, \"pt\"), # reduce space between legend & plot\n    legend.margin=margin(0, 0, 0, 0) )\n\nfigure_print",
    "crumbs": [
      "Public Data (FOSS)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Access via API and R</span>"
    ]
  },
  {
    "objectID": "content/foss-api-r.html#ex.-show-catch-data-for-2023-eastern-bering-sea-walleye-pollock-one-species-in-one-survey-region-in-one-year",
    "href": "content/foss-api-r.html#ex.-show-catch-data-for-2023-eastern-bering-sea-walleye-pollock-one-species-in-one-survey-region-in-one-year",
    "title": "Access via API and R",
    "section": "12.4 Ex. Show catch data for 2023 eastern Bering Sea Walleye Pollock (one species in one survey region in one year)",
    "text": "12.4 Ex. Show catch data for 2023 eastern Bering Sea Walleye Pollock (one species in one survey region in one year)\nData downloads and joins for just one species, survey, and year are much faster and easier to do.\nFirst, because year is identified in the haul table, we need to identify all of the hauls (or more specifically, hauljoin codes) that were completed in the eastern Bering Sea (\"srvy\":\"EBS\") in 2023 (\"year\":2023).\nNote: Check how many rows and columns are in the data pull. The eastern Bering Sea survey (before 2024) has 376 stations in it, and pollock are often found in throughout the region so this should have a similar number of rows.\n\n## query the API link\nres &lt;- httr::GET(url = paste0(api_link_haul, '?limit=10000&q={\"year\":2023,\"srvy\":\"EBS\"}'))\n\n## convert from JSON format\ndata &lt;- jsonlite::fromJSON(base::rawToChar(res$content)) \ndat &lt;- data$items |&gt;\n  dplyr::select(-links) # necessary for API accounting, but not part of the dataset\n\n## show summary of data to make sure it is subset correctly\nsummary(dat |&gt; dplyr::mutate(srvy = as.factor(srvy)))\n\n      year       srvy        survey          survey_name       \n Min.   :2023   EBS:376   Length:376         Length:376        \n 1st Qu.:2023             Class :character   Class :character  \n Median :2023             Mode  :character   Mode  :character  \n Mean   :2023                                                  \n 3rd Qu.:2023                                                  \n Max.   :2023                                                  \n survey_definition_id     cruise         cruisejoin        hauljoin     \n Min.   :98           Min.   :202301   Min.   :-760.0   Min.   :-23019  \n 1st Qu.:98           1st Qu.:202301   1st Qu.:-760.0   1st Qu.:-22776  \n Median :98           Median :202301   Median :-759.0   Median :-22539  \n Mean   :98           Mean   :202301   Mean   :-759.5   Mean   :-22552  \n 3rd Qu.:98           3rd Qu.:202301   3rd Qu.:-759.0   3rd Qu.:-22333  \n Max.   :98           Max.   :202301   Max.   :-759.0   Max.   :-22110  \n      haul           stratum        station            vessel_id    \n Min.   :  7.00   Min.   :10.00   Length:376         Min.   :134.0  \n 1st Qu.: 65.75   1st Qu.:31.00   Class :character   1st Qu.:134.0  \n Median :114.00   Median :41.00   Mode  :character   Median :162.0  \n Mean   :114.16   Mean   :39.22                      Mean   :148.3  \n 3rd Qu.:161.25   3rd Qu.:50.00                      3rd Qu.:162.0  \n Max.   :224.00   Max.   :90.00                      Max.   :162.0  \n vessel_name         date_time         latitude_dd_start longitude_dd_start\n Length:376         Length:376         Min.   :54.66     Min.   :-178.2    \n Class :character   Class :character   1st Qu.:57.00     1st Qu.:-172.7    \n Mode  :character   Mode  :character   Median :58.02     Median :-168.9    \n                                       Mean   :58.26     Mean   :-168.8    \n                                       3rd Qu.:59.50     3rd Qu.:-165.2    \n                                       Max.   :62.01     Max.   :-158.3    \n latitude_dd_end longitude_dd_end bottom_temperature_c surface_temperature_c\n Min.   :54.68   Min.   :-178.2   Min.   :-1.600       Min.   : 1.700       \n 1st Qu.:57.01   1st Qu.:-172.7   1st Qu.: 1.200       1st Qu.: 4.200       \n Median :58.02   Median :-168.9   Median : 2.700       Median : 6.550       \n Mean   :58.26   Mean   :-168.8   Mean   : 2.249       Mean   : 6.386       \n 3rd Qu.:59.50   3rd Qu.:-165.2   3rd Qu.: 3.500       3rd Qu.: 8.525       \n Max.   :62.01   Max.   :-158.3   Max.   : 5.400       Max.   :11.000       \n    depth_m       distance_fished_km  duration_hr      net_width_m   \n Min.   : 20.00   Min.   :1.065      Min.   :0.1890   Min.   :12.90  \n 1st Qu.: 54.75   1st Qu.:2.805      1st Qu.:0.5100   1st Qu.:16.66  \n Median : 74.00   Median :2.889      Median :0.5180   Median :17.27  \n Mean   : 80.75   Mean   :2.854      Mean   :0.5129   Mean   :17.15  \n 3rd Qu.:105.00   3rd Qu.:2.945      3rd Qu.:0.5260   3rd Qu.:17.83  \n Max.   :171.00   Max.   :3.849      Max.   :0.6560   Max.   :20.29  \n  net_height_m   area_swept_km2     performance    \n Min.   :1.300   Min.   :0.02017   Min.   :0.0000  \n 1st Qu.:1.875   1st Qu.:0.04725   1st Qu.:0.0000  \n Median :2.064   Median :0.04944   Median :0.0000  \n Mean   :2.107   Mean   :0.04892   Mean   :0.1075  \n 3rd Qu.:2.343   3rd Qu.:0.05134   3rd Qu.:0.0000  \n Max.   :3.196   Max.   :0.06369   Max.   :6.2200  \n\n## Find how many rows and columns are in the data pull. \nprint(paste0(\"rows: \", nrow(dat), \"; cols: \", ncol(dat)))\n\n[1] \"rows: 376; cols: 27\"\n\n# save outputs for later comparison\ndat_haul_ex &lt;- dat\n\n\n# Print the first few lines of the data \ndat_haul_ex |&gt; \n  head(3) |&gt; \n  flextable::flextable() |&gt;\n  flextable::colformat_num(\n      j = c(\"year\", \"hauljoin\", \"cruise\"), \n      big.mark = \"\") |&gt; \n  flextable::theme_zebra()\n\nHaul data filtered by year = 2023 and\nSRVY = 'EBS'.yearsrvysurveysurvey_namesurvey_definition_idcruisecruisejoinhauljoinhaulstratumstationvessel_idvessel_namedate_timelatitude_dd_startlongitude_dd_startlatitude_dd_endlongitude_dd_endbottom_temperature_csurface_temperature_cdepth_mdistance_fished_kmduration_hrnet_width_mnet_height_marea_swept_km2performance2023EBSeastern Bering SeaEastern Bering Sea Crab/Groundfish Bottom Trawl Survey98202301-760-224729450C-01134NORTHWEST EXPLORER2023-06-21T15:22:41Z55.66353-167.591755.68996-167.59824.47.81352.9660.51218.6471.5870.05530702023EBSeastern Bering SeaEastern Bering Sea Crab/Groundfish Bottom Trawl Survey98202301-760-225109550C-18134NORTHWEST EXPLORER2023-06-22T07:11:43Z55.66357-168.209855.68946-168.21304.48.01362.8840.51917.2591.9310.04977502023EBSeastern Bering SeaEastern Bering Sea Crab/Groundfish Bottom Trawl Survey98202301-760-225119650D-18134NORTHWEST EXPLORER2023-06-22T10:18:09Z55.99245-168.218956.01884-168.22784.37.61512.9860.52817.5202.0420.0523150\n\n\n\n12.4.1 Identify species_code for walleye pollock\nIn the catch data, we itemize species catches by species_code. To find out which species_code to use, you can check variations on the following code. Note that here the word pollock is case sensitive. All species common_name entries are lower case except for proper nouns (e.g., “Pacific”). The notation for finding a string is to use % around the phrase. Since % is a reserved character in a URL, you have to replace % with %25. Similarly, %20 needs to be used in place of a space (e.g., between “walleye” and “pollock”: \"walleye%20pollock\"}').\n\n## query the API link. Use: \nres &lt;- httr::GET(url = paste0(api_link_species, '?q={%22common_name%22:%22walleye%20pollock%22}'))\n# OR\nres &lt;- httr::GET(url = paste0(api_link_species, '?q={\"common_name\":{\"$like\":\"%25pollock%25\"}}'))\n# OR\nres &lt;- httr::GET(url = paste0(api_link_species, '?q={\"common_name\":\"walleye%20pollock\"}'))\n\n## convert from JSON format\ndata &lt;- jsonlite::fromJSON(base::rawToChar(res$content)) \n\n# save outputs for later comparison\ndat_species_ex &lt;- data$items |&gt; dplyr::select(-links) # necessary for API accounting, but not part of the dataset\n\n\n# Print the first few lines of the data\ndat_species_ex |&gt; \n  head(3) |&gt; \n  flextable::flextable() |&gt;\n  flextable::colformat_num(\n      j = c(\"species_code\"), \n      big.mark = \"\") |&gt; \n  flextable::theme_zebra()\n\nWalleye pollock species information.species_codescientific_namecommon_nameid_rankwormsitis21740Gadus chalcogrammuswalleye pollockspecies300,735934,083\n\n\n\n\n12.4.2 Then, apply the hauljoins and species_code to catch query\nWe’ll use the data from the haul and species table we collected before to select 2023 eastern Bering Sea walleye pollock catch data.\n\n## query the API link\n# data for all walleye pollock caught in all 2023 eastern Bering Sea survey hauls\ndat &lt;- data.frame()\n# there must be a better way to select multiple values for one parameter, \n# but saving that, we will loop through each hauljoin and collect the data of interest\nfor (i in 1:nrow(dat_haul_ex)) {\n  res &lt;- httr::GET(url = paste0(\n    api_link_catch, \n    '?q={\"species_code\":21740,\"hauljoin\":', dat_haul_ex$hauljoin[i],'}'))\n  ## convert from JSON format\n  data &lt;- jsonlite::fromJSON(base::rawToChar(res$content)) \n  if (length(data$items) != 0) {\n    dat &lt;- dplyr::bind_rows(\n      dat,\n      data$items |&gt; \n        dplyr::select(-links)) # necessary for API accounting, but not part of the dataset\n  }\n}\n\nExplore data:\n\n# Find how many rows and columns are in the data pull\nprint(paste0(\"rows: \", nrow(dat), \"; cols: \", ncol(dat)))\n\n[1] \"rows: 374; cols: 7\"\n\n# learn about the structure of the data\nsummary(dat)\n\n    hauljoin       species_code     cpue_kgkm2          cpue_nokm2       \n Min.   :-23019   Min.   :21740   Min.   :    10.34   Min.   :    18.26  \n 1st Qu.:-22777   1st Qu.:21740   1st Qu.:  1454.44   1st Qu.:  2281.20  \n Median :-22540   Median :21740   Median :  3286.76   Median :  5863.07  \n Mean   :-22553   Mean   :21740   Mean   :  6364.85   Mean   : 11540.65  \n 3rd Qu.:-22324   3rd Qu.:21740   3rd Qu.:  6956.25   3rd Qu.: 12456.99  \n Max.   :-22110   Max.   :21740   Max.   :148679.68   Max.   :202321.08  \n     count          weight_kg        taxon_confidence  \n Min.   :   1.0   Min.   :   0.492   Length:374        \n 1st Qu.: 113.2   1st Qu.:  71.560   Class :character  \n Median : 284.0   Median : 162.310   Mode  :character  \n Mean   : 572.8   Mean   : 315.419                     \n 3rd Qu.: 616.5   3rd Qu.: 350.399                     \n Max.   :9997.0   Max.   :7346.495                     \n\n# Print the first few lines of the data \ndat |&gt; \n  head(3) |&gt; \n  flextable::flextable() |&gt;\n  flextable::colformat_num(\n      j = c(\"hauljoin\", \"species_code\"), \n      big.mark = \"\") |&gt; \n  flextable::theme_zebra()\n\nhauljoinspecies_codecpue_kgkm2cpue_nokm2countweight_kgtaxon_confidence-224722174052.615472.3235742.91High-2251021740351.5824361.627641817.50High-22511217403,110.78793,784.78562198162.74High\n\n# save outputs for later comparison\ndat_catch_ex &lt;- dat\n\nFor reference and to help break down the above query, see these other query examples:\n\n# data for haul -22775 (i.e., one specific haul)?\nres &lt;- httr::GET(url = paste0(api_link_catch, \n                              '?offset=',i,'&limit=10000&q={\"hauljoin\":-22775}'))\n\n# data for all walleye pollock (i.e., one species) caught in all years and surveys\nres &lt;- httr::GET(url = paste0(api_link_catch, \n                              '?offset=',i,'&limit=10000&q={\"species_code\":21740}'))\n\n\n\n12.4.3 Create zero-filled data for 2023 eastern Bering Sea walleye pollock and plot\nIt is important to create and have access to zero-fill (presence and absence) so you can do simple analyses and plot data.\n\ndat &lt;- dplyr::full_join(\n  dat_haul_ex,\n  dat_catch_ex) |&gt; \n  dplyr::full_join(\n    dat_species_ex)  |&gt; \n  # modify zero-filled rows\n  dplyr::mutate(\n    cpue_kgkm2 = ifelse(is.na(cpue_kgkm2), 0, cpue_kgkm2),\n    cpue_nokm2 = ifelse(is.na(cpue_nokm2), 0, cpue_nokm2),\n    count = ifelse(is.na(count), 0, count),\n    weight_kg = ifelse(is.na(weight_kg), 0, weight_kg))\n\nExplore data\n\n# Find how many rows and columns are in the data pull\nprint(paste0(\"rows: \", nrow(dat), \"; cols: \", ncol(dat)))\n\n[1] \"rows: 376; cols: 38\"\n\n# learn about the structure of the data\nsummary(dat)\n\n      year          srvy              survey          survey_name       \n Min.   :2023   Length:376         Length:376         Length:376        \n 1st Qu.:2023   Class :character   Class :character   Class :character  \n Median :2023   Mode  :character   Mode  :character   Mode  :character  \n Mean   :2023                                                           \n 3rd Qu.:2023                                                           \n Max.   :2023                                                           \n                                                                        \n survey_definition_id     cruise         cruisejoin        hauljoin     \n Min.   :98           Min.   :202301   Min.   :-760.0   Min.   :-23019  \n 1st Qu.:98           1st Qu.:202301   1st Qu.:-760.0   1st Qu.:-22776  \n Median :98           Median :202301   Median :-759.0   Median :-22539  \n Mean   :98           Mean   :202301   Mean   :-759.5   Mean   :-22552  \n 3rd Qu.:98           3rd Qu.:202301   3rd Qu.:-759.0   3rd Qu.:-22333  \n Max.   :98           Max.   :202301   Max.   :-759.0   Max.   :-22110  \n                                                                        \n      haul           stratum        station            vessel_id    \n Min.   :  7.00   Min.   :10.00   Length:376         Min.   :134.0  \n 1st Qu.: 65.75   1st Qu.:31.00   Class :character   1st Qu.:134.0  \n Median :114.00   Median :41.00   Mode  :character   Median :162.0  \n Mean   :114.16   Mean   :39.22                      Mean   :148.3  \n 3rd Qu.:161.25   3rd Qu.:50.00                      3rd Qu.:162.0  \n Max.   :224.00   Max.   :90.00                      Max.   :162.0  \n                                                                    \n vessel_name         date_time         latitude_dd_start longitude_dd_start\n Length:376         Length:376         Min.   :54.66     Min.   :-178.2    \n Class :character   Class :character   1st Qu.:57.00     1st Qu.:-172.7    \n Mode  :character   Mode  :character   Median :58.02     Median :-168.9    \n                                       Mean   :58.26     Mean   :-168.8    \n                                       3rd Qu.:59.50     3rd Qu.:-165.2    \n                                       Max.   :62.01     Max.   :-158.3    \n                                                                           \n latitude_dd_end longitude_dd_end bottom_temperature_c surface_temperature_c\n Min.   :54.68   Min.   :-178.2   Min.   :-1.600       Min.   : 1.700       \n 1st Qu.:57.01   1st Qu.:-172.7   1st Qu.: 1.200       1st Qu.: 4.200       \n Median :58.02   Median :-168.9   Median : 2.700       Median : 6.550       \n Mean   :58.26   Mean   :-168.8   Mean   : 2.249       Mean   : 6.386       \n 3rd Qu.:59.50   3rd Qu.:-165.2   3rd Qu.: 3.500       3rd Qu.: 8.525       \n Max.   :62.01   Max.   :-158.3   Max.   : 5.400       Max.   :11.000       \n                                                                            \n    depth_m       distance_fished_km  duration_hr      net_width_m   \n Min.   : 20.00   Min.   :1.065      Min.   :0.1890   Min.   :12.90  \n 1st Qu.: 54.75   1st Qu.:2.805      1st Qu.:0.5100   1st Qu.:16.66  \n Median : 74.00   Median :2.889      Median :0.5180   Median :17.27  \n Mean   : 80.75   Mean   :2.854      Mean   :0.5129   Mean   :17.15  \n 3rd Qu.:105.00   3rd Qu.:2.945      3rd Qu.:0.5260   3rd Qu.:17.83  \n Max.   :171.00   Max.   :3.849      Max.   :0.6560   Max.   :20.29  \n                                                                     \n  net_height_m   area_swept_km2     performance      species_code  \n Min.   :1.300   Min.   :0.02017   Min.   :0.0000   Min.   :21740  \n 1st Qu.:1.875   1st Qu.:0.04725   1st Qu.:0.0000   1st Qu.:21740  \n Median :2.064   Median :0.04944   Median :0.0000   Median :21740  \n Mean   :2.107   Mean   :0.04892   Mean   :0.1075   Mean   :21740  \n 3rd Qu.:2.343   3rd Qu.:0.05134   3rd Qu.:0.0000   3rd Qu.:21740  \n Max.   :3.196   Max.   :0.06369   Max.   :6.2200   Max.   :21740  \n                                                    NA's   :2      \n   cpue_kgkm2       cpue_nokm2         count          weight_kg      \n Min.   :     0   Min.   :     0   Min.   :   0.0   Min.   :   0.00  \n 1st Qu.:  1431   1st Qu.:  2268   1st Qu.: 112.0   1st Qu.:  70.64  \n Median :  3273   Median :  5842   Median : 280.0   Median : 161.44  \n Mean   :  6331   Mean   : 11479   Mean   : 569.8   Mean   : 313.74  \n 3rd Qu.:  6946   3rd Qu.: 12345   3rd Qu.: 611.5   3rd Qu.: 349.81  \n Max.   :148680   Max.   :202321   Max.   :9997.0   Max.   :7346.49  \n                                                                     \n taxon_confidence   scientific_name    common_name          id_rank         \n Length:376         Length:376         Length:376         Length:376        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n     worms             itis       \n Min.   :300735   Min.   :934083  \n 1st Qu.:300735   1st Qu.:934083  \n Median :300735   Median :934083  \n Mean   :300735   Mean   :934083  \n 3rd Qu.:300735   3rd Qu.:934083  \n Max.   :300735   Max.   :934083  \n NA's   :2        NA's   :2       \n\n# Print the first few lines of the data \ndat |&gt; \n  head(3) |&gt; \n  flextable::flextable() |&gt;\n  flextable::colformat_num(\n      j = c(\"year\", \"cruise\", \"cruisejoin\", \"species_code\"), \n      big.mark = \"\") |&gt; \n  flextable::theme_zebra()\n\nyearsrvysurveysurvey_namesurvey_definition_idcruisecruisejoinhauljoinhaulstratumstationvessel_idvessel_namedate_timelatitude_dd_startlongitude_dd_startlatitude_dd_endlongitude_dd_endbottom_temperature_csurface_temperature_cdepth_mdistance_fished_kmduration_hrnet_width_mnet_height_marea_swept_km2performancespecies_codecpue_kgkm2cpue_nokm2countweight_kgtaxon_confidencescientific_namecommon_nameid_rankwormsitis2023EBSeastern Bering SeaEastern Bering Sea Crab/Groundfish Bottom Trawl Survey98202301-760-22,4729450C-01134NORTHWEST EXPLORER2023-06-21T15:22:41Z55.66353-167.591755.68996-167.59824.47.81352.9660.51218.6471.5870.05530702174052.615472.3235742.91HighGadus chalcogrammuswalleye pollockspecies300,735934,0832023EBSeastern Bering SeaEastern Bering Sea Crab/Groundfish Bottom Trawl Survey98202301-760-22,5109550C-18134NORTHWEST EXPLORER2023-06-22T07:11:43Z55.66357-168.209855.68946-168.21304.48.01362.8840.51917.2591.9310.049775021740351.5824361.627641817.50HighGadus chalcogrammuswalleye pollockspecies300,735934,0832023EBSeastern Bering SeaEastern Bering Sea Crab/Groundfish Bottom Trawl Survey98202301-760-22,5119650D-18134NORTHWEST EXPLORER2023-06-22T10:18:09Z55.99245-168.218956.01884-168.22784.37.61512.9860.52817.5202.0420.0523150217403,110.78793,784.78562198162.74HighGadus chalcogrammuswalleye pollockspecies300,735934,083\n\n\n\n\n12.4.4 Visualize CPUE data in distribution map\nUsing the zero-filled data from the previous example, we can make a few plots!",
    "crumbs": [
      "Public Data (FOSS)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Access via API and R</span>"
    ]
  },
  {
    "objectID": "content/foss-api-r.html#plot-locations",
    "href": "content/foss-api-r.html#plot-locations",
    "title": "Access via API and R",
    "section": "12.5 Plot locations",
    "text": "12.5 Plot locations\n\nlibrary(ggplot2)\n\nggplot2::ggplot(data = dat |&gt; dplyr::filter(cpue_kgkm2 != 0), \n                mapping = aes(x = longitude_dd_start, \n                              y = latitude_dd_start, \n                              size = cpue_kgkm2)) + \n  ggplot2::geom_point(alpha = .75) +\n  ggplot2::geom_point(data = dat |&gt; dplyr::filter(cpue_kgkm2 == 0), \n                      color = \"red\", \n                      shape = 17,\n                      alpha = .75,\n                      size = 3) +\n  ggplot2::xlab(\"Longitude *W\") +\n  ggplot2::ylab(\"Latitude *N\") +\n  ggplot2::ggtitle(label = \"Catches of walleye pollock (Weight CPUE; kg/km2)\", \n                   subtitle = \"2023 eastern Bering Sea bottom trawl survey\") +\n  ggplot2::scale_size_continuous(name = \"Weight (kg)\") + \n  ggplot2::theme_bw()\n\n\n\n\n\n\n\n\n\n12.5.1 Plot inverse-distance weighted modeled product of locations\nThis map is constructed using akgfmaps\n\n# devtools::install_github(\"afsc-gap-products/akgfmaps\", build_vignettes = TRUE)\nlibrary(akgfmaps)\n\nfigure0 &lt;- akgfmaps::make_idw_map(\n  CPUE_KGHA = dat$cpue_kgkm2, # calculates the same, regardless of units.  \n  LATITUDE = dat$latitude_dd_start, \n  LONGITUDE = dat$longitude_dd_start, \n  region = \"bs.south\", # Predefined EBS area\n  set.breaks = \"jenks\", # Gets Jenks breaks from classint::classIntervals()\n  in.crs = \"+proj=longlat\", # Set input coordinate reference system\n  out.crs = \"EPSG:3338\", # Set output coordinate reference system\n  extrapolation.grid.type = \"sf\")\n\n[inverse distance weighted interpolation]\n[inverse distance weighted interpolation]\n\nfigure0$plot + # 20x20km grid\n  ggplot2::guides(fill=guide_legend(title = \"walleye pollock\\nCPUE (kg/km2)\"))",
    "crumbs": [
      "Public Data (FOSS)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Access via API and R</span>"
    ]
  },
  {
    "objectID": "content/foss-api-py.html",
    "href": "content/foss-api-py.html",
    "title": "Access via API and Python",
    "section": "",
    "text": "{afscgap} Library Installation\n\nauthor: Sam Pottinger (sam.pottinger@berkeley.edu; GitHub::sampottinger) date: May 13, 2023\n\nThe third-party afscgap Python package interfaces with FOSS to access AFSC GAP data. It can be installed via pip:\n\n#The reticulate package provides a comprehensive set of tools for interoperability between Python and R. \nlibrary(reticulate)\n\n\npip install afscgap\npip install git+https://github.com/SchmidtDSE/afscgap.git@main\n\nFor more information on installation and deployment, see the library documentation.\n\n\nBasic query\nThis first example queries for Pacific glass shrimp (Pasiphaea pacifica) in the Gulf of Alaska in 2021. The library will automatically generate HTTP queries, converting from Python types to ORDS query syntax.\n\nimport afscgap\n\nquery = afscgap.Query()\nquery.filter_year(eq=2021)\nquery.filter_srvy(eq='GOA')\nquery.filter_scientific_name(eq='Pasiphaea pacifica')\n\nresults = query.execute()\n\nThe results variable in this example is an iterator that will automatically perform pagination behind the scenes.\n\n\nIterating with a for loop\nThe easiest way to interact with results is a simple for loop. This next example determines the frequency of different catch per unit effort where Pacific glass shrimp were reported:\n\nimport afscgap\n\n# Mapping from CPUE to count\ncount_by_cpue = {}\n\n# Build query\nquery = afscgap.Query()\nquery.filter_year(eq=2021)\nquery.filter_srvy(eq='GOA')\nquery.filter_scientific_name(eq='Pasiphaea pacifica')\nresults = query.execute()\n\n# Iterate through results and count\nfor record in results:\n  cpue = record.get_cpue_weight(units='kg/ha')\n  cpue_rounded = round(cpue)\n  count = count_by_cpue.get(cpue_rounded, 0) + 1\n  count_by_cpue[cpue_rounded] = count\n\n# Print the result\nprint(count_by_cpue)\n\nNote that, in this example, only records with Pacific glass shrimp are included (“presence-only” data). See zero catch inference below. In other words, it reports on CPUE only for hauls in which Pacific glass shrimp were recorded, excluding some hauls like those in which Pacific glass shrimp were not found at all.\n\n\nIterating with functional programming\nA for loop is not the only option for iterating through results. List comprehensions and other functional programming methods can be used as well.\n\nimport statistics\n\nimport afscgap\n\n# Build query\nquery = afscgap.Query()\nquery.filter_year(eq=2021)\nquery.filter_srvy(eq='GOA')\nquery.filter_scientific_name(eq='Pasiphaea pacifica')\nresults = query.execute()\n\n# Get temperatures in Celsius\ntemperatures = [record.get_bottom_temperature(units='c') for record in results]\n\n# Take the median\nprint(statistics.median(temperatures))\n\nThis example reports the median temperature in Celcius for when Pacific glass shrimp was reported.\n\n\nLoad into Pandas\nThe results from the afscgap package are serializable and can be loaded into other tools like Pandas. This example loads Pacific glass shrimp from 2021 Gulf of Alaska into a data frame.\n\nimport pandas\n\nimport afscgap\n\nquery = afscgap.Query()\nquery.filter_year(eq=2021)\nquery.filter_srvy(eq='GOA')\nquery.filter_scientific_name(eq='Pasiphaea pacifica')\nresults = query.execute()\n\npandas.DataFrame(results.to_dicts())\n\nSpecifically, to_dicts provides an iterator over a dictionary form of the data that can be read into tools like Pandas.\n\n\nAdvanced filtering\nQueries so far have focused on filters requiring equality but range queries can be built as well.\n\nimport afscgap\n\n# Build query\nquery = afscgap.Query()\nquery.filter_year(min_val=2015, max_val=2019)   # Note min/max_val\nquery.filter_srvy(eq='GOA')\nquery.filter_scientific_name(eq='Pasiphaea pacifica')\nresults = query.execute()\n\n# Sum weight\nweights = map(lambda x: x.get_weight(units='kg'), results)\ntotal_weight = sum(weights)\nprint(total_weight)\n\nThis example queries for Pacific glass shrimp data between 2015 and 2019, summing the total weight caught. Note that most users will likely take advantage of built-in Python to ORDS query generation which dictates how the library communicates with the API service. However, users can provide raw ORDS queries as well using manual filtering.\n\n\nZero-catch inference\nUntil this point, these examples use presence-only data. However, the afscgap package can infer negative or “zero catch” records as well.\n\nimport afscgap\n\n# Mapping from CPUE to count\ncount_by_cpue = {}\n\n# Build query\nquery = afscgap.Query()\nquery.filter_year(eq=2021)\nquery.filter_srvy(eq='GOA')\nquery.filter_scientific_name(eq='Pasiphaea pacifica')\nquery.set_presence_only(False)  # Added to earlier example\nresults = query.execute()\n\n# Iterate through results and count\nfor record in results:\n  cpue = record.get_cpue_weight(units='kg/ha')\n  cpue_rounded = round(cpue)\n  count = count_by_cpue.get(cpue_rounded, 0) + 1\n  count_by_cpue[cpue_rounded] = count\n\n# Print the result\nprint(count_by_cpue)\n\nThis example revisits the earlier snippet for CPUE counts but set_presence_only(False) directs the library to look at additional data on hauls, determining which hauls did not have Pacific glass shrimp. This lets the library return records for hauls in which Pacific glass shrimp were not found. This can be seen in differences in counts reported:\n\n\n\n\n\n\n\n\nRounded CPUE\nCount with set_presence_only(True)\nCount with set_presence_only(False)\n\n\n\n\n0 kg/ha\n44\n521\n\n\n1 kg/ha\n7\n7\n\n\n2 kg/ha\n1\n1\n\n\n\nPut simply, while the earlier example showed CPUE counts for hauls in which Pacific glass shrimp were seen, this revised example reports for all hauls in the Gulf of Alaska in 2021.\n\n\nMore information\nPlease see the API documentation for the Python library for additional details.",
    "crumbs": [
      "Public Data (FOSS)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Access via API and Python</span>"
    ]
  },
  {
    "objectID": "content/foss-oracle-r.html",
    "href": "content/foss-oracle-r.html",
    "title": "Access via Oracle and R (AFSC Staff only)",
    "section": "",
    "text": "If the user has access to the AFSC Oracle database, the user can use SQL developer to view and pull the FOSS public data directly from the GAP_PRODUCTS Oracle schema.\n\n14.0.1 Connect to Oracle from R\nMany users will want to access the data from Oracle using R. The user will need to install the RODBC R package and ask OFIS (IT) connect R to Oracle. Then, use the following code in R to establish a connection from R to Oracle:\nHere, the user can write in their username and password directly into the RODBC connect function. Never save usernames or passwords in scripts that may be intentionally or unintentionally shared with others. If no username and password is entered in the function, pop-ups will appear on the screen asking for the username and password.\n\nlibrary(gapindex)\nchannel &lt;- gapindex::get_connected()\n\n\n\n14.0.2 Ex. Wholesale download data and join data in R\n\nlocations &lt;- c(\n  \"GAP_PRODUCTS.FOSS_CATCH\",\n  \"GAP_PRODUCTS.FOSS_HAUL\",\n  \"GAP_PRODUCTS.FOSS_SPECIES\"\n)\n\nprint(Sys.Date())\n\nerror_loading &lt;- c() # log if any tables are unable to download \nfor (i in 1:length(locations)){\n  print(locations[i])\n  a &lt;- RODBC::sqlQuery(channel, paste0(\"SELECT * FROM \", locations[i], \"; \"))\n  if (is.null(nrow(a))) { # if an error in downloading has occurred\n    error_loading &lt;- c(error_loading, locations[i])\n  } else { # if no error in downloading has occurred\n    write.csv(x = a, \n              # change file name to be more computer file storage friendly\n              here::here(paste0(tolower(gsub(\n                pattern = '.', \n                replacement = \"_\", \n                x = locations[i], \n                fixed = TRUE)),\n                \".csv\")))\n  }\n}\nerror_loading\n\nJoin downloaded files into presence-only table\n\n# Load data\nlibrary(dplyr)\nlibrary(here)\nlibrary(readr)\ncatch &lt;- readr::read_csv(file = here::here(\"data/gap_products_foss_catch.csv\"))[,-1] # remove \"row number\" column\nhaul &lt;- readr::read_csv(file = here::here(\"data/gap_products_foss_haul.csv\"))[,-1] # remove \"row number\" column\nspecies &lt;- readr::read_csv(file = here::here(\"data/gap_products_foss_species.csv\"))[,-1] # remove \"row number\" column\n\ndat &lt;- \n  # join haul and catch data to unique species by survey table\n  dplyr::left_join(haul, catch) |&gt; \n  # join species data to unique species by survey table\n  dplyr::left_join(species) |&gt; \n  # modify zero-filled rows\n  dplyr::mutate(\n    CPUE_KGKM2 = ifelse(is.null(CPUE_KGKM2), 0, CPUE_KGKM2), # just in case\n    CPUE_KGHA = CPUE_KGKM2/100, # Hectares\n    CPUE_NOKM2 = ifelse(is.null(CPUE_NOKM2), 0, CPUE_NOKM2), # just in case\n    CPUE_NOHA = CPUE_NOKM2/100, # Hectares\n    COUNT = ifelse(is.null(COUNT), 0, COUNT),\n    WEIGHT_KG = ifelse(is.null(WEIGHT_KG), 0, WEIGHT_KG) )\n\nJoin downloaded files into zero-filled table\n\n# Load data\nlibrary(dplyr)\nlibrary(here)\nlibrary(readr)\ncatch &lt;- readr::read_csv(file = here::here(\"data/gap_products_foss_catch.csv\"))[,-1] # remove \"row number\" column\nhaul &lt;- readr::read_csv(file = here::here(\"data/gap_products_foss_haul.csv\"))[,-1] # remove \"row number\" column\nspecies &lt;- readr::read_csv(file = here::here(\"data/gap_products_foss_species.csv\"))[,-1] # remove \"row number\" column\n\n# come up with full combination of what species should be listed for what hauls/surveys\n# for zero-filled data, all species caught in a survey need to have zero or non-zero row entries for a haul\ncomb &lt;- dplyr::full_join(\n  x = dplyr::left_join(catch, haul, by = \"HAULJOIN\") |&gt;\n    dplyr::select(SURVEY_DEFINITION_ID, SPECIES_CODE) |&gt;\n    dplyr::distinct(),\n  y = haul |&gt;\n    dplyr::select(SURVEY_DEFINITION_ID, HAULJOIN) |&gt;\n    dplyr::distinct(), \n  by = \"SURVEY_DEFINITION_ID\", \n  relationship = \"many-to-many\"\n)\n\n# Join data to make a full zero-filled CPUE dataset\ndat &lt;- comb |&gt; \n  # add species data to unique species by survey table\n  dplyr::left_join(species, \"SPECIES_CODE\") |&gt; \n  # add catch data\n  dplyr::full_join(catch, c(\"SPECIES_CODE\", \"HAULJOIN\")) |&gt; \n  # add haul data\n  dplyr::full_join(haul) |&gt; # , c(\"SURVEY_DEFINITION_ID\", \"HAULJOIN\")\n  # modify zero-filled rows\n  dplyr::mutate(\n    CPUE_KGKM2 = ifelse(is.null(CPUE_KGKM2), 0, CPUE_KGKM2),\n    CPUE_KGHA = CPUE_KGKM2/100, # Hectares\n    CPUE_NOKM2 = ifelse(is.null(CPUE_NOKM2), 0, CPUE_NOKM2),\n    CPUE_NOHA = CPUE_NOKM2/100, # Hectares\n    COUNT = ifelse(is.null(COUNT), 0, COUNT),\n    WEIGHT_KG = ifelse(is.null(WEIGHT_KG), 0, WEIGHT_KG) ) \n\n\n\n14.0.3 Ex. Join data using Oracle\nTo join these tables in Oracle, you may use a variant of the following code:\n\n\nSELECT \nhh.YEAR,\nhh.SRVY,                 \nhh.SURVEY,\nhh.SURVEY_DEFINITION_ID,\nhh.SURVEY_NAME,\nhh.CRUISE,\nhh.CRUISEJOIN,           \nhh.HAUL,\nhh.HAULJOIN,\nhh.STRATUM,\nhh.STATION,\nhh.VESSEL_ID,\nhh.VESSEL_NAME,          \nhh.DATE_TIME,\nhh.LATITUDE_DD_START, \nhh.LONGITUDE_DD_START, \nhh.LATITUDE_DD_END,\nhh.LONGITUDE_DD_END, \nhh.BOTTOM_TEMPERATURE_C,\nhh.SURFACE_TEMPERATURE_C,\nhh.DEPTH_M,\ncc.SPECIES_CODE,\nss.ITIS,\nss.WORMS,\nss.COMMON_NAME,     \nss.SCIENTIFIC_NAME,\nss.ID_RANK,\nCASE WHEN cc.CPUE_KGKM2 IS NULL THEN 0 ELSE cc.CPUE_KGKM2 END AS CPUE_KGKM2,\nCASE WHEN cc.CPUE_NOKM2 IS NULL THEN 0 ELSE cc.CPUE_NOKM2 END AS CPUE_NOKM2,\nCASE WHEN cc.COUNT IS NULL THEN 0 ELSE cc.COUNT END AS COUNT,\nCASE WHEN cc.WEIGHT_KG IS NULL THEN 0 ELSE cc.WEIGHT_KG END AS WEIGHT_KG,\nCASE WHEN cc.TAXON_CONFIDENCE IS NULL THEN NULL ELSE cc.TAXON_CONFIDENCE END AS TAXON_CONFIDENCE,\nhh.AREA_SWEPT_KM2,       \nhh.DISTANCE_FISHED_KM,\nhh.DURATION_HR,          \nhh.NET_WIDTH_M,\nhh.NET_HEIGHT_M,\nhh.PERFORMANCE \nFROM GAP_PRODUCTS.FOSS_SURVEY_SPECIES sv\nFULL OUTER JOIN GAP_PRODUCTS.FOSS_SPECIES ss\nON sv.SPECIES_CODE = ss.SPECIES_CODE\nFULL OUTER JOIN GAP_PRODUCTS.FOSS_HAUL hh\nON sv.SURVEY_DEFINITION_ID = hh.SURVEY_DEFINITION_ID\nFULL OUTER JOIN GAP_PRODUCTS.FOSS_CATCH cc\nON sv.SPECIES_CODE = cc.SPECIES_CODE\nAND hh.HAULJOIN = cc.HAULJOIN\n\n\n\n14.0.4 Ex. Subset data\nHere, we are pulling EBS Pacific cod from 2010 - 2021:\n\n# Pull data\ndata &lt;- RODBC::sqlQuery(\nchannel = channel, \nquery = \n\"SELECT * FROM GAP_PRODUCTS.FOSS_CATCH cc\nJOIN GAP_PRODUCTS.FOSS_HAUL hh\nON cc.HAULJOIN = hh.HAULJOIN\nWHERE SRVY = 'EBS' \nAND SPECIES_CODE = 21720 -- 'Pacific cod' \nAND YEAR &gt;= 2010 \nAND YEAR &lt; 2021\")\n\nflextable::flextable(data[1:3,]) |&gt; \n  flextable::theme_zebra() \n\nHAULJOINSPECIES_CODECPUE_KGKM2CPUE_NOKM2COUNTWEIGHT_KGTAXON_CONFIDENCEYEARSRVYSURVEYSURVEY_DEFINITION_IDSURVEY_NAMECRUISECRUISEJOINHAULJOIN.1HAULSTRATUMSTATIONVESSEL_IDVESSEL_NAMEDATE_TIMELATITUDE_DD_STARTLONGITUDE_DD_STARTLATITUDE_DD_ENDLONGITUDE_DD_ENDBOTTOM_TEMPERATURE_CSURFACE_TEMPERATURE_CDEPTH_MDISTANCE_FISHED_KMDURATION_HRNET_WIDTH_MNET_HEIGHT_MAREA_SWEPT_KM2PERFORMANCE-6,36121,7201,733.74172,910.605710763.736High2,010EBSeastern Bering Sea98Eastern Bering Sea Crab/Groundfish Bottom Trawl Survey201,001-658-6,361210H-1689ALDEBARAN2010-06-07 08:17:5157.32308-158.416657.34365-158.39872.94.4322.5320.45814.5192.4070.036762111.12-6,36221,7204,048.84731,182.511649167.773High2,010EBSeastern Bering Sea98Eastern Bering Sea Crab/Groundfish Bottom Trawl Survey201,001-658-6,362310I-1689ALDEBARAN2010-06-07 10:49:2157.65588-158.365157.68152-158.36372.42.9372.8540.52314.5192.1170.041437230.00-6,36321,720964.1577288.08061240.162High2,010EBSeastern Bering Sea98Eastern Bering Sea Crab/Groundfish Bottom Trawl Survey201,001-658-6,363410J-1689ALDEBARAN2010-06-07 13:32:4657.98402-158.328358.00947-158.33531.92.2352.8690.52114.5191.9330.041655010.00\n\n\n\n\n14.0.5 Ex. Find all species found in the eastern Bering Sea (EBS) survey in 2023\n\n# Pull data\ndata &lt;- RODBC::sqlQuery(\nchannel = channel, \nquery = \n\"SELECT DISTINCT \nss.COMMON_NAME,\nss.SCIENTIFIC_NAME, \nss.ID_RANK, \nss.WORMS\nFROM GAP_PRODUCTS.FOSS_CATCH cc -- get species codes\nLEFT JOIN GAP_PRODUCTS.FOSS_SPECIES ss -- get species info\nON cc.SPECIES_CODE = ss.SPECIES_CODE\nLEFT JOIN GAP_PRODUCTS.FOSS_HAUL hh -- filter by year and survey\nON cc.HAULJOIN = hh.HAULJOIN\nWHERE hh.YEAR = 2023\nAND hh.SURVEY_DEFINITION_ID = 98 -- EBS survey\nORDER BY COMMON_NAME\")\n\nflextable::flextable(data[1:3,]) |&gt; \n  # flextable::fit_to_width(max_width = 6) |&gt; \n  flextable::theme_zebra() \n\nCOMMON_NAMESCIENTIFIC_NAMEID_RANKWORMSAlaska great-tellinMegangulus luteusspecies423,511Alaska plaicePleuronectes quadrituberculatusspecies254,564Alaska skateArctoraja parmiferaspecies1,577,324",
    "crumbs": [
      "Public Data (FOSS)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Access via Oracle and R (AFSC Staff only)</span>"
    ]
  },
  {
    "objectID": "content/other-intro.html",
    "href": "content/other-intro.html",
    "title": "Data Products & Tools",
    "section": "",
    "text": "To accompany these data, we also produce data products to make using our data more accessible and straightforward.\n\n\nSurvey of products developed by GAPProductPoint of ContactAIPoint of ContactGOAPoint of ContactBSDescriptionDataFinalized bottom trawl dataSusanne McDermottNed LamanDuane StevensonNOAA-NMFS-AFSC-RACE-GAP bottom trawl data that has completed the post-survey internal QAQC process.Data requestsAlexandra DowlinChris AndersonTo request a subset of the NOAA-NMFS-AFSC-RACE-GAP bottom trawl raw data or a data product.Species codebookChris AndersonList of codes used for fish and invertebrates identified in NOAA-NMFS-AFSC-RACE-GAP Division surveys.Survey protocolsEm?Documentation of NOAA-NMFS-AFSC-RACE-GAP groundfish bottom trawl survey protocols.AnalysisDesign-based indices for target speciesSusanne McDermottNed LamanDuane StevensonStandard design-based indices of biomass and abundance from NOAA-NMFS-AFSC-RACE-GAP bottom trawl survey data.Design-based age or length compositionSusanne McDermottNed LamanDuane StevensonStandard design-based indices of size and age composition from NOAA-NMFS-AFSC-RACE-GAP bottom trawl survey data.Model-based indices, age comps (stock assessment), area occupied, and COG (ESP)Lewis BarnettSpatiotemporal model-based biomass indices, abundance indices, and age composition from NOAA-NMFS-AFSC-RACE-GAP bottom trawl survey data.Annual bottom and surface temperature summary (ESR, stock assessment)Rebecca HowardSean Rohan &Lewis BarnettSummary metrics for bottom trawl bottom and surface temperatures relative to historical baseline.Bering Sea cold pool index and temperature data products (ESR, ESP, stock assessment)-Sean Rohan &Lewis BarnettCreate annual temperature rasters for the EBS, calculate the EBS cold pool index and temperature data products, and produce visualizations.Annual fish condition (ESR)Rebecca Howard, Sean Rohan, &Bianca ProhaskaRebecca Howard &Bianca ProhaskaBianca Prohaska &Sean RohanGroundfish morphometric condition for fish in the Bering Sea, Aleutian Islands, and Gulf of Alaska.Rockfish indices vs environmental gradients (ESR)Alexandra Dowlin &Christina Conrath-GOA/AI survey trends in distribution and abundance of 6 rockfishes across 3 environmental gradients in the North Pacific.Structure-Forming Invertebrates-Habitat Areas of Particular Concern (SFI-HAPC) (ESR)Christina ConrathThaddeus BuserRelative abundance of sponges, hydrocorals, soft corals, Gorgonians, anemones, and Pennatulaceans in GOA and AI surveys.Forage fishes (ESR)-Megsie Siple-Relative abundance of capelin, eulachon, sandfish, sand lance, and prickelbacks in GOA and AI surveys.Miscellaneous species (ESR)Sarah FriedmanThaddeus BuserRelative abundance of echinoderms, poachers, shrimp and eelpouts in GOA and AI surveys.Jellies (ESR)Alexandra DowlinThaddeus BuserRelative abundance of sea jellies in GOA and AI surveys.Essential fish habitatMegsie SipleSean RohanHabitat maps for groundfish and crab based on species distribution models. Updated every five years.Visualization ToolsAlaska groundfish maps (CPUE, etc.)Megsie SipleSean RohanCommunicationAnnual survey data reportMegsie Siple, Bethany Riggle, Alex DowlinEmily Markowitz, Sophia Wassermann, Nicole Charriere, Chris AndersonAlaska Fisheries Science Center NOAA Technical Memorandum summary of the survey progress and findings. These are available online and the latest publications for each survey are listed below (https://repository.library.noaa.gov/).ADF&G report of research activitiesAlexandra DowlinNicole Charriere &Rebecca HaehnReport on AI and GOA trawl survey fishing activity inside and outside of Alaska State waters.IPHC report of research activitiesNed LamanRebecca HaehnPlan team survey results presentationMegsie Siple, Susanne McDermottMegsie Siple, Ned LamanDuane StevensonNOAA-NMFS-AFSC-RACE-GAP present their findings to the North Pacific Groundfish Plan Team; presentations, recordings, and attachments located here: https://www.npfmc.org/about-the-council/plan-teams/bsai-and-goa-groundfish/.Community highlights reportSusanne McDermottEmily MarkowitzCompilation of NOAA-NMFS-AFSC-RACE-GAP survey findings for communities around Alaska.Bottom Trawl Survey Temperature and Progress MapsNed LamanEmily MarkowitzNear real-time survey progress and ocean temperatures recorded during the Aleutian Islands, Gulf of Alaska, and Bering Sea Bottom Trawl Surveys.",
    "crumbs": [
      "Data Products & Tools"
    ]
  },
  {
    "objectID": "content/other-pkgs.html",
    "href": "content/other-pkgs.html",
    "title": "Open source code",
    "section": "",
    "text": "R Packages",
    "crumbs": [
      "Data Products & Tools",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Open source code</span>"
    ]
  },
  {
    "objectID": "content/other-pkgs.html#r-packages",
    "href": "content/other-pkgs.html#r-packages",
    "title": "Open source code",
    "section": "",
    "text": "akgfmaps R package\nBttom trawl survey maps layers and plotting examples. POC: Sean Rohan\n\n\ncoldpool R package\nCold pool area and temperature data products for the Bering Sea. POC: Sean Rohan\n\n\nakfishcondition R package\nGroundfish morphometric condition indicators for fish in the Bering Sea, Aleutian Islands, and Gulf of Alaska. POC: Sean Rohan\n\n\ngapindex R package\nCalculation of Design-Based Indices of Abundance and Composition for AFSC GAP Bottom Trawl Surveys. POC: Zack Oyafuso and Margaret Siple",
    "crumbs": [
      "Data Products & Tools",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Open source code</span>"
    ]
  },
  {
    "objectID": "content/end-contact-us.html",
    "href": "content/end-contact-us.html",
    "title": "Contact us",
    "section": "",
    "text": "This code is primarally maintained by:\nThank you for using our data guide!\nEmily Markowitz (Emily.Markowitz AT noaa.gov; @EmilyMarkowitz-NOAA)\nZack Oyafuso (Zack.Oyafuso AT noaa.gov; @zoyafuso-NOAA)\nSarah Friedman (Sarah.Friedman AT noaa.gov; @SarahFriedman-NOAA)\nAlaska Fisheries Science Center,\nNational Marine Fisheries Service,\nNational Oceanic and Atmospheric Administration,\nSeattle, WA 98195\nGeneral questions and more specific data requests can be sent to nmfs.afsc.gap.metadata@noaa.gov or submitted as an issue on our GitHub Organization. The version of this data used for stock assessments can be found through the Alaska Fisheries Information Network (AKFIN). For questions about the eastern Bering Sea surveys, contact Duane Stevenson (Duane.Stevenson@noaa.gov). For questions about the Gulf of Alaska or Aleutian Islands surveys, contact Ned Laman (Ned.Laman@noaa.gov). For questions specifically about crab data in any region, contact Mike Litzow (Mike.Litzow@noaa.gov), the Shellfish Assessment Program lead.\nFor questions, comments, and concerns specifically about the Fisheries One Stop Shop (FOSS) platform, please contact us using the Comments page on the FOSS webpage.",
    "crumbs": [
      "Contact us"
    ]
  },
  {
    "objectID": "content/end-run-notes.html",
    "href": "content/end-run-notes.html",
    "title": "Production run notes",
    "section": "",
    "text": "Report run date: Tuesday, September 30, 2025\n\n\nR Version Metadata\n\n\nR version 4.5.1 (2025-06-13 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 22631)\n\nMatrix products: default\n  LAPACK version 3.12.1\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/Los_Angeles\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.5.1    fastmap_1.2.0     cli_3.6.5        \n [5] tools_4.5.1       htmltools_0.5.8.1 rstudioapi_0.17.1 yaml_2.3.10      \n [9] rmarkdown_2.30    knitr_1.50        jsonlite_2.0.0    xfun_0.53        \n[13] digest_0.6.37     rlang_1.1.6       evaluate_1.0.5   \n\n\n\nNOAA README\nThis repository is a scientific product and is not official communication of the National Oceanic and Atmospheric Administration, or the United States Department of Commerce. All NOAA GitHub project code is provided on an ‘as is’ basis and the user assumes responsibility for its use. Any claims against the Department of Commerce or Department of Commerce bureaus stemming from the use of this GitHub project will be governed by all applicable Federal law. Any reference to specific commercial products, processes, or services by service mark, trademark, manufacturer, or otherwise, does not constitute or imply their endorsement, recommendation or favoring by the Department of Commerce. The Department of Commerce seal and logo, or the seal and logo of a DOC bureau, shall not be used in any manner to imply endorsement of any commercial product or activity by DOC or the United States Government.\n\n\nNOAA License\nSoftware code created by U.S. Government employees is not subject to copyright in the United States (17 U.S.C. §105). The United States/Department of Commerce reserve all rights to seek and obtain copyright protection in countries other than the United States for Software authored in its entirety by the Department of Commerce. To this end, the Department of Commerce hereby grants to Recipient a royalty-free, nonexclusive license to use, copy, and create derivative works of the Software outside of the United States.",
    "crumbs": [
      "Contact us",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Production run notes</span>"
    ]
  },
  {
    "objectID": "content/end-acknowledgements.html",
    "href": "content/end-acknowledgements.html",
    "title": "Acknowledgments",
    "section": "",
    "text": "Community Acknowledgments\nWe would like to thank the many communities of Alaska and their members who have helped contribute to this body of work. The knowledge, experiences, and insights have been instrumental in expanding the scope of our science and knowledge to encompass the many issues that face this important ecosystem. We appreciate feedback from those residing in the region that are willing to share their insights and participation in an open dialog about how we can improve our collective knowledge of the ecosystem and the region.",
    "crumbs": [
      "Contact us",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Acknowledgments</span>"
    ]
  },
  {
    "objectID": "content/end-acknowledgements.html#partners",
    "href": "content/end-acknowledgements.html#partners",
    "title": "Acknowledgments",
    "section": "Partners",
    "text": "Partners\nScientists from the Alaska Fisheries Science Center conduct these bottom trawl surveys with participation from the Alaska Department of Fish & Game (ADF&G), the International Pacific Halibut Commission (IPHC), and universities. This research is conducted on chartered fishing vessels.",
    "crumbs": [
      "Contact us",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Acknowledgments</span>"
    ]
  },
  {
    "objectID": "content/end-acknowledgements.html#collaborators",
    "href": "content/end-acknowledgements.html#collaborators",
    "title": "Acknowledgments",
    "section": "Collaborators",
    "text": "Collaborators\nOur data are used in many annual publications, including but not limited to the list below:\n\nAlaska Stock Assessments\nNorth Pacific Groundfish Stock Assessment and Fishery Evaluation Reports\nGroundfish Economic Status Reports for the Gulf of Alaska and Bering Sea and Aleutian Islands\nAlaska Marine Ecosystem Status Report Database\nSoutheast Alaska Coastal Monitoring Survey Reports\nAlaska Fisheries Life History Database\nEssential Fish Habitat Research Plan in Alaska",
    "crumbs": [
      "Contact us",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Acknowledgments</span>"
    ]
  },
  {
    "objectID": "content/end-refs.html",
    "href": "content/end-refs.html",
    "title": "Citations and References",
    "section": "",
    "text": "Access Constraints\nThere are no legal restrictions on access to the data. They reside in public domain and can be freely distributed.\nUser Constraints: Users must read and fully comprehend the metadata prior to use. Data should not be used beyond the limits of the source scale. Acknowledgement of AFSC Groundfish Assessment Program, as the source from which these data were obtained, in any publications and/or other representations of these data, is suggested.\n\n\nReferences\n\n\nAlaska Fisheries Information Network (AKFIN). (2024). AFSC\ngroundfish assessment program design-based production data.\nNOAA Fisheries Alaska Fisheries Science Center, Groundfish\nAssessment Program; https://akfinbi.psmfc.org/analytics/;\nU.S. Dep. Commer. https://www.psmfc.org/program/alaska-fisheries-information-network-akfin\n\n\nHoff, G. R. (2016). Results of the 2016 eastern Bering\nSea upper continental slope survey of groundfishes and\ninvertebrate resources (NOAA Tech. Memo. NOAA-AFSC-339). U.S.\nDep. Commer. https://doi.org/10.7289/V5/TM-AFSC-339\n\n\nMarkowitz, E. H., Dawson, E. J., Wassermann, S., Anderson, C. B., Rohan,\nS. K., Charriere, B. K., and Stevenson, D. E. (2024). Results of the\n2023 eastern and northern Bering Sea continental shelf\nbottom trawl survey of groundfish and invertebrate fauna (NOAA\nTech. Memo. NMFS-AFSC-487; p. 242). U.S. Dep. Commer. https://doi.org/10.25923/2mry-yx09\n\n\nMarkowitz, E. H., Wassermann, S., Rohan, S. K., Charriere, B. K.,\nAnderson, C. B., and Stevenson, D. E. (2025). Results of the 2024\neastern and northern Bering Sea continental shelf bottom\ntrawl survey of groundfish and invertebrate fauna (NOAA Tech. Memo.\nNMFS-AFSC-499; p. 203). U.S. Dep. Commer. https://doi.org/10.25923/8qa3-x785\n\n\nNOAA Fisheries Alaska Fisheries Science Center. (2024). Fisheries\none stop shop public data: RACE division bottom trawl survey data\nquery. https://www.fisheries.noaa.gov/foss; U.S. Dep.\nCommer.\n\n\nNOAA Fisheries Alaska Fisheries Science Center, Goundfish Assessment\nProgram. (2024). AFSC goundfish assessment program design-based\nproduction data.\nhttps://www.fisheries.noaa.gov/alaska/science-data/groundfish-assessment-program-bottom-trawl-surveys;\nU.S. Dep. Commer.\n\n\nSiple, M. C., Szalay, P. G. von, Raring, N. W., Dowlin, A. N., and\nRiggle, B. C. (2024). Data report: 2023 gulf of alaska bottom trawl\nsurvey (NOAA Tech. Memo. AFSC processed report; 2024-09).\nU.S. Dep. Commer. https://doi.org/10.25923/gbb1-x748\n\n\nVon Szalay, P. G., Raring, N. W., Siple, M. C., Dowlin, A. N., Riggle,\nB. C., and Laman, E. A. and. (2023). Data report: 2022\nAleutian Islands bottom trawl survey (AFSC Processed\nRep. 2023-07; p. 230). U.S. Dep. Commer. https://doi.org/10.25923/85cy-g225",
    "crumbs": [
      "Contact us",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Citations and References</span>"
    ]
  }
]